{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "9PqCvW1c1bkD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.manifold import TSNE\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import statistics\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SjZu-CYh1nI-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file=r'/content/sample_data/mice_imputed.csv'\n",
        "df=pd.read_csv(file)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGXQEyzTXInV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        },
        "outputId": "56af2a33-f0ba-4465-b08b-f20113957bf0"
      },
      "source": [
        "df"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>FireSeason</th>\n",
              "      <th>Month</th>\n",
              "      <th>individual_fire_num</th>\n",
              "      <th>PrepLevel</th>\n",
              "      <th>day0_F_min</th>\n",
              "      <th>day0_F_mean</th>\n",
              "      <th>day0_F_max</th>\n",
              "      <th>day0_IN_Sea_level</th>\n",
              "      <th>day0_F_Mean_dew_point</th>\n",
              "      <th>day0_IN_tot_rain</th>\n",
              "      <th>day0_MI_visibilty</th>\n",
              "      <th>day0_MPH_mean_wind_speed</th>\n",
              "      <th>day0_MPH_max_sustained_wind</th>\n",
              "      <th>day0_MPH_max_wind</th>\n",
              "      <th>day1_F_min</th>\n",
              "      <th>day1_F_mean</th>\n",
              "      <th>day1_F_max</th>\n",
              "      <th>day1_IN_Sea_level</th>\n",
              "      <th>day1_F_Mean_dew_point</th>\n",
              "      <th>day1_IN_tot_rain</th>\n",
              "      <th>day1_MI_visibilty</th>\n",
              "      <th>day1_MPH_mean_wind_speed</th>\n",
              "      <th>day1_MPH_max_sustained_wind</th>\n",
              "      <th>day1_MPH_max_wind</th>\n",
              "      <th>day2_F_min</th>\n",
              "      <th>day2_F_mean</th>\n",
              "      <th>day2_F_max</th>\n",
              "      <th>day2_IN_Sea_level</th>\n",
              "      <th>day2_F_Mean_dew_point</th>\n",
              "      <th>day2_IN_tot_rain</th>\n",
              "      <th>day2_MI_visibilty</th>\n",
              "      <th>day2_MPH_mean_wind_speed</th>\n",
              "      <th>day2_MPH_max_sustained_wind</th>\n",
              "      <th>day2_MPH_max_wind</th>\n",
              "      <th>day3_F_min</th>\n",
              "      <th>day3_F_mean</th>\n",
              "      <th>day3_F_max</th>\n",
              "      <th>day3_IN_Sea_level</th>\n",
              "      <th>day3_F_Mean_dew_point</th>\n",
              "      <th>day3_IN_tot_rain</th>\n",
              "      <th>day3_MI_visibilty</th>\n",
              "      <th>day3_MPH_mean_wind_speed</th>\n",
              "      <th>day3_MPH_max_sustained_wind</th>\n",
              "      <th>day3_MPH_max_wind</th>\n",
              "      <th>day4_F_min</th>\n",
              "      <th>day4_F_mean</th>\n",
              "      <th>day4_F_max</th>\n",
              "      <th>day4_IN_Sea_level</th>\n",
              "      <th>day4_F_Mean_dew_point</th>\n",
              "      <th>day4_IN_tot_rain</th>\n",
              "      <th>day4_MI_visibilty</th>\n",
              "      <th>day4_MPH_mean_wind_speed</th>\n",
              "      <th>day4_MPH_max_sustained_wind</th>\n",
              "      <th>day4_MPH_max_wind</th>\n",
              "      <th>Fire_Severity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1993</td>\n",
              "      <td>5</td>\n",
              "      <td>62</td>\n",
              "      <td>1</td>\n",
              "      <td>34.0</td>\n",
              "      <td>43.9</td>\n",
              "      <td>53.1</td>\n",
              "      <td>29.86</td>\n",
              "      <td>37.3</td>\n",
              "      <td>0.00</td>\n",
              "      <td>26.8</td>\n",
              "      <td>8.75</td>\n",
              "      <td>13.81</td>\n",
              "      <td>17.26</td>\n",
              "      <td>34.9</td>\n",
              "      <td>42.0</td>\n",
              "      <td>52.0</td>\n",
              "      <td>29.55</td>\n",
              "      <td>32.9</td>\n",
              "      <td>0.00</td>\n",
              "      <td>31.4</td>\n",
              "      <td>11.62</td>\n",
              "      <td>17.26</td>\n",
              "      <td>20.71</td>\n",
              "      <td>29.8</td>\n",
              "      <td>36.9</td>\n",
              "      <td>44.1</td>\n",
              "      <td>29.83</td>\n",
              "      <td>28.7</td>\n",
              "      <td>0.00</td>\n",
              "      <td>35.1</td>\n",
              "      <td>9.09</td>\n",
              "      <td>16.11</td>\n",
              "      <td>19.56</td>\n",
              "      <td>23.9</td>\n",
              "      <td>30.4</td>\n",
              "      <td>37.9</td>\n",
              "      <td>30.12</td>\n",
              "      <td>22.2</td>\n",
              "      <td>0.00</td>\n",
              "      <td>28.2</td>\n",
              "      <td>10.24</td>\n",
              "      <td>14.96</td>\n",
              "      <td>17.26</td>\n",
              "      <td>23.0</td>\n",
              "      <td>27.4</td>\n",
              "      <td>41.9</td>\n",
              "      <td>29.97</td>\n",
              "      <td>21.3</td>\n",
              "      <td>0.00</td>\n",
              "      <td>17.9</td>\n",
              "      <td>13.00</td>\n",
              "      <td>16.11</td>\n",
              "      <td>20.71</td>\n",
              "      <td>Small</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1993</td>\n",
              "      <td>5</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>38.8</td>\n",
              "      <td>48.1</td>\n",
              "      <td>55.9</td>\n",
              "      <td>30.07</td>\n",
              "      <td>39.7</td>\n",
              "      <td>0.00</td>\n",
              "      <td>29.8</td>\n",
              "      <td>8.75</td>\n",
              "      <td>12.77</td>\n",
              "      <td>19.68</td>\n",
              "      <td>34.0</td>\n",
              "      <td>43.9</td>\n",
              "      <td>53.1</td>\n",
              "      <td>29.86</td>\n",
              "      <td>37.3</td>\n",
              "      <td>0.00</td>\n",
              "      <td>26.8</td>\n",
              "      <td>8.75</td>\n",
              "      <td>13.81</td>\n",
              "      <td>24.17</td>\n",
              "      <td>34.9</td>\n",
              "      <td>42.0</td>\n",
              "      <td>52.0</td>\n",
              "      <td>29.55</td>\n",
              "      <td>32.9</td>\n",
              "      <td>0.00</td>\n",
              "      <td>31.4</td>\n",
              "      <td>11.62</td>\n",
              "      <td>17.26</td>\n",
              "      <td>20.71</td>\n",
              "      <td>29.8</td>\n",
              "      <td>36.9</td>\n",
              "      <td>44.1</td>\n",
              "      <td>29.83</td>\n",
              "      <td>28.7</td>\n",
              "      <td>0.00</td>\n",
              "      <td>35.1</td>\n",
              "      <td>9.09</td>\n",
              "      <td>16.11</td>\n",
              "      <td>19.56</td>\n",
              "      <td>23.9</td>\n",
              "      <td>30.4</td>\n",
              "      <td>37.9</td>\n",
              "      <td>30.12</td>\n",
              "      <td>22.2</td>\n",
              "      <td>0.00</td>\n",
              "      <td>28.2</td>\n",
              "      <td>10.24</td>\n",
              "      <td>14.96</td>\n",
              "      <td>16.11</td>\n",
              "      <td>Small</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1993</td>\n",
              "      <td>5</td>\n",
              "      <td>28</td>\n",
              "      <td>1</td>\n",
              "      <td>42.1</td>\n",
              "      <td>49.0</td>\n",
              "      <td>59.9</td>\n",
              "      <td>29.93</td>\n",
              "      <td>42.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>39.4</td>\n",
              "      <td>9.67</td>\n",
              "      <td>14.96</td>\n",
              "      <td>17.26</td>\n",
              "      <td>45.9</td>\n",
              "      <td>53.0</td>\n",
              "      <td>59.0</td>\n",
              "      <td>29.79</td>\n",
              "      <td>39.9</td>\n",
              "      <td>0.00</td>\n",
              "      <td>53.4</td>\n",
              "      <td>11.28</td>\n",
              "      <td>19.68</td>\n",
              "      <td>20.71</td>\n",
              "      <td>32.9</td>\n",
              "      <td>44.8</td>\n",
              "      <td>55.9</td>\n",
              "      <td>29.98</td>\n",
              "      <td>35.2</td>\n",
              "      <td>0.12</td>\n",
              "      <td>36.0</td>\n",
              "      <td>9.09</td>\n",
              "      <td>14.96</td>\n",
              "      <td>16.11</td>\n",
              "      <td>38.8</td>\n",
              "      <td>46.1</td>\n",
              "      <td>57.0</td>\n",
              "      <td>29.99</td>\n",
              "      <td>38.7</td>\n",
              "      <td>0.08</td>\n",
              "      <td>24.9</td>\n",
              "      <td>10.93</td>\n",
              "      <td>22.79</td>\n",
              "      <td>26.47</td>\n",
              "      <td>38.8</td>\n",
              "      <td>48.1</td>\n",
              "      <td>55.9</td>\n",
              "      <td>30.07</td>\n",
              "      <td>39.7</td>\n",
              "      <td>0.00</td>\n",
              "      <td>29.8</td>\n",
              "      <td>8.75</td>\n",
              "      <td>12.77</td>\n",
              "      <td>17.26</td>\n",
              "      <td>Large</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1993</td>\n",
              "      <td>5</td>\n",
              "      <td>20</td>\n",
              "      <td>2</td>\n",
              "      <td>39.9</td>\n",
              "      <td>49.2</td>\n",
              "      <td>60.1</td>\n",
              "      <td>29.57</td>\n",
              "      <td>37.8</td>\n",
              "      <td>0.00</td>\n",
              "      <td>32.5</td>\n",
              "      <td>15.08</td>\n",
              "      <td>21.86</td>\n",
              "      <td>26.47</td>\n",
              "      <td>36.0</td>\n",
              "      <td>42.4</td>\n",
              "      <td>54.9</td>\n",
              "      <td>30.03</td>\n",
              "      <td>34.5</td>\n",
              "      <td>0.12</td>\n",
              "      <td>32.3</td>\n",
              "      <td>12.89</td>\n",
              "      <td>20.83</td>\n",
              "      <td>25.32</td>\n",
              "      <td>42.1</td>\n",
              "      <td>49.3</td>\n",
              "      <td>61.0</td>\n",
              "      <td>29.97</td>\n",
              "      <td>39.3</td>\n",
              "      <td>0.13</td>\n",
              "      <td>33.7</td>\n",
              "      <td>13.12</td>\n",
              "      <td>18.30</td>\n",
              "      <td>20.71</td>\n",
              "      <td>38.8</td>\n",
              "      <td>45.3</td>\n",
              "      <td>55.0</td>\n",
              "      <td>30.18</td>\n",
              "      <td>36.8</td>\n",
              "      <td>0.00</td>\n",
              "      <td>36.0</td>\n",
              "      <td>8.17</td>\n",
              "      <td>13.81</td>\n",
              "      <td>16.11</td>\n",
              "      <td>42.1</td>\n",
              "      <td>49.0</td>\n",
              "      <td>59.9</td>\n",
              "      <td>29.93</td>\n",
              "      <td>42.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>39.4</td>\n",
              "      <td>9.67</td>\n",
              "      <td>14.96</td>\n",
              "      <td>17.26</td>\n",
              "      <td>Small</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1993</td>\n",
              "      <td>5</td>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "      <td>43.0</td>\n",
              "      <td>50.7</td>\n",
              "      <td>56.8</td>\n",
              "      <td>29.88</td>\n",
              "      <td>40.5</td>\n",
              "      <td>0.01</td>\n",
              "      <td>38.1</td>\n",
              "      <td>12.77</td>\n",
              "      <td>21.86</td>\n",
              "      <td>21.86</td>\n",
              "      <td>41.0</td>\n",
              "      <td>50.3</td>\n",
              "      <td>55.9</td>\n",
              "      <td>29.97</td>\n",
              "      <td>39.4</td>\n",
              "      <td>0.05</td>\n",
              "      <td>41.8</td>\n",
              "      <td>9.32</td>\n",
              "      <td>17.26</td>\n",
              "      <td>25.32</td>\n",
              "      <td>43.9</td>\n",
              "      <td>50.7</td>\n",
              "      <td>61.0</td>\n",
              "      <td>29.49</td>\n",
              "      <td>37.1</td>\n",
              "      <td>0.04</td>\n",
              "      <td>31.7</td>\n",
              "      <td>14.38</td>\n",
              "      <td>20.83</td>\n",
              "      <td>25.32</td>\n",
              "      <td>39.9</td>\n",
              "      <td>49.2</td>\n",
              "      <td>60.1</td>\n",
              "      <td>29.57</td>\n",
              "      <td>37.8</td>\n",
              "      <td>0.00</td>\n",
              "      <td>32.5</td>\n",
              "      <td>15.08</td>\n",
              "      <td>21.86</td>\n",
              "      <td>26.47</td>\n",
              "      <td>36.0</td>\n",
              "      <td>42.4</td>\n",
              "      <td>54.9</td>\n",
              "      <td>30.03</td>\n",
              "      <td>34.5</td>\n",
              "      <td>0.12</td>\n",
              "      <td>32.3</td>\n",
              "      <td>12.89</td>\n",
              "      <td>20.83</td>\n",
              "      <td>25.32</td>\n",
              "      <td>Small</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3243</th>\n",
              "      <td>3244</td>\n",
              "      <td>2019</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>32.0</td>\n",
              "      <td>43.3</td>\n",
              "      <td>52.0</td>\n",
              "      <td>29.89</td>\n",
              "      <td>37.6</td>\n",
              "      <td>0.28</td>\n",
              "      <td>9.4</td>\n",
              "      <td>18.87</td>\n",
              "      <td>36.94</td>\n",
              "      <td>48.33</td>\n",
              "      <td>32.0</td>\n",
              "      <td>40.1</td>\n",
              "      <td>51.1</td>\n",
              "      <td>29.87</td>\n",
              "      <td>34.9</td>\n",
              "      <td>0.00</td>\n",
              "      <td>10.0</td>\n",
              "      <td>9.67</td>\n",
              "      <td>18.30</td>\n",
              "      <td>29.92</td>\n",
              "      <td>37.0</td>\n",
              "      <td>43.6</td>\n",
              "      <td>53.1</td>\n",
              "      <td>29.48</td>\n",
              "      <td>37.1</td>\n",
              "      <td>0.01</td>\n",
              "      <td>10.0</td>\n",
              "      <td>8.75</td>\n",
              "      <td>17.26</td>\n",
              "      <td>24.17</td>\n",
              "      <td>27.0</td>\n",
              "      <td>44.6</td>\n",
              "      <td>53.1</td>\n",
              "      <td>29.44</td>\n",
              "      <td>41.1</td>\n",
              "      <td>0.16</td>\n",
              "      <td>10.0</td>\n",
              "      <td>13.46</td>\n",
              "      <td>23.02</td>\n",
              "      <td>26.35</td>\n",
              "      <td>27.0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>29.59</td>\n",
              "      <td>32.8</td>\n",
              "      <td>0.00</td>\n",
              "      <td>8.9</td>\n",
              "      <td>10.36</td>\n",
              "      <td>23.02</td>\n",
              "      <td>33.26</td>\n",
              "      <td>Large</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3244</th>\n",
              "      <td>3245</td>\n",
              "      <td>2019</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>32.0</td>\n",
              "      <td>41.1</td>\n",
              "      <td>53.6</td>\n",
              "      <td>30.24</td>\n",
              "      <td>35.5</td>\n",
              "      <td>0.02</td>\n",
              "      <td>10.0</td>\n",
              "      <td>9.55</td>\n",
              "      <td>19.68</td>\n",
              "      <td>27.73</td>\n",
              "      <td>32.0</td>\n",
              "      <td>43.3</td>\n",
              "      <td>52.0</td>\n",
              "      <td>29.89</td>\n",
              "      <td>37.6</td>\n",
              "      <td>0.28</td>\n",
              "      <td>9.4</td>\n",
              "      <td>18.87</td>\n",
              "      <td>36.94</td>\n",
              "      <td>48.33</td>\n",
              "      <td>32.0</td>\n",
              "      <td>40.1</td>\n",
              "      <td>51.1</td>\n",
              "      <td>29.87</td>\n",
              "      <td>34.9</td>\n",
              "      <td>0.00</td>\n",
              "      <td>10.0</td>\n",
              "      <td>9.67</td>\n",
              "      <td>18.30</td>\n",
              "      <td>28.77</td>\n",
              "      <td>37.0</td>\n",
              "      <td>43.6</td>\n",
              "      <td>53.1</td>\n",
              "      <td>29.48</td>\n",
              "      <td>37.1</td>\n",
              "      <td>0.01</td>\n",
              "      <td>10.0</td>\n",
              "      <td>8.75</td>\n",
              "      <td>17.26</td>\n",
              "      <td>24.17</td>\n",
              "      <td>27.0</td>\n",
              "      <td>44.6</td>\n",
              "      <td>53.1</td>\n",
              "      <td>29.44</td>\n",
              "      <td>41.1</td>\n",
              "      <td>0.16</td>\n",
              "      <td>10.0</td>\n",
              "      <td>13.46</td>\n",
              "      <td>23.02</td>\n",
              "      <td>26.35</td>\n",
              "      <td>Severe</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3245</th>\n",
              "      <td>3246</td>\n",
              "      <td>2019</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>46.0</td>\n",
              "      <td>48.3</td>\n",
              "      <td>53.1</td>\n",
              "      <td>30.21</td>\n",
              "      <td>40.5</td>\n",
              "      <td>0.00</td>\n",
              "      <td>10.0</td>\n",
              "      <td>14.27</td>\n",
              "      <td>19.68</td>\n",
              "      <td>28.88</td>\n",
              "      <td>32.0</td>\n",
              "      <td>41.1</td>\n",
              "      <td>53.6</td>\n",
              "      <td>30.24</td>\n",
              "      <td>35.5</td>\n",
              "      <td>0.02</td>\n",
              "      <td>10.0</td>\n",
              "      <td>9.55</td>\n",
              "      <td>19.68</td>\n",
              "      <td>27.73</td>\n",
              "      <td>32.0</td>\n",
              "      <td>43.3</td>\n",
              "      <td>52.0</td>\n",
              "      <td>29.89</td>\n",
              "      <td>37.6</td>\n",
              "      <td>0.28</td>\n",
              "      <td>9.4</td>\n",
              "      <td>18.87</td>\n",
              "      <td>36.94</td>\n",
              "      <td>48.33</td>\n",
              "      <td>32.0</td>\n",
              "      <td>40.1</td>\n",
              "      <td>51.1</td>\n",
              "      <td>29.87</td>\n",
              "      <td>34.9</td>\n",
              "      <td>0.00</td>\n",
              "      <td>10.0</td>\n",
              "      <td>9.67</td>\n",
              "      <td>18.30</td>\n",
              "      <td>25.32</td>\n",
              "      <td>37.0</td>\n",
              "      <td>43.6</td>\n",
              "      <td>53.1</td>\n",
              "      <td>29.48</td>\n",
              "      <td>37.1</td>\n",
              "      <td>0.01</td>\n",
              "      <td>10.0</td>\n",
              "      <td>8.75</td>\n",
              "      <td>17.26</td>\n",
              "      <td>26.47</td>\n",
              "      <td>Small</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3246</th>\n",
              "      <td>3247</td>\n",
              "      <td>2019</td>\n",
              "      <td>10</td>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "      <td>37.0</td>\n",
              "      <td>43.2</td>\n",
              "      <td>53.1</td>\n",
              "      <td>29.97</td>\n",
              "      <td>37.7</td>\n",
              "      <td>0.00</td>\n",
              "      <td>10.0</td>\n",
              "      <td>9.55</td>\n",
              "      <td>12.77</td>\n",
              "      <td>21.86</td>\n",
              "      <td>41.0</td>\n",
              "      <td>45.2</td>\n",
              "      <td>52.0</td>\n",
              "      <td>29.84</td>\n",
              "      <td>41.9</td>\n",
              "      <td>0.05</td>\n",
              "      <td>10.0</td>\n",
              "      <td>8.98</td>\n",
              "      <td>17.26</td>\n",
              "      <td>25.32</td>\n",
              "      <td>45.0</td>\n",
              "      <td>48.3</td>\n",
              "      <td>53.1</td>\n",
              "      <td>29.62</td>\n",
              "      <td>46.4</td>\n",
              "      <td>0.52</td>\n",
              "      <td>4.8</td>\n",
              "      <td>10.01</td>\n",
              "      <td>25.32</td>\n",
              "      <td>37.98</td>\n",
              "      <td>45.0</td>\n",
              "      <td>48.7</td>\n",
              "      <td>55.0</td>\n",
              "      <td>30.00</td>\n",
              "      <td>43.8</td>\n",
              "      <td>0.04</td>\n",
              "      <td>10.0</td>\n",
              "      <td>8.63</td>\n",
              "      <td>20.83</td>\n",
              "      <td>27.73</td>\n",
              "      <td>46.0</td>\n",
              "      <td>48.3</td>\n",
              "      <td>53.1</td>\n",
              "      <td>30.21</td>\n",
              "      <td>40.5</td>\n",
              "      <td>0.00</td>\n",
              "      <td>10.0</td>\n",
              "      <td>14.27</td>\n",
              "      <td>19.68</td>\n",
              "      <td>28.88</td>\n",
              "      <td>Small</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3247</th>\n",
              "      <td>3248</td>\n",
              "      <td>2019</td>\n",
              "      <td>10</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>42.8</td>\n",
              "      <td>46.4</td>\n",
              "      <td>51.8</td>\n",
              "      <td>29.95</td>\n",
              "      <td>42.1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>8.9</td>\n",
              "      <td>7.60</td>\n",
              "      <td>12.77</td>\n",
              "      <td>17.26</td>\n",
              "      <td>37.0</td>\n",
              "      <td>43.2</td>\n",
              "      <td>53.1</td>\n",
              "      <td>29.97</td>\n",
              "      <td>37.7</td>\n",
              "      <td>0.00</td>\n",
              "      <td>10.0</td>\n",
              "      <td>9.55</td>\n",
              "      <td>12.77</td>\n",
              "      <td>17.26</td>\n",
              "      <td>41.0</td>\n",
              "      <td>45.2</td>\n",
              "      <td>52.0</td>\n",
              "      <td>29.84</td>\n",
              "      <td>41.9</td>\n",
              "      <td>0.05</td>\n",
              "      <td>10.0</td>\n",
              "      <td>8.98</td>\n",
              "      <td>17.26</td>\n",
              "      <td>25.32</td>\n",
              "      <td>45.0</td>\n",
              "      <td>48.3</td>\n",
              "      <td>53.1</td>\n",
              "      <td>29.62</td>\n",
              "      <td>46.4</td>\n",
              "      <td>0.52</td>\n",
              "      <td>4.8</td>\n",
              "      <td>10.01</td>\n",
              "      <td>25.32</td>\n",
              "      <td>37.98</td>\n",
              "      <td>45.0</td>\n",
              "      <td>48.7</td>\n",
              "      <td>55.0</td>\n",
              "      <td>30.00</td>\n",
              "      <td>43.8</td>\n",
              "      <td>0.04</td>\n",
              "      <td>10.0</td>\n",
              "      <td>8.63</td>\n",
              "      <td>20.83</td>\n",
              "      <td>27.73</td>\n",
              "      <td>Small</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3248 rows × 56 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Unnamed: 0  FireSeason  ...  day4_MPH_max_wind  Fire_Severity\n",
              "0              1        1993  ...              20.71          Small\n",
              "1              2        1993  ...              16.11          Small\n",
              "2              3        1993  ...              17.26          Large\n",
              "3              4        1993  ...              17.26          Small\n",
              "4              5        1993  ...              25.32          Small\n",
              "...          ...         ...  ...                ...            ...\n",
              "3243        3244        2019  ...              33.26          Large\n",
              "3244        3245        2019  ...              26.35         Severe\n",
              "3245        3246        2019  ...              26.47          Small\n",
              "3246        3247        2019  ...              28.88          Small\n",
              "3247        3248        2019  ...              27.73          Small\n",
              "\n",
              "[3248 rows x 56 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-hBx2tJ1w56",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = df.drop(['Unnamed: 0','FireSeason','individual_fire_num'], axis=1)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZsYEnhH2Z6Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 150
        },
        "outputId": "70e97bde-5707-443d-be72-eb7e727cb8c6"
      },
      "source": [
        "label_col = df.pop('Fire_Severity')\n",
        "df.insert(0, 'label', label_col)\n",
        "print(df.head())"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   label  Month  ...  day4_MPH_max_sustained_wind  day4_MPH_max_wind\n",
            "0  Small      5  ...                        16.11              20.71\n",
            "1  Small      5  ...                        14.96              16.11\n",
            "2  Large      5  ...                        12.77              17.26\n",
            "3  Small      5  ...                        14.96              17.26\n",
            "4  Small      5  ...                        20.83              25.32\n",
            "\n",
            "[5 rows x 53 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jdk_3BTJqwPA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "cb166897-df80-45f6-d98b-84cf8f99cbad"
      },
      "source": [
        "print(df.columns.values.tolist())\n",
        "columns_list=df.columns.values.tolist()\n",
        "columns_xlist=columns_list[1:]\n",
        "print(columns_xlist)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['label', 'Month', 'PrepLevel', 'day0_F_min', 'day0_F_mean', 'day0_F_max', 'day0_IN_Sea_level', 'day0_F_Mean_dew_point', 'day0_IN_tot_rain', 'day0_MI_visibilty', 'day0_MPH_mean_wind_speed', 'day0_MPH_max_sustained_wind', 'day0_MPH_max_wind', 'day1_F_min', 'day1_F_mean', 'day1_F_max', 'day1_IN_Sea_level', 'day1_F_Mean_dew_point', 'day1_IN_tot_rain', 'day1_MI_visibilty', 'day1_MPH_mean_wind_speed', 'day1_MPH_max_sustained_wind', 'day1_MPH_max_wind', 'day2_F_min', 'day2_F_mean', 'day2_F_max', 'day2_IN_Sea_level', 'day2_F_Mean_dew_point', 'day2_IN_tot_rain', 'day2_MI_visibilty', 'day2_MPH_mean_wind_speed', 'day2_MPH_max_sustained_wind', 'day2_MPH_max_wind', 'day3_F_min', 'day3_F_mean', 'day3_F_max', 'day3_IN_Sea_level', 'day3_F_Mean_dew_point', 'day3_IN_tot_rain', 'day3_MI_visibilty', 'day3_MPH_mean_wind_speed', 'day3_MPH_max_sustained_wind', 'day3_MPH_max_wind', 'day4_F_min', 'day4_F_mean', 'day4_F_max', 'day4_IN_Sea_level', 'day4_F_Mean_dew_point', 'day4_IN_tot_rain', 'day4_MI_visibilty', 'day4_MPH_mean_wind_speed', 'day4_MPH_max_sustained_wind', 'day4_MPH_max_wind']\n",
            "['Month', 'PrepLevel', 'day0_F_min', 'day0_F_mean', 'day0_F_max', 'day0_IN_Sea_level', 'day0_F_Mean_dew_point', 'day0_IN_tot_rain', 'day0_MI_visibilty', 'day0_MPH_mean_wind_speed', 'day0_MPH_max_sustained_wind', 'day0_MPH_max_wind', 'day1_F_min', 'day1_F_mean', 'day1_F_max', 'day1_IN_Sea_level', 'day1_F_Mean_dew_point', 'day1_IN_tot_rain', 'day1_MI_visibilty', 'day1_MPH_mean_wind_speed', 'day1_MPH_max_sustained_wind', 'day1_MPH_max_wind', 'day2_F_min', 'day2_F_mean', 'day2_F_max', 'day2_IN_Sea_level', 'day2_F_Mean_dew_point', 'day2_IN_tot_rain', 'day2_MI_visibilty', 'day2_MPH_mean_wind_speed', 'day2_MPH_max_sustained_wind', 'day2_MPH_max_wind', 'day3_F_min', 'day3_F_mean', 'day3_F_max', 'day3_IN_Sea_level', 'day3_F_Mean_dew_point', 'day3_IN_tot_rain', 'day3_MI_visibilty', 'day3_MPH_mean_wind_speed', 'day3_MPH_max_sustained_wind', 'day3_MPH_max_wind', 'day4_F_min', 'day4_F_mean', 'day4_F_max', 'day4_IN_Sea_level', 'day4_F_Mean_dew_point', 'day4_IN_tot_rain', 'day4_MI_visibilty', 'day4_MPH_mean_wind_speed', 'day4_MPH_max_sustained_wind', 'day4_MPH_max_wind']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3Tv6NYKBaZH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "3b12efa1-fc00-4513-e692-6b8badc4ea37"
      },
      "source": [
        "print(df.shape)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3248, 53)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vXBgD66C7M3E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "outputId": "5ada0c9a-f4b2-4a9c-b31f-0fb081198eaf"
      },
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "sm = SMOTE(random_state=123)\n",
        "y=df['label']\n",
        "\n",
        "df_x=df.drop('label',axis=1)\n",
        "X_smote,y_smote = sm.fit_sample(df_x, y)\n",
        "\n",
        "print(type(X_smote))\n",
        "print(type(y_smote))\n",
        "\n",
        "\n",
        "df_x=pd.DataFrame(X_smote,columns=columns_xlist)\n",
        "df_y=pd.DataFrame(y_smote,columns=['label'])\n",
        "df=pd.concat([df_x,df_y],axis=1)\n",
        "print(df_x.shape)\n",
        "print(df_y.shape)\n",
        "print(df.head())"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "(4446, 52)\n",
            "(4446, 1)\n",
            "   Month  PrepLevel  ...  day4_MPH_max_wind  label\n",
            "0    5.0        1.0  ...              20.71  Small\n",
            "1    5.0        1.0  ...              16.11  Small\n",
            "2    5.0        1.0  ...              17.26  Large\n",
            "3    5.0        2.0  ...              17.26  Small\n",
            "4    5.0        1.0  ...              25.32  Small\n",
            "\n",
            "[5 rows x 53 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_8RWVU-2glE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df1=pd.get_dummies(df['label'])\n",
        "df=pd.concat([df,df1],axis=1)\n",
        "df.drop('label',axis=1,inplace=True)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtvXEsrLX8Fu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "outputId": "c727e9fe-77a2-4050-b203-2620a3e3ce86"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Month</th>\n",
              "      <th>PrepLevel</th>\n",
              "      <th>day0_F_min</th>\n",
              "      <th>day0_F_mean</th>\n",
              "      <th>day0_F_max</th>\n",
              "      <th>day0_IN_Sea_level</th>\n",
              "      <th>day0_F_Mean_dew_point</th>\n",
              "      <th>day0_IN_tot_rain</th>\n",
              "      <th>day0_MI_visibilty</th>\n",
              "      <th>day0_MPH_mean_wind_speed</th>\n",
              "      <th>day0_MPH_max_sustained_wind</th>\n",
              "      <th>day0_MPH_max_wind</th>\n",
              "      <th>day1_F_min</th>\n",
              "      <th>day1_F_mean</th>\n",
              "      <th>day1_F_max</th>\n",
              "      <th>day1_IN_Sea_level</th>\n",
              "      <th>day1_F_Mean_dew_point</th>\n",
              "      <th>day1_IN_tot_rain</th>\n",
              "      <th>day1_MI_visibilty</th>\n",
              "      <th>day1_MPH_mean_wind_speed</th>\n",
              "      <th>day1_MPH_max_sustained_wind</th>\n",
              "      <th>day1_MPH_max_wind</th>\n",
              "      <th>day2_F_min</th>\n",
              "      <th>day2_F_mean</th>\n",
              "      <th>day2_F_max</th>\n",
              "      <th>day2_IN_Sea_level</th>\n",
              "      <th>day2_F_Mean_dew_point</th>\n",
              "      <th>day2_IN_tot_rain</th>\n",
              "      <th>day2_MI_visibilty</th>\n",
              "      <th>day2_MPH_mean_wind_speed</th>\n",
              "      <th>day2_MPH_max_sustained_wind</th>\n",
              "      <th>day2_MPH_max_wind</th>\n",
              "      <th>day3_F_min</th>\n",
              "      <th>day3_F_mean</th>\n",
              "      <th>day3_F_max</th>\n",
              "      <th>day3_IN_Sea_level</th>\n",
              "      <th>day3_F_Mean_dew_point</th>\n",
              "      <th>day3_IN_tot_rain</th>\n",
              "      <th>day3_MI_visibilty</th>\n",
              "      <th>day3_MPH_mean_wind_speed</th>\n",
              "      <th>day3_MPH_max_sustained_wind</th>\n",
              "      <th>day3_MPH_max_wind</th>\n",
              "      <th>day4_F_min</th>\n",
              "      <th>day4_F_mean</th>\n",
              "      <th>day4_F_max</th>\n",
              "      <th>day4_IN_Sea_level</th>\n",
              "      <th>day4_F_Mean_dew_point</th>\n",
              "      <th>day4_IN_tot_rain</th>\n",
              "      <th>day4_MI_visibilty</th>\n",
              "      <th>day4_MPH_mean_wind_speed</th>\n",
              "      <th>day4_MPH_max_sustained_wind</th>\n",
              "      <th>day4_MPH_max_wind</th>\n",
              "      <th>Large</th>\n",
              "      <th>Severe</th>\n",
              "      <th>Small</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>43.9</td>\n",
              "      <td>53.1</td>\n",
              "      <td>29.86</td>\n",
              "      <td>37.3</td>\n",
              "      <td>0.00</td>\n",
              "      <td>26.8</td>\n",
              "      <td>8.75</td>\n",
              "      <td>13.81</td>\n",
              "      <td>17.26</td>\n",
              "      <td>34.9</td>\n",
              "      <td>42.0</td>\n",
              "      <td>52.0</td>\n",
              "      <td>29.55</td>\n",
              "      <td>32.9</td>\n",
              "      <td>0.00</td>\n",
              "      <td>31.4</td>\n",
              "      <td>11.62</td>\n",
              "      <td>17.26</td>\n",
              "      <td>20.71</td>\n",
              "      <td>29.8</td>\n",
              "      <td>36.9</td>\n",
              "      <td>44.1</td>\n",
              "      <td>29.83</td>\n",
              "      <td>28.7</td>\n",
              "      <td>0.00</td>\n",
              "      <td>35.1</td>\n",
              "      <td>9.09</td>\n",
              "      <td>16.11</td>\n",
              "      <td>19.56</td>\n",
              "      <td>23.9</td>\n",
              "      <td>30.4</td>\n",
              "      <td>37.9</td>\n",
              "      <td>30.12</td>\n",
              "      <td>22.2</td>\n",
              "      <td>0.00</td>\n",
              "      <td>28.2</td>\n",
              "      <td>10.24</td>\n",
              "      <td>14.96</td>\n",
              "      <td>17.26</td>\n",
              "      <td>23.0</td>\n",
              "      <td>27.4</td>\n",
              "      <td>41.9</td>\n",
              "      <td>29.97</td>\n",
              "      <td>21.3</td>\n",
              "      <td>0.00</td>\n",
              "      <td>17.9</td>\n",
              "      <td>13.00</td>\n",
              "      <td>16.11</td>\n",
              "      <td>20.71</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>38.8</td>\n",
              "      <td>48.1</td>\n",
              "      <td>55.9</td>\n",
              "      <td>30.07</td>\n",
              "      <td>39.7</td>\n",
              "      <td>0.00</td>\n",
              "      <td>29.8</td>\n",
              "      <td>8.75</td>\n",
              "      <td>12.77</td>\n",
              "      <td>19.68</td>\n",
              "      <td>34.0</td>\n",
              "      <td>43.9</td>\n",
              "      <td>53.1</td>\n",
              "      <td>29.86</td>\n",
              "      <td>37.3</td>\n",
              "      <td>0.00</td>\n",
              "      <td>26.8</td>\n",
              "      <td>8.75</td>\n",
              "      <td>13.81</td>\n",
              "      <td>24.17</td>\n",
              "      <td>34.9</td>\n",
              "      <td>42.0</td>\n",
              "      <td>52.0</td>\n",
              "      <td>29.55</td>\n",
              "      <td>32.9</td>\n",
              "      <td>0.00</td>\n",
              "      <td>31.4</td>\n",
              "      <td>11.62</td>\n",
              "      <td>17.26</td>\n",
              "      <td>20.71</td>\n",
              "      <td>29.8</td>\n",
              "      <td>36.9</td>\n",
              "      <td>44.1</td>\n",
              "      <td>29.83</td>\n",
              "      <td>28.7</td>\n",
              "      <td>0.00</td>\n",
              "      <td>35.1</td>\n",
              "      <td>9.09</td>\n",
              "      <td>16.11</td>\n",
              "      <td>19.56</td>\n",
              "      <td>23.9</td>\n",
              "      <td>30.4</td>\n",
              "      <td>37.9</td>\n",
              "      <td>30.12</td>\n",
              "      <td>22.2</td>\n",
              "      <td>0.00</td>\n",
              "      <td>28.2</td>\n",
              "      <td>10.24</td>\n",
              "      <td>14.96</td>\n",
              "      <td>16.11</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>42.1</td>\n",
              "      <td>49.0</td>\n",
              "      <td>59.9</td>\n",
              "      <td>29.93</td>\n",
              "      <td>42.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>39.4</td>\n",
              "      <td>9.67</td>\n",
              "      <td>14.96</td>\n",
              "      <td>17.26</td>\n",
              "      <td>45.9</td>\n",
              "      <td>53.0</td>\n",
              "      <td>59.0</td>\n",
              "      <td>29.79</td>\n",
              "      <td>39.9</td>\n",
              "      <td>0.00</td>\n",
              "      <td>53.4</td>\n",
              "      <td>11.28</td>\n",
              "      <td>19.68</td>\n",
              "      <td>20.71</td>\n",
              "      <td>32.9</td>\n",
              "      <td>44.8</td>\n",
              "      <td>55.9</td>\n",
              "      <td>29.98</td>\n",
              "      <td>35.2</td>\n",
              "      <td>0.12</td>\n",
              "      <td>36.0</td>\n",
              "      <td>9.09</td>\n",
              "      <td>14.96</td>\n",
              "      <td>16.11</td>\n",
              "      <td>38.8</td>\n",
              "      <td>46.1</td>\n",
              "      <td>57.0</td>\n",
              "      <td>29.99</td>\n",
              "      <td>38.7</td>\n",
              "      <td>0.08</td>\n",
              "      <td>24.9</td>\n",
              "      <td>10.93</td>\n",
              "      <td>22.79</td>\n",
              "      <td>26.47</td>\n",
              "      <td>38.8</td>\n",
              "      <td>48.1</td>\n",
              "      <td>55.9</td>\n",
              "      <td>30.07</td>\n",
              "      <td>39.7</td>\n",
              "      <td>0.00</td>\n",
              "      <td>29.8</td>\n",
              "      <td>8.75</td>\n",
              "      <td>12.77</td>\n",
              "      <td>17.26</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>39.9</td>\n",
              "      <td>49.2</td>\n",
              "      <td>60.1</td>\n",
              "      <td>29.57</td>\n",
              "      <td>37.8</td>\n",
              "      <td>0.00</td>\n",
              "      <td>32.5</td>\n",
              "      <td>15.08</td>\n",
              "      <td>21.86</td>\n",
              "      <td>26.47</td>\n",
              "      <td>36.0</td>\n",
              "      <td>42.4</td>\n",
              "      <td>54.9</td>\n",
              "      <td>30.03</td>\n",
              "      <td>34.5</td>\n",
              "      <td>0.12</td>\n",
              "      <td>32.3</td>\n",
              "      <td>12.89</td>\n",
              "      <td>20.83</td>\n",
              "      <td>25.32</td>\n",
              "      <td>42.1</td>\n",
              "      <td>49.3</td>\n",
              "      <td>61.0</td>\n",
              "      <td>29.97</td>\n",
              "      <td>39.3</td>\n",
              "      <td>0.13</td>\n",
              "      <td>33.7</td>\n",
              "      <td>13.12</td>\n",
              "      <td>18.30</td>\n",
              "      <td>20.71</td>\n",
              "      <td>38.8</td>\n",
              "      <td>45.3</td>\n",
              "      <td>55.0</td>\n",
              "      <td>30.18</td>\n",
              "      <td>36.8</td>\n",
              "      <td>0.00</td>\n",
              "      <td>36.0</td>\n",
              "      <td>8.17</td>\n",
              "      <td>13.81</td>\n",
              "      <td>16.11</td>\n",
              "      <td>42.1</td>\n",
              "      <td>49.0</td>\n",
              "      <td>59.9</td>\n",
              "      <td>29.93</td>\n",
              "      <td>42.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>39.4</td>\n",
              "      <td>9.67</td>\n",
              "      <td>14.96</td>\n",
              "      <td>17.26</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>43.0</td>\n",
              "      <td>50.7</td>\n",
              "      <td>56.8</td>\n",
              "      <td>29.88</td>\n",
              "      <td>40.5</td>\n",
              "      <td>0.01</td>\n",
              "      <td>38.1</td>\n",
              "      <td>12.77</td>\n",
              "      <td>21.86</td>\n",
              "      <td>21.86</td>\n",
              "      <td>41.0</td>\n",
              "      <td>50.3</td>\n",
              "      <td>55.9</td>\n",
              "      <td>29.97</td>\n",
              "      <td>39.4</td>\n",
              "      <td>0.05</td>\n",
              "      <td>41.8</td>\n",
              "      <td>9.32</td>\n",
              "      <td>17.26</td>\n",
              "      <td>25.32</td>\n",
              "      <td>43.9</td>\n",
              "      <td>50.7</td>\n",
              "      <td>61.0</td>\n",
              "      <td>29.49</td>\n",
              "      <td>37.1</td>\n",
              "      <td>0.04</td>\n",
              "      <td>31.7</td>\n",
              "      <td>14.38</td>\n",
              "      <td>20.83</td>\n",
              "      <td>25.32</td>\n",
              "      <td>39.9</td>\n",
              "      <td>49.2</td>\n",
              "      <td>60.1</td>\n",
              "      <td>29.57</td>\n",
              "      <td>37.8</td>\n",
              "      <td>0.00</td>\n",
              "      <td>32.5</td>\n",
              "      <td>15.08</td>\n",
              "      <td>21.86</td>\n",
              "      <td>26.47</td>\n",
              "      <td>36.0</td>\n",
              "      <td>42.4</td>\n",
              "      <td>54.9</td>\n",
              "      <td>30.03</td>\n",
              "      <td>34.5</td>\n",
              "      <td>0.12</td>\n",
              "      <td>32.3</td>\n",
              "      <td>12.89</td>\n",
              "      <td>20.83</td>\n",
              "      <td>25.32</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Month  PrepLevel  day0_F_min  ...  Large  Severe  Small\n",
              "0    5.0        1.0        34.0  ...      0       0      1\n",
              "1    5.0        1.0        38.8  ...      0       0      1\n",
              "2    5.0        1.0        42.1  ...      1       0      0\n",
              "3    5.0        2.0        39.9  ...      0       0      1\n",
              "4    5.0        1.0        43.0  ...      0       0      1\n",
              "\n",
              "[5 rows x 55 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SWZZl2XM23ch",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "402d0c38-da9f-4537-d617-8c4a1477337e"
      },
      "source": [
        "Y=df[['Large','Small','Severe']].values\n",
        "df.drop(['Large','Small','Severe'],axis=1,inplace=True)\n",
        "print(Y.shape)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4446, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDkhDquo291L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        },
        "outputId": "d65cb962-c059-42dc-8786-58f130445d58"
      },
      "source": [
        "X=df.values\n",
        "X"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 5.        ,  1.        , 34.        , ..., 13.        ,\n",
              "        16.11      , 20.71      ],\n",
              "       [ 5.        ,  1.        , 38.8       , ..., 10.24      ,\n",
              "        14.96      , 16.11      ],\n",
              "       [ 5.        ,  1.        , 42.1       , ...,  8.75      ,\n",
              "        12.77      , 17.26      ],\n",
              "       ...,\n",
              "       [ 9.        ,  2.        , 48.12427911, ..., 14.5012136 ,\n",
              "        26.04896837, 32.71297382],\n",
              "       [ 7.13514833,  3.13514833, 47.64596507, ..., 10.85755464,\n",
              "        18.15104995, 24.66728971],\n",
              "       [ 9.        ,  1.        , 37.5659263 , ..., 11.47339248,\n",
              "        17.12101253, 25.18101253]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5B_b-t03Bwr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "dc11dcfe-3480-4705-dc5c-7d1a7c6efb44"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "x_data=scaler.fit_transform(X)\n",
        "x_data.shape"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4446, 52)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-0F95Cwx3IsA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def time_seq_arrange(mat_X): # 1st and 2nd column are normalized month and perp level values,next 10 cols are records for day 0 and so on\n",
        "    month_and_prep = mat_X[:,:2]\n",
        "    day_0 = mat_X[:,2:12]\n",
        "    day_1 = mat_X[:,12:22]\n",
        "    day_2 = mat_X[:,22:32]\n",
        "    day_3 = mat_X[:,32:42]\n",
        "    day_4 = mat_X[:,42:]\n",
        "    \n",
        "    output_0 = np.concatenate((month_and_prep,day_4),axis=1)\n",
        "    output_1 = np.concatenate((month_and_prep,day_3),axis=1)\n",
        "    output_2 = np.concatenate((month_and_prep,day_2),axis=1)\n",
        "    output_3 = np.concatenate((month_and_prep,day_1),axis=1)\n",
        "    output_4 = np.concatenate((month_and_prep,day_0),axis=1)\n",
        "    \n",
        "    output = np.concatenate((output_0,output_1,output_2,output_3,output_4),axis=1)\n",
        "    \n",
        "    return output"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWXMSdNZ3LrG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "c6d1b1c6-c88c-4ddf-addc-310d5028a375"
      },
      "source": [
        "final=time_seq_arrange(x_data)\n",
        "reshaped=np.reshape(final, ( -1,5,12))\n",
        "print(reshaped.shape)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4446, 5, 12)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UeEwNwsy3Ykv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_val, Y_train, Y_val = train_test_split(reshaped, Y, test_size=0.20, random_state=42)\n",
        "##X_train, X_test, Y_train, Y_test = train_test_split(X_train, Y_train, test_size=0.10, random_state=42)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDEDZGVR3dXx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "88219191-ca82-4aca-d030-adc2c7cf46b2"
      },
      "source": [
        "import numpy\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.preprocessing import sequence\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(6, activation='relu', return_sequences=False))\n",
        "##model.add(LSTM(6, activation='relu', return_sequences=True,input_shape=(5, 12)))\n",
        "model.add(Dense(3,activation='sigmoid'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FA0LojYK3oMo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "abab2025-c8a8-4262-a465-747e9ff07638"
      },
      "source": [
        "history=model.fit(X_train, Y_train, validation_data=(X_val,Y_val), epochs=2000, batch_size=64)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2000\n",
            "56/56 [==============================] - 1s 16ms/step - loss: 1.1020 - accuracy: 0.2829 - val_loss: 1.0951 - val_accuracy: 0.2989\n",
            "Epoch 2/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 1.0880 - accuracy: 0.3206 - val_loss: 1.0779 - val_accuracy: 0.3978\n",
            "Epoch 3/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 1.0613 - accuracy: 0.4542 - val_loss: 1.0368 - val_accuracy: 0.5281\n",
            "Epoch 4/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 1.0057 - accuracy: 0.5222 - val_loss: 0.9733 - val_accuracy: 0.5640\n",
            "Epoch 5/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.9436 - accuracy: 0.5596 - val_loss: 0.9197 - val_accuracy: 0.5663\n",
            "Epoch 6/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.9095 - accuracy: 0.5681 - val_loss: 0.8988 - val_accuracy: 0.5607\n",
            "Epoch 7/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.8991 - accuracy: 0.5773 - val_loss: 0.8960 - val_accuracy: 0.5876\n",
            "Epoch 8/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.8954 - accuracy: 0.5785 - val_loss: 0.8897 - val_accuracy: 0.5843\n",
            "Epoch 9/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.8912 - accuracy: 0.5779 - val_loss: 0.8978 - val_accuracy: 0.5708\n",
            "Epoch 10/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.8860 - accuracy: 0.5869 - val_loss: 0.8922 - val_accuracy: 0.5787\n",
            "Epoch 11/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.8835 - accuracy: 0.5889 - val_loss: 0.8848 - val_accuracy: 0.5798\n",
            "Epoch 12/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.8825 - accuracy: 0.5920 - val_loss: 0.8781 - val_accuracy: 0.5854\n",
            "Epoch 13/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.8801 - accuracy: 0.5942 - val_loss: 0.8790 - val_accuracy: 0.5843\n",
            "Epoch 14/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8777 - accuracy: 0.5976 - val_loss: 0.8747 - val_accuracy: 0.5899\n",
            "Epoch 15/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.8750 - accuracy: 0.6010 - val_loss: 0.8835 - val_accuracy: 0.5921\n",
            "Epoch 16/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.8754 - accuracy: 0.6004 - val_loss: 0.8881 - val_accuracy: 0.5753\n",
            "Epoch 17/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.8728 - accuracy: 0.5939 - val_loss: 0.8760 - val_accuracy: 0.5888\n",
            "Epoch 18/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.8719 - accuracy: 0.6074 - val_loss: 0.8767 - val_accuracy: 0.5888\n",
            "Epoch 19/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.8687 - accuracy: 0.6071 - val_loss: 0.8753 - val_accuracy: 0.6000\n",
            "Epoch 20/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.8687 - accuracy: 0.6021 - val_loss: 0.8795 - val_accuracy: 0.5944\n",
            "Epoch 21/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.8680 - accuracy: 0.6077 - val_loss: 0.8728 - val_accuracy: 0.5933\n",
            "Epoch 22/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8664 - accuracy: 0.6049 - val_loss: 0.8794 - val_accuracy: 0.5798\n",
            "Epoch 23/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8673 - accuracy: 0.6026 - val_loss: 0.8719 - val_accuracy: 0.5933\n",
            "Epoch 24/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8636 - accuracy: 0.6012 - val_loss: 0.8775 - val_accuracy: 0.5989\n",
            "Epoch 25/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8641 - accuracy: 0.6066 - val_loss: 0.8763 - val_accuracy: 0.5955\n",
            "Epoch 26/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8659 - accuracy: 0.6007 - val_loss: 0.8757 - val_accuracy: 0.5978\n",
            "Epoch 27/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8667 - accuracy: 0.6004 - val_loss: 0.8671 - val_accuracy: 0.5933\n",
            "Epoch 28/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8619 - accuracy: 0.6102 - val_loss: 0.8635 - val_accuracy: 0.5944\n",
            "Epoch 29/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8592 - accuracy: 0.6122 - val_loss: 0.8639 - val_accuracy: 0.6180\n",
            "Epoch 30/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8599 - accuracy: 0.6085 - val_loss: 0.8647 - val_accuracy: 0.6011\n",
            "Epoch 31/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8609 - accuracy: 0.6032 - val_loss: 0.8700 - val_accuracy: 0.6022\n",
            "Epoch 32/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8591 - accuracy: 0.6083 - val_loss: 0.8677 - val_accuracy: 0.5955\n",
            "Epoch 33/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8583 - accuracy: 0.6080 - val_loss: 0.8730 - val_accuracy: 0.5899\n",
            "Epoch 34/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8540 - accuracy: 0.6097 - val_loss: 0.8621 - val_accuracy: 0.5989\n",
            "Epoch 35/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8562 - accuracy: 0.6114 - val_loss: 0.8589 - val_accuracy: 0.6022\n",
            "Epoch 36/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8546 - accuracy: 0.6125 - val_loss: 0.8643 - val_accuracy: 0.5955\n",
            "Epoch 37/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8542 - accuracy: 0.6122 - val_loss: 0.8601 - val_accuracy: 0.5989\n",
            "Epoch 38/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8556 - accuracy: 0.6024 - val_loss: 0.8576 - val_accuracy: 0.6000\n",
            "Epoch 39/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8536 - accuracy: 0.6125 - val_loss: 0.8679 - val_accuracy: 0.5989\n",
            "Epoch 40/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8517 - accuracy: 0.6142 - val_loss: 0.8656 - val_accuracy: 0.6034\n",
            "Epoch 41/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8485 - accuracy: 0.6173 - val_loss: 0.8584 - val_accuracy: 0.6011\n",
            "Epoch 42/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8480 - accuracy: 0.6195 - val_loss: 0.8608 - val_accuracy: 0.5910\n",
            "Epoch 43/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8480 - accuracy: 0.6192 - val_loss: 0.8588 - val_accuracy: 0.6000\n",
            "Epoch 44/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8473 - accuracy: 0.6159 - val_loss: 0.8604 - val_accuracy: 0.6090\n",
            "Epoch 45/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8468 - accuracy: 0.6181 - val_loss: 0.8535 - val_accuracy: 0.6247\n",
            "Epoch 46/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8499 - accuracy: 0.6136 - val_loss: 0.8579 - val_accuracy: 0.6135\n",
            "Epoch 47/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8478 - accuracy: 0.6206 - val_loss: 0.8605 - val_accuracy: 0.6090\n",
            "Epoch 48/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8470 - accuracy: 0.6161 - val_loss: 0.8691 - val_accuracy: 0.5899\n",
            "Epoch 49/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8448 - accuracy: 0.6215 - val_loss: 0.8553 - val_accuracy: 0.6034\n",
            "Epoch 50/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8439 - accuracy: 0.6164 - val_loss: 0.8556 - val_accuracy: 0.6124\n",
            "Epoch 51/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8441 - accuracy: 0.6212 - val_loss: 0.8692 - val_accuracy: 0.5876\n",
            "Epoch 52/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8441 - accuracy: 0.6195 - val_loss: 0.8511 - val_accuracy: 0.6258\n",
            "Epoch 53/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8426 - accuracy: 0.6243 - val_loss: 0.8497 - val_accuracy: 0.6213\n",
            "Epoch 54/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8425 - accuracy: 0.6249 - val_loss: 0.8503 - val_accuracy: 0.6191\n",
            "Epoch 55/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8407 - accuracy: 0.6226 - val_loss: 0.8632 - val_accuracy: 0.6000\n",
            "Epoch 56/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8422 - accuracy: 0.6285 - val_loss: 0.8896 - val_accuracy: 0.5978\n",
            "Epoch 57/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8467 - accuracy: 0.6246 - val_loss: 0.8687 - val_accuracy: 0.5910\n",
            "Epoch 58/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8397 - accuracy: 0.6204 - val_loss: 0.8589 - val_accuracy: 0.6034\n",
            "Epoch 59/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8402 - accuracy: 0.6263 - val_loss: 0.8500 - val_accuracy: 0.6169\n",
            "Epoch 60/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8372 - accuracy: 0.6187 - val_loss: 0.8655 - val_accuracy: 0.5921\n",
            "Epoch 61/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.8394 - accuracy: 0.6240 - val_loss: 0.8603 - val_accuracy: 0.5966\n",
            "Epoch 62/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8389 - accuracy: 0.6235 - val_loss: 0.8518 - val_accuracy: 0.6213\n",
            "Epoch 63/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8415 - accuracy: 0.6201 - val_loss: 0.8489 - val_accuracy: 0.6191\n",
            "Epoch 64/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8367 - accuracy: 0.6299 - val_loss: 0.8707 - val_accuracy: 0.5854\n",
            "Epoch 65/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8406 - accuracy: 0.6192 - val_loss: 0.8479 - val_accuracy: 0.6247\n",
            "Epoch 66/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.8404 - accuracy: 0.6204 - val_loss: 0.8483 - val_accuracy: 0.6202\n",
            "Epoch 67/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8355 - accuracy: 0.6254 - val_loss: 0.8605 - val_accuracy: 0.6011\n",
            "Epoch 68/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8367 - accuracy: 0.6277 - val_loss: 0.8514 - val_accuracy: 0.6090\n",
            "Epoch 69/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8358 - accuracy: 0.6308 - val_loss: 0.8650 - val_accuracy: 0.5978\n",
            "Epoch 70/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8375 - accuracy: 0.6254 - val_loss: 0.8575 - val_accuracy: 0.6011\n",
            "Epoch 71/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.8373 - accuracy: 0.6229 - val_loss: 0.8547 - val_accuracy: 0.6056\n",
            "Epoch 72/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8381 - accuracy: 0.6310 - val_loss: 0.8513 - val_accuracy: 0.6101\n",
            "Epoch 73/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8335 - accuracy: 0.6265 - val_loss: 0.8472 - val_accuracy: 0.6213\n",
            "Epoch 74/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8339 - accuracy: 0.6280 - val_loss: 0.8499 - val_accuracy: 0.6146\n",
            "Epoch 75/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8321 - accuracy: 0.6330 - val_loss: 0.8599 - val_accuracy: 0.6022\n",
            "Epoch 76/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8342 - accuracy: 0.6249 - val_loss: 0.8600 - val_accuracy: 0.6157\n",
            "Epoch 77/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8360 - accuracy: 0.6263 - val_loss: 0.8584 - val_accuracy: 0.6045\n",
            "Epoch 78/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8351 - accuracy: 0.6294 - val_loss: 0.8515 - val_accuracy: 0.6191\n",
            "Epoch 79/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8309 - accuracy: 0.6316 - val_loss: 0.8479 - val_accuracy: 0.6112\n",
            "Epoch 80/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8339 - accuracy: 0.6319 - val_loss: 0.8511 - val_accuracy: 0.6090\n",
            "Epoch 81/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8365 - accuracy: 0.6229 - val_loss: 0.8460 - val_accuracy: 0.6157\n",
            "Epoch 82/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8331 - accuracy: 0.6302 - val_loss: 0.8525 - val_accuracy: 0.6124\n",
            "Epoch 83/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8396 - accuracy: 0.6288 - val_loss: 0.8521 - val_accuracy: 0.6022\n",
            "Epoch 84/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8334 - accuracy: 0.6237 - val_loss: 0.8725 - val_accuracy: 0.5966\n",
            "Epoch 85/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8328 - accuracy: 0.6316 - val_loss: 0.8531 - val_accuracy: 0.6124\n",
            "Epoch 86/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8324 - accuracy: 0.6392 - val_loss: 0.8516 - val_accuracy: 0.6112\n",
            "Epoch 87/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8309 - accuracy: 0.6361 - val_loss: 0.8453 - val_accuracy: 0.6213\n",
            "Epoch 88/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8314 - accuracy: 0.6282 - val_loss: 0.8454 - val_accuracy: 0.6180\n",
            "Epoch 89/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8306 - accuracy: 0.6339 - val_loss: 0.8518 - val_accuracy: 0.6011\n",
            "Epoch 90/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8318 - accuracy: 0.6353 - val_loss: 0.8479 - val_accuracy: 0.6124\n",
            "Epoch 91/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.8353 - accuracy: 0.6254 - val_loss: 0.8437 - val_accuracy: 0.6258\n",
            "Epoch 92/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8313 - accuracy: 0.6347 - val_loss: 0.8451 - val_accuracy: 0.6213\n",
            "Epoch 93/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8327 - accuracy: 0.6319 - val_loss: 0.8571 - val_accuracy: 0.5955\n",
            "Epoch 94/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8306 - accuracy: 0.6280 - val_loss: 0.8911 - val_accuracy: 0.5831\n",
            "Epoch 95/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8338 - accuracy: 0.6263 - val_loss: 0.8633 - val_accuracy: 0.5921\n",
            "Epoch 96/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8330 - accuracy: 0.6339 - val_loss: 0.8453 - val_accuracy: 0.6146\n",
            "Epoch 97/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8274 - accuracy: 0.6344 - val_loss: 0.8610 - val_accuracy: 0.5899\n",
            "Epoch 98/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8290 - accuracy: 0.6327 - val_loss: 0.8469 - val_accuracy: 0.6034\n",
            "Epoch 99/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8296 - accuracy: 0.6319 - val_loss: 0.8592 - val_accuracy: 0.5989\n",
            "Epoch 100/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8318 - accuracy: 0.6263 - val_loss: 0.8532 - val_accuracy: 0.5910\n",
            "Epoch 101/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8263 - accuracy: 0.6375 - val_loss: 0.8444 - val_accuracy: 0.6180\n",
            "Epoch 102/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8278 - accuracy: 0.6353 - val_loss: 0.8448 - val_accuracy: 0.6157\n",
            "Epoch 103/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8311 - accuracy: 0.6263 - val_loss: 0.8426 - val_accuracy: 0.6180\n",
            "Epoch 104/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.8278 - accuracy: 0.6344 - val_loss: 0.8568 - val_accuracy: 0.5921\n",
            "Epoch 105/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8281 - accuracy: 0.6339 - val_loss: 0.8610 - val_accuracy: 0.5944\n",
            "Epoch 106/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8269 - accuracy: 0.6330 - val_loss: 0.8470 - val_accuracy: 0.6124\n",
            "Epoch 107/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8264 - accuracy: 0.6386 - val_loss: 0.8472 - val_accuracy: 0.6146\n",
            "Epoch 108/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8282 - accuracy: 0.6389 - val_loss: 0.8620 - val_accuracy: 0.5944\n",
            "Epoch 109/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8290 - accuracy: 0.6310 - val_loss: 0.8426 - val_accuracy: 0.6180\n",
            "Epoch 110/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8344 - accuracy: 0.6237 - val_loss: 0.8515 - val_accuracy: 0.5989\n",
            "Epoch 111/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8264 - accuracy: 0.6330 - val_loss: 0.8467 - val_accuracy: 0.6045\n",
            "Epoch 112/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.8271 - accuracy: 0.6339 - val_loss: 0.8522 - val_accuracy: 0.5955\n",
            "Epoch 113/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8256 - accuracy: 0.6325 - val_loss: 0.8502 - val_accuracy: 0.5978\n",
            "Epoch 114/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.8279 - accuracy: 0.6361 - val_loss: 0.8551 - val_accuracy: 0.6011\n",
            "Epoch 115/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8316 - accuracy: 0.6302 - val_loss: 0.8602 - val_accuracy: 0.5978\n",
            "Epoch 116/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8278 - accuracy: 0.6333 - val_loss: 0.8497 - val_accuracy: 0.6022\n",
            "Epoch 117/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8252 - accuracy: 0.6367 - val_loss: 0.8523 - val_accuracy: 0.6011\n",
            "Epoch 118/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.8260 - accuracy: 0.6386 - val_loss: 0.8579 - val_accuracy: 0.6000\n",
            "Epoch 119/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8231 - accuracy: 0.6417 - val_loss: 0.8403 - val_accuracy: 0.6213\n",
            "Epoch 120/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.8255 - accuracy: 0.6381 - val_loss: 0.8634 - val_accuracy: 0.6000\n",
            "Epoch 121/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8241 - accuracy: 0.6375 - val_loss: 0.8485 - val_accuracy: 0.5966\n",
            "Epoch 122/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8270 - accuracy: 0.6322 - val_loss: 0.8554 - val_accuracy: 0.6079\n",
            "Epoch 123/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8254 - accuracy: 0.6355 - val_loss: 0.8474 - val_accuracy: 0.6056\n",
            "Epoch 124/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8241 - accuracy: 0.6327 - val_loss: 0.8466 - val_accuracy: 0.6191\n",
            "Epoch 125/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8260 - accuracy: 0.6333 - val_loss: 0.8405 - val_accuracy: 0.6180\n",
            "Epoch 126/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8249 - accuracy: 0.6367 - val_loss: 0.8529 - val_accuracy: 0.6034\n",
            "Epoch 127/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8243 - accuracy: 0.6372 - val_loss: 0.8565 - val_accuracy: 0.5966\n",
            "Epoch 128/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8239 - accuracy: 0.6409 - val_loss: 0.8435 - val_accuracy: 0.6146\n",
            "Epoch 129/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.8232 - accuracy: 0.6412 - val_loss: 0.8457 - val_accuracy: 0.6067\n",
            "Epoch 130/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8228 - accuracy: 0.6358 - val_loss: 0.8404 - val_accuracy: 0.6169\n",
            "Epoch 131/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8300 - accuracy: 0.6251 - val_loss: 0.8460 - val_accuracy: 0.6124\n",
            "Epoch 132/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8224 - accuracy: 0.6381 - val_loss: 0.8435 - val_accuracy: 0.6090\n",
            "Epoch 133/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8237 - accuracy: 0.6400 - val_loss: 0.8496 - val_accuracy: 0.6101\n",
            "Epoch 134/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8226 - accuracy: 0.6412 - val_loss: 0.8429 - val_accuracy: 0.6191\n",
            "Epoch 135/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8236 - accuracy: 0.6333 - val_loss: 0.8399 - val_accuracy: 0.6213\n",
            "Epoch 136/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.8247 - accuracy: 0.6375 - val_loss: 0.8414 - val_accuracy: 0.6202\n",
            "Epoch 137/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8259 - accuracy: 0.6322 - val_loss: 0.8517 - val_accuracy: 0.5989\n",
            "Epoch 138/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8203 - accuracy: 0.6420 - val_loss: 0.8396 - val_accuracy: 0.6202\n",
            "Epoch 139/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8231 - accuracy: 0.6344 - val_loss: 0.8579 - val_accuracy: 0.6000\n",
            "Epoch 140/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.8233 - accuracy: 0.6353 - val_loss: 0.8420 - val_accuracy: 0.6146\n",
            "Epoch 141/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8227 - accuracy: 0.6355 - val_loss: 0.8643 - val_accuracy: 0.5978\n",
            "Epoch 142/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.8244 - accuracy: 0.6355 - val_loss: 0.8408 - val_accuracy: 0.6146\n",
            "Epoch 143/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.8207 - accuracy: 0.6350 - val_loss: 0.8574 - val_accuracy: 0.5978\n",
            "Epoch 144/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8209 - accuracy: 0.6367 - val_loss: 0.8442 - val_accuracy: 0.6079\n",
            "Epoch 145/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.8213 - accuracy: 0.6347 - val_loss: 0.8417 - val_accuracy: 0.6124\n",
            "Epoch 146/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.8208 - accuracy: 0.6400 - val_loss: 0.8399 - val_accuracy: 0.6135\n",
            "Epoch 147/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8207 - accuracy: 0.6353 - val_loss: 0.8542 - val_accuracy: 0.5966\n",
            "Epoch 148/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.8236 - accuracy: 0.6291 - val_loss: 0.8576 - val_accuracy: 0.6000\n",
            "Epoch 149/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8233 - accuracy: 0.6330 - val_loss: 0.8446 - val_accuracy: 0.6034\n",
            "Epoch 150/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8207 - accuracy: 0.6423 - val_loss: 0.8412 - val_accuracy: 0.6180\n",
            "Epoch 151/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.8238 - accuracy: 0.6336 - val_loss: 0.8416 - val_accuracy: 0.6124\n",
            "Epoch 152/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.8203 - accuracy: 0.6412 - val_loss: 0.8426 - val_accuracy: 0.6180\n",
            "Epoch 153/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8199 - accuracy: 0.6353 - val_loss: 0.8421 - val_accuracy: 0.6191\n",
            "Epoch 154/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8188 - accuracy: 0.6417 - val_loss: 0.8471 - val_accuracy: 0.5989\n",
            "Epoch 155/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8193 - accuracy: 0.6395 - val_loss: 0.8642 - val_accuracy: 0.6022\n",
            "Epoch 156/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.8229 - accuracy: 0.6358 - val_loss: 0.8377 - val_accuracy: 0.6247\n",
            "Epoch 157/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.8210 - accuracy: 0.6361 - val_loss: 0.8531 - val_accuracy: 0.6169\n",
            "Epoch 158/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8200 - accuracy: 0.6392 - val_loss: 0.8391 - val_accuracy: 0.6213\n",
            "Epoch 159/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8194 - accuracy: 0.6367 - val_loss: 0.8419 - val_accuracy: 0.6067\n",
            "Epoch 160/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8170 - accuracy: 0.6412 - val_loss: 0.8427 - val_accuracy: 0.6112\n",
            "Epoch 161/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8209 - accuracy: 0.6403 - val_loss: 0.8402 - val_accuracy: 0.6169\n",
            "Epoch 162/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.8170 - accuracy: 0.6398 - val_loss: 0.8418 - val_accuracy: 0.6135\n",
            "Epoch 163/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.8169 - accuracy: 0.6398 - val_loss: 0.8445 - val_accuracy: 0.6112\n",
            "Epoch 164/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.8184 - accuracy: 0.6367 - val_loss: 0.8511 - val_accuracy: 0.6011\n",
            "Epoch 165/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8226 - accuracy: 0.6339 - val_loss: 0.8371 - val_accuracy: 0.6202\n",
            "Epoch 166/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8184 - accuracy: 0.6361 - val_loss: 0.8425 - val_accuracy: 0.6112\n",
            "Epoch 167/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8193 - accuracy: 0.6364 - val_loss: 0.8451 - val_accuracy: 0.6067\n",
            "Epoch 168/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.8152 - accuracy: 0.6440 - val_loss: 0.8473 - val_accuracy: 0.6034\n",
            "Epoch 169/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8182 - accuracy: 0.6403 - val_loss: 0.8526 - val_accuracy: 0.6000\n",
            "Epoch 170/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8183 - accuracy: 0.6370 - val_loss: 0.8380 - val_accuracy: 0.6180\n",
            "Epoch 171/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.8152 - accuracy: 0.6386 - val_loss: 0.8445 - val_accuracy: 0.6124\n",
            "Epoch 172/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8169 - accuracy: 0.6378 - val_loss: 0.8484 - val_accuracy: 0.6022\n",
            "Epoch 173/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8179 - accuracy: 0.6384 - val_loss: 0.8465 - val_accuracy: 0.6022\n",
            "Epoch 174/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.8152 - accuracy: 0.6403 - val_loss: 0.8713 - val_accuracy: 0.5944\n",
            "Epoch 175/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.8255 - accuracy: 0.6336 - val_loss: 0.8406 - val_accuracy: 0.6135\n",
            "Epoch 176/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.8160 - accuracy: 0.6319 - val_loss: 0.8515 - val_accuracy: 0.6034\n",
            "Epoch 177/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.8180 - accuracy: 0.6386 - val_loss: 0.8396 - val_accuracy: 0.6202\n",
            "Epoch 178/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8131 - accuracy: 0.6412 - val_loss: 0.8400 - val_accuracy: 0.6146\n",
            "Epoch 179/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.8187 - accuracy: 0.6367 - val_loss: 0.8388 - val_accuracy: 0.6180\n",
            "Epoch 180/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8223 - accuracy: 0.6375 - val_loss: 0.8432 - val_accuracy: 0.6067\n",
            "Epoch 181/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8221 - accuracy: 0.6305 - val_loss: 0.8605 - val_accuracy: 0.5955\n",
            "Epoch 182/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.8170 - accuracy: 0.6395 - val_loss: 0.8398 - val_accuracy: 0.6112\n",
            "Epoch 183/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8145 - accuracy: 0.6462 - val_loss: 0.8393 - val_accuracy: 0.6202\n",
            "Epoch 184/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.8151 - accuracy: 0.6370 - val_loss: 0.8560 - val_accuracy: 0.5955\n",
            "Epoch 185/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8191 - accuracy: 0.6350 - val_loss: 0.8556 - val_accuracy: 0.6067\n",
            "Epoch 186/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.8152 - accuracy: 0.6434 - val_loss: 0.8402 - val_accuracy: 0.6112\n",
            "Epoch 187/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.8132 - accuracy: 0.6386 - val_loss: 0.8469 - val_accuracy: 0.6090\n",
            "Epoch 188/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8176 - accuracy: 0.6415 - val_loss: 0.8364 - val_accuracy: 0.6157\n",
            "Epoch 189/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8149 - accuracy: 0.6386 - val_loss: 0.8447 - val_accuracy: 0.6056\n",
            "Epoch 190/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.8173 - accuracy: 0.6358 - val_loss: 0.8372 - val_accuracy: 0.6225\n",
            "Epoch 191/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8141 - accuracy: 0.6398 - val_loss: 0.8427 - val_accuracy: 0.6101\n",
            "Epoch 192/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.8113 - accuracy: 0.6389 - val_loss: 0.8438 - val_accuracy: 0.6124\n",
            "Epoch 193/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.8195 - accuracy: 0.6367 - val_loss: 0.8521 - val_accuracy: 0.5978\n",
            "Epoch 194/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.8152 - accuracy: 0.6412 - val_loss: 0.8380 - val_accuracy: 0.6202\n",
            "Epoch 195/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.8140 - accuracy: 0.6389 - val_loss: 0.8375 - val_accuracy: 0.6202\n",
            "Epoch 196/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.8142 - accuracy: 0.6406 - val_loss: 0.8383 - val_accuracy: 0.6124\n",
            "Epoch 197/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.8128 - accuracy: 0.6339 - val_loss: 0.8445 - val_accuracy: 0.5978\n",
            "Epoch 198/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8104 - accuracy: 0.6440 - val_loss: 0.8345 - val_accuracy: 0.6236\n",
            "Epoch 199/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.8095 - accuracy: 0.6451 - val_loss: 0.8450 - val_accuracy: 0.5989\n",
            "Epoch 200/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8120 - accuracy: 0.6417 - val_loss: 0.8429 - val_accuracy: 0.6011\n",
            "Epoch 201/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8102 - accuracy: 0.6389 - val_loss: 0.8353 - val_accuracy: 0.6202\n",
            "Epoch 202/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.8102 - accuracy: 0.6400 - val_loss: 0.8396 - val_accuracy: 0.6101\n",
            "Epoch 203/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.8142 - accuracy: 0.6384 - val_loss: 0.8485 - val_accuracy: 0.6135\n",
            "Epoch 204/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8142 - accuracy: 0.6381 - val_loss: 0.8557 - val_accuracy: 0.6034\n",
            "Epoch 205/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8104 - accuracy: 0.6386 - val_loss: 0.8344 - val_accuracy: 0.6202\n",
            "Epoch 206/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8091 - accuracy: 0.6406 - val_loss: 0.8346 - val_accuracy: 0.6258\n",
            "Epoch 207/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8072 - accuracy: 0.6457 - val_loss: 0.8349 - val_accuracy: 0.6191\n",
            "Epoch 208/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8080 - accuracy: 0.6451 - val_loss: 0.8340 - val_accuracy: 0.6225\n",
            "Epoch 209/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8081 - accuracy: 0.6445 - val_loss: 0.8374 - val_accuracy: 0.6067\n",
            "Epoch 210/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8064 - accuracy: 0.6454 - val_loss: 0.8365 - val_accuracy: 0.6135\n",
            "Epoch 211/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8106 - accuracy: 0.6420 - val_loss: 0.8438 - val_accuracy: 0.6000\n",
            "Epoch 212/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8068 - accuracy: 0.6386 - val_loss: 0.8365 - val_accuracy: 0.6124\n",
            "Epoch 213/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8046 - accuracy: 0.6445 - val_loss: 0.8362 - val_accuracy: 0.6157\n",
            "Epoch 214/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8051 - accuracy: 0.6415 - val_loss: 0.8483 - val_accuracy: 0.5955\n",
            "Epoch 215/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8038 - accuracy: 0.6406 - val_loss: 0.8402 - val_accuracy: 0.6067\n",
            "Epoch 216/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8048 - accuracy: 0.6384 - val_loss: 0.8449 - val_accuracy: 0.6022\n",
            "Epoch 217/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8042 - accuracy: 0.6454 - val_loss: 0.8398 - val_accuracy: 0.6169\n",
            "Epoch 218/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8070 - accuracy: 0.6448 - val_loss: 0.8337 - val_accuracy: 0.6236\n",
            "Epoch 219/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8083 - accuracy: 0.6384 - val_loss: 0.8423 - val_accuracy: 0.6067\n",
            "Epoch 220/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8043 - accuracy: 0.6409 - val_loss: 0.8432 - val_accuracy: 0.6011\n",
            "Epoch 221/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8046 - accuracy: 0.6426 - val_loss: 0.8367 - val_accuracy: 0.6180\n",
            "Epoch 222/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8073 - accuracy: 0.6437 - val_loss: 0.8375 - val_accuracy: 0.6315\n",
            "Epoch 223/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8048 - accuracy: 0.6479 - val_loss: 0.8339 - val_accuracy: 0.6236\n",
            "Epoch 224/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8061 - accuracy: 0.6434 - val_loss: 0.8514 - val_accuracy: 0.5933\n",
            "Epoch 225/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8079 - accuracy: 0.6400 - val_loss: 0.8342 - val_accuracy: 0.6258\n",
            "Epoch 226/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8032 - accuracy: 0.6431 - val_loss: 0.8325 - val_accuracy: 0.6281\n",
            "Epoch 227/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8029 - accuracy: 0.6443 - val_loss: 0.8389 - val_accuracy: 0.6146\n",
            "Epoch 228/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8079 - accuracy: 0.6386 - val_loss: 0.8382 - val_accuracy: 0.6169\n",
            "Epoch 229/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8065 - accuracy: 0.6440 - val_loss: 0.8384 - val_accuracy: 0.6180\n",
            "Epoch 230/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8036 - accuracy: 0.6482 - val_loss: 0.8409 - val_accuracy: 0.6034\n",
            "Epoch 231/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8024 - accuracy: 0.6445 - val_loss: 0.8331 - val_accuracy: 0.6270\n",
            "Epoch 232/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8023 - accuracy: 0.6462 - val_loss: 0.8338 - val_accuracy: 0.6180\n",
            "Epoch 233/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8043 - accuracy: 0.6445 - val_loss: 0.8420 - val_accuracy: 0.6056\n",
            "Epoch 234/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8035 - accuracy: 0.6454 - val_loss: 0.8320 - val_accuracy: 0.6303\n",
            "Epoch 235/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.8020 - accuracy: 0.6493 - val_loss: 0.8334 - val_accuracy: 0.6281\n",
            "Epoch 236/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.8084 - accuracy: 0.6361 - val_loss: 0.8367 - val_accuracy: 0.6236\n",
            "Epoch 237/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.8023 - accuracy: 0.6476 - val_loss: 0.8344 - val_accuracy: 0.6258\n",
            "Epoch 238/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.8036 - accuracy: 0.6403 - val_loss: 0.8401 - val_accuracy: 0.6034\n",
            "Epoch 239/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.8030 - accuracy: 0.6400 - val_loss: 0.8449 - val_accuracy: 0.6090\n",
            "Epoch 240/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.8021 - accuracy: 0.6471 - val_loss: 0.8429 - val_accuracy: 0.5978\n",
            "Epoch 241/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.8015 - accuracy: 0.6434 - val_loss: 0.8433 - val_accuracy: 0.6022\n",
            "Epoch 242/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.8006 - accuracy: 0.6527 - val_loss: 0.8398 - val_accuracy: 0.6079\n",
            "Epoch 243/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.8028 - accuracy: 0.6482 - val_loss: 0.8349 - val_accuracy: 0.6236\n",
            "Epoch 244/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.8003 - accuracy: 0.6479 - val_loss: 0.8392 - val_accuracy: 0.6112\n",
            "Epoch 245/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.8032 - accuracy: 0.6471 - val_loss: 0.8375 - val_accuracy: 0.6146\n",
            "Epoch 246/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.8000 - accuracy: 0.6465 - val_loss: 0.8554 - val_accuracy: 0.5966\n",
            "Epoch 247/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.8033 - accuracy: 0.6420 - val_loss: 0.8321 - val_accuracy: 0.6258\n",
            "Epoch 248/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.8027 - accuracy: 0.6462 - val_loss: 0.8444 - val_accuracy: 0.6000\n",
            "Epoch 249/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.8001 - accuracy: 0.6445 - val_loss: 0.8372 - val_accuracy: 0.5966\n",
            "Epoch 250/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.8021 - accuracy: 0.6406 - val_loss: 0.8344 - val_accuracy: 0.6315\n",
            "Epoch 251/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8045 - accuracy: 0.6440 - val_loss: 0.8327 - val_accuracy: 0.6236\n",
            "Epoch 252/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8001 - accuracy: 0.6516 - val_loss: 0.8339 - val_accuracy: 0.6236\n",
            "Epoch 253/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7993 - accuracy: 0.6507 - val_loss: 0.8350 - val_accuracy: 0.6213\n",
            "Epoch 254/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8025 - accuracy: 0.6454 - val_loss: 0.8393 - val_accuracy: 0.6135\n",
            "Epoch 255/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8001 - accuracy: 0.6454 - val_loss: 0.8452 - val_accuracy: 0.6022\n",
            "Epoch 256/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8015 - accuracy: 0.6468 - val_loss: 0.8473 - val_accuracy: 0.5955\n",
            "Epoch 257/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8015 - accuracy: 0.6426 - val_loss: 0.8315 - val_accuracy: 0.6236\n",
            "Epoch 258/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8056 - accuracy: 0.6355 - val_loss: 0.8531 - val_accuracy: 0.5899\n",
            "Epoch 259/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8022 - accuracy: 0.6429 - val_loss: 0.8467 - val_accuracy: 0.6000\n",
            "Epoch 260/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7993 - accuracy: 0.6451 - val_loss: 0.8311 - val_accuracy: 0.6225\n",
            "Epoch 261/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7992 - accuracy: 0.6445 - val_loss: 0.8530 - val_accuracy: 0.6169\n",
            "Epoch 262/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8047 - accuracy: 0.6431 - val_loss: 0.8378 - val_accuracy: 0.6067\n",
            "Epoch 263/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7997 - accuracy: 0.6504 - val_loss: 0.8413 - val_accuracy: 0.6034\n",
            "Epoch 264/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7996 - accuracy: 0.6485 - val_loss: 0.8395 - val_accuracy: 0.6112\n",
            "Epoch 265/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8006 - accuracy: 0.6426 - val_loss: 0.8352 - val_accuracy: 0.6056\n",
            "Epoch 266/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7987 - accuracy: 0.6485 - val_loss: 0.8421 - val_accuracy: 0.6056\n",
            "Epoch 267/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8005 - accuracy: 0.6457 - val_loss: 0.8391 - val_accuracy: 0.6146\n",
            "Epoch 268/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7994 - accuracy: 0.6493 - val_loss: 0.8348 - val_accuracy: 0.6270\n",
            "Epoch 269/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7982 - accuracy: 0.6474 - val_loss: 0.8352 - val_accuracy: 0.6236\n",
            "Epoch 270/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7988 - accuracy: 0.6516 - val_loss: 0.8330 - val_accuracy: 0.6191\n",
            "Epoch 271/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7994 - accuracy: 0.6434 - val_loss: 0.8390 - val_accuracy: 0.6124\n",
            "Epoch 272/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7985 - accuracy: 0.6465 - val_loss: 0.8335 - val_accuracy: 0.6247\n",
            "Epoch 273/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8009 - accuracy: 0.6431 - val_loss: 0.8319 - val_accuracy: 0.6303\n",
            "Epoch 274/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7996 - accuracy: 0.6482 - val_loss: 0.8380 - val_accuracy: 0.6079\n",
            "Epoch 275/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7975 - accuracy: 0.6493 - val_loss: 0.8385 - val_accuracy: 0.6135\n",
            "Epoch 276/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8032 - accuracy: 0.6375 - val_loss: 0.8337 - val_accuracy: 0.6247\n",
            "Epoch 277/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7975 - accuracy: 0.6454 - val_loss: 0.8524 - val_accuracy: 0.5876\n",
            "Epoch 278/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8006 - accuracy: 0.6479 - val_loss: 0.8312 - val_accuracy: 0.6236\n",
            "Epoch 279/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7971 - accuracy: 0.6502 - val_loss: 0.8373 - val_accuracy: 0.6045\n",
            "Epoch 280/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7981 - accuracy: 0.6448 - val_loss: 0.8346 - val_accuracy: 0.6281\n",
            "Epoch 281/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7977 - accuracy: 0.6524 - val_loss: 0.8350 - val_accuracy: 0.6180\n",
            "Epoch 282/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7958 - accuracy: 0.6510 - val_loss: 0.8350 - val_accuracy: 0.6315\n",
            "Epoch 283/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7990 - accuracy: 0.6437 - val_loss: 0.8674 - val_accuracy: 0.5876\n",
            "Epoch 284/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8030 - accuracy: 0.6437 - val_loss: 0.8344 - val_accuracy: 0.6202\n",
            "Epoch 285/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7963 - accuracy: 0.6454 - val_loss: 0.8307 - val_accuracy: 0.6258\n",
            "Epoch 286/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7966 - accuracy: 0.6476 - val_loss: 0.8333 - val_accuracy: 0.6258\n",
            "Epoch 287/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8038 - accuracy: 0.6423 - val_loss: 0.8455 - val_accuracy: 0.5989\n",
            "Epoch 288/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7968 - accuracy: 0.6445 - val_loss: 0.8326 - val_accuracy: 0.6337\n",
            "Epoch 289/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.8025 - accuracy: 0.6457 - val_loss: 0.8320 - val_accuracy: 0.6303\n",
            "Epoch 290/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7975 - accuracy: 0.6479 - val_loss: 0.8326 - val_accuracy: 0.6079\n",
            "Epoch 291/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7978 - accuracy: 0.6434 - val_loss: 0.8305 - val_accuracy: 0.6236\n",
            "Epoch 292/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7983 - accuracy: 0.6448 - val_loss: 0.8665 - val_accuracy: 0.5854\n",
            "Epoch 293/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7996 - accuracy: 0.6474 - val_loss: 0.8316 - val_accuracy: 0.6247\n",
            "Epoch 294/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7973 - accuracy: 0.6460 - val_loss: 0.8309 - val_accuracy: 0.6247\n",
            "Epoch 295/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7990 - accuracy: 0.6474 - val_loss: 0.8389 - val_accuracy: 0.6056\n",
            "Epoch 296/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7970 - accuracy: 0.6471 - val_loss: 0.8426 - val_accuracy: 0.6022\n",
            "Epoch 297/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7977 - accuracy: 0.6412 - val_loss: 0.8319 - val_accuracy: 0.6281\n",
            "Epoch 298/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7981 - accuracy: 0.6510 - val_loss: 0.8354 - val_accuracy: 0.6067\n",
            "Epoch 299/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7955 - accuracy: 0.6516 - val_loss: 0.8388 - val_accuracy: 0.6090\n",
            "Epoch 300/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7962 - accuracy: 0.6462 - val_loss: 0.8378 - val_accuracy: 0.6112\n",
            "Epoch 301/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7946 - accuracy: 0.6507 - val_loss: 0.8356 - val_accuracy: 0.6124\n",
            "Epoch 302/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7981 - accuracy: 0.6493 - val_loss: 0.8645 - val_accuracy: 0.5865\n",
            "Epoch 303/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7942 - accuracy: 0.6535 - val_loss: 0.8290 - val_accuracy: 0.6281\n",
            "Epoch 304/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7938 - accuracy: 0.6524 - val_loss: 0.8309 - val_accuracy: 0.6213\n",
            "Epoch 305/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7957 - accuracy: 0.6504 - val_loss: 0.8568 - val_accuracy: 0.6022\n",
            "Epoch 306/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7975 - accuracy: 0.6431 - val_loss: 0.8348 - val_accuracy: 0.6056\n",
            "Epoch 307/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7974 - accuracy: 0.6538 - val_loss: 0.8337 - val_accuracy: 0.6348\n",
            "Epoch 308/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7967 - accuracy: 0.6490 - val_loss: 0.8498 - val_accuracy: 0.5899\n",
            "Epoch 309/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7962 - accuracy: 0.6474 - val_loss: 0.8315 - val_accuracy: 0.6270\n",
            "Epoch 310/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7966 - accuracy: 0.6462 - val_loss: 0.8298 - val_accuracy: 0.6236\n",
            "Epoch 311/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7954 - accuracy: 0.6476 - val_loss: 0.8383 - val_accuracy: 0.6202\n",
            "Epoch 312/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7970 - accuracy: 0.6445 - val_loss: 0.8285 - val_accuracy: 0.6315\n",
            "Epoch 313/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7933 - accuracy: 0.6488 - val_loss: 0.8322 - val_accuracy: 0.6213\n",
            "Epoch 314/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7957 - accuracy: 0.6496 - val_loss: 0.8518 - val_accuracy: 0.6011\n",
            "Epoch 315/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7954 - accuracy: 0.6465 - val_loss: 0.8353 - val_accuracy: 0.6135\n",
            "Epoch 316/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7955 - accuracy: 0.6527 - val_loss: 0.8362 - val_accuracy: 0.6258\n",
            "Epoch 317/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7960 - accuracy: 0.6437 - val_loss: 0.8379 - val_accuracy: 0.6034\n",
            "Epoch 318/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7931 - accuracy: 0.6538 - val_loss: 0.8310 - val_accuracy: 0.6303\n",
            "Epoch 319/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7929 - accuracy: 0.6533 - val_loss: 0.8427 - val_accuracy: 0.6157\n",
            "Epoch 320/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7919 - accuracy: 0.6519 - val_loss: 0.8306 - val_accuracy: 0.6258\n",
            "Epoch 321/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7967 - accuracy: 0.6496 - val_loss: 0.8356 - val_accuracy: 0.6169\n",
            "Epoch 322/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7937 - accuracy: 0.6488 - val_loss: 0.8343 - val_accuracy: 0.6056\n",
            "Epoch 323/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7941 - accuracy: 0.6510 - val_loss: 0.8410 - val_accuracy: 0.6090\n",
            "Epoch 324/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7934 - accuracy: 0.6496 - val_loss: 0.8478 - val_accuracy: 0.5989\n",
            "Epoch 325/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7951 - accuracy: 0.6465 - val_loss: 0.8475 - val_accuracy: 0.5989\n",
            "Epoch 326/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7937 - accuracy: 0.6493 - val_loss: 0.8366 - val_accuracy: 0.6135\n",
            "Epoch 327/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7943 - accuracy: 0.6493 - val_loss: 0.8398 - val_accuracy: 0.6022\n",
            "Epoch 328/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7941 - accuracy: 0.6488 - val_loss: 0.8358 - val_accuracy: 0.6034\n",
            "Epoch 329/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7945 - accuracy: 0.6504 - val_loss: 0.8281 - val_accuracy: 0.6270\n",
            "Epoch 330/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7948 - accuracy: 0.6521 - val_loss: 0.8303 - val_accuracy: 0.6258\n",
            "Epoch 331/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7966 - accuracy: 0.6479 - val_loss: 0.8303 - val_accuracy: 0.6236\n",
            "Epoch 332/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7933 - accuracy: 0.6521 - val_loss: 0.8329 - val_accuracy: 0.6191\n",
            "Epoch 333/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7942 - accuracy: 0.6454 - val_loss: 0.8351 - val_accuracy: 0.6124\n",
            "Epoch 334/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7921 - accuracy: 0.6547 - val_loss: 0.8470 - val_accuracy: 0.6045\n",
            "Epoch 335/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7923 - accuracy: 0.6504 - val_loss: 0.8391 - val_accuracy: 0.6045\n",
            "Epoch 336/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7955 - accuracy: 0.6490 - val_loss: 0.8283 - val_accuracy: 0.6213\n",
            "Epoch 337/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7928 - accuracy: 0.6519 - val_loss: 0.8373 - val_accuracy: 0.6180\n",
            "Epoch 338/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7929 - accuracy: 0.6510 - val_loss: 0.8308 - val_accuracy: 0.6270\n",
            "Epoch 339/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7918 - accuracy: 0.6521 - val_loss: 0.8288 - val_accuracy: 0.6303\n",
            "Epoch 340/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7920 - accuracy: 0.6561 - val_loss: 0.8404 - val_accuracy: 0.6124\n",
            "Epoch 341/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7946 - accuracy: 0.6474 - val_loss: 0.8467 - val_accuracy: 0.5944\n",
            "Epoch 342/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7941 - accuracy: 0.6474 - val_loss: 0.8305 - val_accuracy: 0.6270\n",
            "Epoch 343/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7936 - accuracy: 0.6533 - val_loss: 0.8310 - val_accuracy: 0.6146\n",
            "Epoch 344/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7913 - accuracy: 0.6516 - val_loss: 0.8286 - val_accuracy: 0.6225\n",
            "Epoch 345/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7924 - accuracy: 0.6502 - val_loss: 0.8408 - val_accuracy: 0.5966\n",
            "Epoch 346/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7937 - accuracy: 0.6493 - val_loss: 0.8354 - val_accuracy: 0.6000\n",
            "Epoch 347/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7943 - accuracy: 0.6488 - val_loss: 0.8306 - val_accuracy: 0.6303\n",
            "Epoch 348/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7966 - accuracy: 0.6521 - val_loss: 0.8301 - val_accuracy: 0.6270\n",
            "Epoch 349/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7931 - accuracy: 0.6530 - val_loss: 0.8361 - val_accuracy: 0.6045\n",
            "Epoch 350/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7910 - accuracy: 0.6527 - val_loss: 0.8428 - val_accuracy: 0.6034\n",
            "Epoch 351/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7952 - accuracy: 0.6448 - val_loss: 0.8395 - val_accuracy: 0.6169\n",
            "Epoch 352/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7923 - accuracy: 0.6482 - val_loss: 0.8281 - val_accuracy: 0.6258\n",
            "Epoch 353/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7923 - accuracy: 0.6524 - val_loss: 0.8361 - val_accuracy: 0.6124\n",
            "Epoch 354/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7935 - accuracy: 0.6488 - val_loss: 0.8287 - val_accuracy: 0.6202\n",
            "Epoch 355/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7901 - accuracy: 0.6521 - val_loss: 0.8340 - val_accuracy: 0.6225\n",
            "Epoch 356/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7901 - accuracy: 0.6496 - val_loss: 0.8365 - val_accuracy: 0.6045\n",
            "Epoch 357/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7931 - accuracy: 0.6575 - val_loss: 0.8396 - val_accuracy: 0.6000\n",
            "Epoch 358/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7936 - accuracy: 0.6454 - val_loss: 0.8406 - val_accuracy: 0.5944\n",
            "Epoch 359/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7957 - accuracy: 0.6468 - val_loss: 0.8330 - val_accuracy: 0.6045\n",
            "Epoch 360/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7938 - accuracy: 0.6462 - val_loss: 0.8523 - val_accuracy: 0.5921\n",
            "Epoch 361/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7903 - accuracy: 0.6504 - val_loss: 0.8376 - val_accuracy: 0.6045\n",
            "Epoch 362/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7922 - accuracy: 0.6496 - val_loss: 0.8269 - val_accuracy: 0.6348\n",
            "Epoch 363/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7895 - accuracy: 0.6521 - val_loss: 0.8359 - val_accuracy: 0.6056\n",
            "Epoch 364/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7890 - accuracy: 0.6547 - val_loss: 0.8391 - val_accuracy: 0.6101\n",
            "Epoch 365/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7915 - accuracy: 0.6476 - val_loss: 0.8381 - val_accuracy: 0.5978\n",
            "Epoch 366/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7917 - accuracy: 0.6502 - val_loss: 0.8314 - val_accuracy: 0.6202\n",
            "Epoch 367/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7896 - accuracy: 0.6496 - val_loss: 0.8299 - val_accuracy: 0.6180\n",
            "Epoch 368/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7915 - accuracy: 0.6454 - val_loss: 0.8322 - val_accuracy: 0.6270\n",
            "Epoch 369/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7922 - accuracy: 0.6524 - val_loss: 0.8278 - val_accuracy: 0.6247\n",
            "Epoch 370/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7915 - accuracy: 0.6519 - val_loss: 0.8338 - val_accuracy: 0.6225\n",
            "Epoch 371/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7927 - accuracy: 0.6499 - val_loss: 0.8346 - val_accuracy: 0.6079\n",
            "Epoch 372/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7903 - accuracy: 0.6496 - val_loss: 0.8318 - val_accuracy: 0.6270\n",
            "Epoch 373/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7892 - accuracy: 0.6513 - val_loss: 0.8373 - val_accuracy: 0.5955\n",
            "Epoch 374/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7902 - accuracy: 0.6527 - val_loss: 0.8462 - val_accuracy: 0.6067\n",
            "Epoch 375/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7910 - accuracy: 0.6555 - val_loss: 0.8296 - val_accuracy: 0.6169\n",
            "Epoch 376/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7900 - accuracy: 0.6471 - val_loss: 0.8310 - val_accuracy: 0.6191\n",
            "Epoch 377/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7907 - accuracy: 0.6521 - val_loss: 0.8388 - val_accuracy: 0.6090\n",
            "Epoch 378/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7902 - accuracy: 0.6502 - val_loss: 0.8417 - val_accuracy: 0.5955\n",
            "Epoch 379/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7887 - accuracy: 0.6519 - val_loss: 0.8312 - val_accuracy: 0.6236\n",
            "Epoch 380/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7906 - accuracy: 0.6502 - val_loss: 0.8311 - val_accuracy: 0.6135\n",
            "Epoch 381/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7954 - accuracy: 0.6468 - val_loss: 0.8354 - val_accuracy: 0.6011\n",
            "Epoch 382/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7866 - accuracy: 0.6547 - val_loss: 0.8298 - val_accuracy: 0.6124\n",
            "Epoch 383/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7881 - accuracy: 0.6490 - val_loss: 0.8335 - val_accuracy: 0.6169\n",
            "Epoch 384/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7907 - accuracy: 0.6510 - val_loss: 0.8388 - val_accuracy: 0.5966\n",
            "Epoch 385/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7882 - accuracy: 0.6527 - val_loss: 0.8249 - val_accuracy: 0.6281\n",
            "Epoch 386/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7892 - accuracy: 0.6457 - val_loss: 0.8497 - val_accuracy: 0.5955\n",
            "Epoch 387/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7920 - accuracy: 0.6521 - val_loss: 0.8370 - val_accuracy: 0.6022\n",
            "Epoch 388/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7890 - accuracy: 0.6527 - val_loss: 0.8368 - val_accuracy: 0.5955\n",
            "Epoch 389/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7894 - accuracy: 0.6507 - val_loss: 0.8274 - val_accuracy: 0.6213\n",
            "Epoch 390/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7879 - accuracy: 0.6572 - val_loss: 0.8258 - val_accuracy: 0.6315\n",
            "Epoch 391/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7880 - accuracy: 0.6507 - val_loss: 0.8324 - val_accuracy: 0.6056\n",
            "Epoch 392/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7873 - accuracy: 0.6547 - val_loss: 0.8388 - val_accuracy: 0.6011\n",
            "Epoch 393/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7896 - accuracy: 0.6504 - val_loss: 0.8291 - val_accuracy: 0.6180\n",
            "Epoch 394/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7879 - accuracy: 0.6521 - val_loss: 0.8312 - val_accuracy: 0.6090\n",
            "Epoch 395/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7906 - accuracy: 0.6479 - val_loss: 0.8264 - val_accuracy: 0.6292\n",
            "Epoch 396/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7910 - accuracy: 0.6566 - val_loss: 0.8271 - val_accuracy: 0.6247\n",
            "Epoch 397/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7892 - accuracy: 0.6496 - val_loss: 0.8455 - val_accuracy: 0.5921\n",
            "Epoch 398/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7892 - accuracy: 0.6479 - val_loss: 0.8304 - val_accuracy: 0.6202\n",
            "Epoch 399/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7887 - accuracy: 0.6482 - val_loss: 0.8251 - val_accuracy: 0.6258\n",
            "Epoch 400/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7853 - accuracy: 0.6507 - val_loss: 0.8333 - val_accuracy: 0.6067\n",
            "Epoch 401/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7845 - accuracy: 0.6533 - val_loss: 0.8252 - val_accuracy: 0.6258\n",
            "Epoch 402/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7906 - accuracy: 0.6516 - val_loss: 0.8350 - val_accuracy: 0.6157\n",
            "Epoch 403/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7857 - accuracy: 0.6549 - val_loss: 0.8314 - val_accuracy: 0.6157\n",
            "Epoch 404/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7882 - accuracy: 0.6488 - val_loss: 0.8288 - val_accuracy: 0.6303\n",
            "Epoch 405/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7913 - accuracy: 0.6490 - val_loss: 0.8367 - val_accuracy: 0.6157\n",
            "Epoch 406/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7875 - accuracy: 0.6533 - val_loss: 0.8463 - val_accuracy: 0.5955\n",
            "Epoch 407/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7893 - accuracy: 0.6457 - val_loss: 0.8260 - val_accuracy: 0.6213\n",
            "Epoch 408/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7884 - accuracy: 0.6544 - val_loss: 0.8296 - val_accuracy: 0.6202\n",
            "Epoch 409/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7868 - accuracy: 0.6555 - val_loss: 0.8264 - val_accuracy: 0.6169\n",
            "Epoch 410/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7852 - accuracy: 0.6533 - val_loss: 0.8247 - val_accuracy: 0.6393\n",
            "Epoch 411/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7845 - accuracy: 0.6530 - val_loss: 0.8236 - val_accuracy: 0.6236\n",
            "Epoch 412/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7870 - accuracy: 0.6555 - val_loss: 0.8239 - val_accuracy: 0.6292\n",
            "Epoch 413/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7864 - accuracy: 0.6538 - val_loss: 0.8328 - val_accuracy: 0.6236\n",
            "Epoch 414/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7833 - accuracy: 0.6504 - val_loss: 0.8276 - val_accuracy: 0.6191\n",
            "Epoch 415/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7865 - accuracy: 0.6516 - val_loss: 0.8320 - val_accuracy: 0.6101\n",
            "Epoch 416/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7858 - accuracy: 0.6538 - val_loss: 0.8431 - val_accuracy: 0.6022\n",
            "Epoch 417/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7891 - accuracy: 0.6502 - val_loss: 0.8344 - val_accuracy: 0.6135\n",
            "Epoch 418/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7868 - accuracy: 0.6504 - val_loss: 0.8266 - val_accuracy: 0.6270\n",
            "Epoch 419/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7856 - accuracy: 0.6524 - val_loss: 0.8287 - val_accuracy: 0.6202\n",
            "Epoch 420/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7855 - accuracy: 0.6572 - val_loss: 0.8316 - val_accuracy: 0.6213\n",
            "Epoch 421/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7920 - accuracy: 0.6485 - val_loss: 0.8252 - val_accuracy: 0.6247\n",
            "Epoch 422/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7884 - accuracy: 0.6549 - val_loss: 0.8270 - val_accuracy: 0.6315\n",
            "Epoch 423/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7878 - accuracy: 0.6535 - val_loss: 0.8356 - val_accuracy: 0.6191\n",
            "Epoch 424/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7860 - accuracy: 0.6493 - val_loss: 0.8353 - val_accuracy: 0.6079\n",
            "Epoch 425/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7852 - accuracy: 0.6513 - val_loss: 0.8239 - val_accuracy: 0.6270\n",
            "Epoch 426/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7848 - accuracy: 0.6555 - val_loss: 0.8378 - val_accuracy: 0.5933\n",
            "Epoch 427/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7873 - accuracy: 0.6485 - val_loss: 0.8270 - val_accuracy: 0.6258\n",
            "Epoch 428/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7845 - accuracy: 0.6555 - val_loss: 0.8300 - val_accuracy: 0.6180\n",
            "Epoch 429/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7836 - accuracy: 0.6544 - val_loss: 0.8300 - val_accuracy: 0.6056\n",
            "Epoch 430/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7853 - accuracy: 0.6564 - val_loss: 0.8229 - val_accuracy: 0.6303\n",
            "Epoch 431/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7882 - accuracy: 0.6457 - val_loss: 0.8284 - val_accuracy: 0.6169\n",
            "Epoch 432/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7852 - accuracy: 0.6524 - val_loss: 0.8246 - val_accuracy: 0.6191\n",
            "Epoch 433/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7869 - accuracy: 0.6569 - val_loss: 0.8299 - val_accuracy: 0.6191\n",
            "Epoch 434/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7855 - accuracy: 0.6561 - val_loss: 0.8417 - val_accuracy: 0.6135\n",
            "Epoch 435/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7857 - accuracy: 0.6572 - val_loss: 0.8331 - val_accuracy: 0.5989\n",
            "Epoch 436/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7864 - accuracy: 0.6558 - val_loss: 0.8303 - val_accuracy: 0.6169\n",
            "Epoch 437/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7857 - accuracy: 0.6544 - val_loss: 0.8250 - val_accuracy: 0.6180\n",
            "Epoch 438/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7838 - accuracy: 0.6572 - val_loss: 0.8256 - val_accuracy: 0.6292\n",
            "Epoch 439/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7847 - accuracy: 0.6510 - val_loss: 0.8215 - val_accuracy: 0.6337\n",
            "Epoch 440/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7840 - accuracy: 0.6558 - val_loss: 0.8235 - val_accuracy: 0.6236\n",
            "Epoch 441/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7826 - accuracy: 0.6519 - val_loss: 0.8470 - val_accuracy: 0.6101\n",
            "Epoch 442/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7840 - accuracy: 0.6566 - val_loss: 0.8269 - val_accuracy: 0.6124\n",
            "Epoch 443/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7831 - accuracy: 0.6541 - val_loss: 0.8341 - val_accuracy: 0.5944\n",
            "Epoch 444/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7867 - accuracy: 0.6549 - val_loss: 0.8240 - val_accuracy: 0.6247\n",
            "Epoch 445/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7847 - accuracy: 0.6541 - val_loss: 0.8222 - val_accuracy: 0.6303\n",
            "Epoch 446/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7836 - accuracy: 0.6513 - val_loss: 0.8225 - val_accuracy: 0.6416\n",
            "Epoch 447/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7867 - accuracy: 0.6462 - val_loss: 0.8308 - val_accuracy: 0.6135\n",
            "Epoch 448/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7848 - accuracy: 0.6569 - val_loss: 0.8328 - val_accuracy: 0.6045\n",
            "Epoch 449/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7870 - accuracy: 0.6541 - val_loss: 0.8354 - val_accuracy: 0.6000\n",
            "Epoch 450/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7823 - accuracy: 0.6558 - val_loss: 0.8348 - val_accuracy: 0.6079\n",
            "Epoch 451/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7883 - accuracy: 0.6488 - val_loss: 0.8245 - val_accuracy: 0.6236\n",
            "Epoch 452/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7874 - accuracy: 0.6578 - val_loss: 0.8232 - val_accuracy: 0.6472\n",
            "Epoch 453/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7848 - accuracy: 0.6578 - val_loss: 0.8245 - val_accuracy: 0.6157\n",
            "Epoch 454/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7828 - accuracy: 0.6575 - val_loss: 0.8380 - val_accuracy: 0.5978\n",
            "Epoch 455/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7834 - accuracy: 0.6544 - val_loss: 0.8335 - val_accuracy: 0.6079\n",
            "Epoch 456/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7814 - accuracy: 0.6552 - val_loss: 0.8244 - val_accuracy: 0.6371\n",
            "Epoch 457/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7870 - accuracy: 0.6566 - val_loss: 0.8376 - val_accuracy: 0.5966\n",
            "Epoch 458/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7860 - accuracy: 0.6541 - val_loss: 0.8271 - val_accuracy: 0.6247\n",
            "Epoch 459/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7845 - accuracy: 0.6558 - val_loss: 0.8236 - val_accuracy: 0.6247\n",
            "Epoch 460/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7848 - accuracy: 0.6538 - val_loss: 0.8234 - val_accuracy: 0.6225\n",
            "Epoch 461/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7829 - accuracy: 0.6527 - val_loss: 0.8310 - val_accuracy: 0.6124\n",
            "Epoch 462/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7862 - accuracy: 0.6502 - val_loss: 0.8269 - val_accuracy: 0.6281\n",
            "Epoch 463/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7828 - accuracy: 0.6580 - val_loss: 0.8445 - val_accuracy: 0.5888\n",
            "Epoch 464/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7853 - accuracy: 0.6561 - val_loss: 0.8217 - val_accuracy: 0.6281\n",
            "Epoch 465/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7835 - accuracy: 0.6597 - val_loss: 0.8247 - val_accuracy: 0.6281\n",
            "Epoch 466/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7847 - accuracy: 0.6513 - val_loss: 0.8348 - val_accuracy: 0.6011\n",
            "Epoch 467/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7854 - accuracy: 0.6564 - val_loss: 0.8344 - val_accuracy: 0.6090\n",
            "Epoch 468/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7835 - accuracy: 0.6535 - val_loss: 0.8206 - val_accuracy: 0.6416\n",
            "Epoch 469/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7831 - accuracy: 0.6519 - val_loss: 0.8423 - val_accuracy: 0.5978\n",
            "Epoch 470/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7836 - accuracy: 0.6555 - val_loss: 0.8320 - val_accuracy: 0.6056\n",
            "Epoch 471/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7821 - accuracy: 0.6611 - val_loss: 0.8286 - val_accuracy: 0.6213\n",
            "Epoch 472/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7845 - accuracy: 0.6549 - val_loss: 0.8236 - val_accuracy: 0.6236\n",
            "Epoch 473/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7803 - accuracy: 0.6555 - val_loss: 0.8336 - val_accuracy: 0.6045\n",
            "Epoch 474/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7815 - accuracy: 0.6555 - val_loss: 0.8307 - val_accuracy: 0.6180\n",
            "Epoch 475/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7834 - accuracy: 0.6535 - val_loss: 0.8298 - val_accuracy: 0.6101\n",
            "Epoch 476/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7820 - accuracy: 0.6558 - val_loss: 0.8220 - val_accuracy: 0.6270\n",
            "Epoch 477/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7827 - accuracy: 0.6535 - val_loss: 0.8270 - val_accuracy: 0.6180\n",
            "Epoch 478/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7824 - accuracy: 0.6561 - val_loss: 0.8259 - val_accuracy: 0.6169\n",
            "Epoch 479/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7850 - accuracy: 0.6575 - val_loss: 0.8635 - val_accuracy: 0.5921\n",
            "Epoch 480/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7867 - accuracy: 0.6541 - val_loss: 0.8271 - val_accuracy: 0.6135\n",
            "Epoch 481/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7812 - accuracy: 0.6538 - val_loss: 0.8290 - val_accuracy: 0.6191\n",
            "Epoch 482/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7841 - accuracy: 0.6634 - val_loss: 0.8221 - val_accuracy: 0.6449\n",
            "Epoch 483/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7817 - accuracy: 0.6566 - val_loss: 0.8355 - val_accuracy: 0.6067\n",
            "Epoch 484/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7812 - accuracy: 0.6589 - val_loss: 0.8228 - val_accuracy: 0.6303\n",
            "Epoch 485/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7837 - accuracy: 0.6474 - val_loss: 0.8291 - val_accuracy: 0.6135\n",
            "Epoch 486/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7837 - accuracy: 0.6569 - val_loss: 0.8244 - val_accuracy: 0.6270\n",
            "Epoch 487/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7798 - accuracy: 0.6561 - val_loss: 0.8222 - val_accuracy: 0.6303\n",
            "Epoch 488/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7860 - accuracy: 0.6482 - val_loss: 0.8199 - val_accuracy: 0.6427\n",
            "Epoch 489/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7802 - accuracy: 0.6558 - val_loss: 0.8262 - val_accuracy: 0.6202\n",
            "Epoch 490/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7794 - accuracy: 0.6555 - val_loss: 0.8270 - val_accuracy: 0.6157\n",
            "Epoch 491/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7803 - accuracy: 0.6586 - val_loss: 0.8265 - val_accuracy: 0.6225\n",
            "Epoch 492/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7806 - accuracy: 0.6603 - val_loss: 0.8276 - val_accuracy: 0.6157\n",
            "Epoch 493/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7803 - accuracy: 0.6606 - val_loss: 0.8247 - val_accuracy: 0.6202\n",
            "Epoch 494/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7814 - accuracy: 0.6502 - val_loss: 0.8258 - val_accuracy: 0.6382\n",
            "Epoch 495/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7843 - accuracy: 0.6547 - val_loss: 0.8206 - val_accuracy: 0.6247\n",
            "Epoch 496/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7818 - accuracy: 0.6547 - val_loss: 0.8196 - val_accuracy: 0.6360\n",
            "Epoch 497/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7857 - accuracy: 0.6507 - val_loss: 0.8293 - val_accuracy: 0.6146\n",
            "Epoch 498/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7818 - accuracy: 0.6561 - val_loss: 0.8271 - val_accuracy: 0.6135\n",
            "Epoch 499/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7785 - accuracy: 0.6597 - val_loss: 0.8221 - val_accuracy: 0.6292\n",
            "Epoch 500/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7813 - accuracy: 0.6578 - val_loss: 0.8318 - val_accuracy: 0.6112\n",
            "Epoch 501/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7797 - accuracy: 0.6572 - val_loss: 0.8193 - val_accuracy: 0.6360\n",
            "Epoch 502/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7788 - accuracy: 0.6589 - val_loss: 0.8240 - val_accuracy: 0.6225\n",
            "Epoch 503/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7853 - accuracy: 0.6527 - val_loss: 0.8304 - val_accuracy: 0.6236\n",
            "Epoch 504/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7811 - accuracy: 0.6606 - val_loss: 0.8417 - val_accuracy: 0.6067\n",
            "Epoch 505/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7835 - accuracy: 0.6476 - val_loss: 0.8213 - val_accuracy: 0.6292\n",
            "Epoch 506/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7809 - accuracy: 0.6586 - val_loss: 0.8229 - val_accuracy: 0.6258\n",
            "Epoch 507/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7782 - accuracy: 0.6583 - val_loss: 0.8417 - val_accuracy: 0.6079\n",
            "Epoch 508/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7847 - accuracy: 0.6516 - val_loss: 0.8608 - val_accuracy: 0.5966\n",
            "Epoch 509/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7827 - accuracy: 0.6507 - val_loss: 0.8248 - val_accuracy: 0.6247\n",
            "Epoch 510/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7851 - accuracy: 0.6507 - val_loss: 0.8308 - val_accuracy: 0.6236\n",
            "Epoch 511/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7793 - accuracy: 0.6535 - val_loss: 0.8264 - val_accuracy: 0.6337\n",
            "Epoch 512/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7839 - accuracy: 0.6533 - val_loss: 0.8235 - val_accuracy: 0.6258\n",
            "Epoch 513/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7832 - accuracy: 0.6533 - val_loss: 0.8398 - val_accuracy: 0.5910\n",
            "Epoch 514/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7800 - accuracy: 0.6614 - val_loss: 0.8332 - val_accuracy: 0.6067\n",
            "Epoch 515/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7783 - accuracy: 0.6558 - val_loss: 0.8371 - val_accuracy: 0.6112\n",
            "Epoch 516/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7814 - accuracy: 0.6569 - val_loss: 0.8235 - val_accuracy: 0.6427\n",
            "Epoch 517/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7816 - accuracy: 0.6558 - val_loss: 0.8303 - val_accuracy: 0.6079\n",
            "Epoch 518/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7778 - accuracy: 0.6597 - val_loss: 0.8247 - val_accuracy: 0.6202\n",
            "Epoch 519/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7800 - accuracy: 0.6558 - val_loss: 0.8216 - val_accuracy: 0.6281\n",
            "Epoch 520/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7788 - accuracy: 0.6589 - val_loss: 0.8222 - val_accuracy: 0.6404\n",
            "Epoch 521/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7782 - accuracy: 0.6648 - val_loss: 0.8200 - val_accuracy: 0.6427\n",
            "Epoch 522/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7835 - accuracy: 0.6457 - val_loss: 0.8279 - val_accuracy: 0.6146\n",
            "Epoch 523/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7813 - accuracy: 0.6569 - val_loss: 0.8202 - val_accuracy: 0.6393\n",
            "Epoch 524/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7837 - accuracy: 0.6533 - val_loss: 0.8233 - val_accuracy: 0.6281\n",
            "Epoch 525/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7819 - accuracy: 0.6592 - val_loss: 0.8237 - val_accuracy: 0.6393\n",
            "Epoch 526/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7801 - accuracy: 0.6597 - val_loss: 0.8223 - val_accuracy: 0.6191\n",
            "Epoch 527/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7783 - accuracy: 0.6578 - val_loss: 0.8287 - val_accuracy: 0.6236\n",
            "Epoch 528/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7803 - accuracy: 0.6561 - val_loss: 0.8547 - val_accuracy: 0.5820\n",
            "Epoch 529/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7803 - accuracy: 0.6533 - val_loss: 0.8200 - val_accuracy: 0.6382\n",
            "Epoch 530/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7817 - accuracy: 0.6521 - val_loss: 0.8296 - val_accuracy: 0.6045\n",
            "Epoch 531/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7770 - accuracy: 0.6541 - val_loss: 0.8475 - val_accuracy: 0.5944\n",
            "Epoch 532/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7802 - accuracy: 0.6569 - val_loss: 0.8339 - val_accuracy: 0.6011\n",
            "Epoch 533/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7793 - accuracy: 0.6564 - val_loss: 0.8346 - val_accuracy: 0.6090\n",
            "Epoch 534/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7786 - accuracy: 0.6564 - val_loss: 0.8295 - val_accuracy: 0.6135\n",
            "Epoch 535/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7765 - accuracy: 0.6589 - val_loss: 0.8308 - val_accuracy: 0.6213\n",
            "Epoch 536/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7790 - accuracy: 0.6569 - val_loss: 0.8406 - val_accuracy: 0.5921\n",
            "Epoch 537/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7782 - accuracy: 0.6564 - val_loss: 0.8235 - val_accuracy: 0.6360\n",
            "Epoch 538/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7799 - accuracy: 0.6564 - val_loss: 0.8199 - val_accuracy: 0.6292\n",
            "Epoch 539/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7770 - accuracy: 0.6597 - val_loss: 0.8420 - val_accuracy: 0.5933\n",
            "Epoch 540/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7791 - accuracy: 0.6566 - val_loss: 0.8314 - val_accuracy: 0.6157\n",
            "Epoch 541/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7753 - accuracy: 0.6628 - val_loss: 0.8315 - val_accuracy: 0.6090\n",
            "Epoch 542/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7794 - accuracy: 0.6634 - val_loss: 0.8317 - val_accuracy: 0.6146\n",
            "Epoch 543/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7784 - accuracy: 0.6631 - val_loss: 0.8266 - val_accuracy: 0.6124\n",
            "Epoch 544/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7824 - accuracy: 0.6575 - val_loss: 0.8195 - val_accuracy: 0.6292\n",
            "Epoch 545/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7767 - accuracy: 0.6547 - val_loss: 0.8225 - val_accuracy: 0.6247\n",
            "Epoch 546/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7770 - accuracy: 0.6549 - val_loss: 0.8283 - val_accuracy: 0.6135\n",
            "Epoch 547/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7811 - accuracy: 0.6580 - val_loss: 0.8190 - val_accuracy: 0.6427\n",
            "Epoch 548/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7765 - accuracy: 0.6524 - val_loss: 0.8197 - val_accuracy: 0.6315\n",
            "Epoch 549/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7750 - accuracy: 0.6625 - val_loss: 0.8189 - val_accuracy: 0.6303\n",
            "Epoch 550/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7772 - accuracy: 0.6654 - val_loss: 0.8198 - val_accuracy: 0.6348\n",
            "Epoch 551/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7758 - accuracy: 0.6611 - val_loss: 0.8202 - val_accuracy: 0.6258\n",
            "Epoch 552/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7771 - accuracy: 0.6586 - val_loss: 0.8225 - val_accuracy: 0.6281\n",
            "Epoch 553/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7778 - accuracy: 0.6575 - val_loss: 0.8226 - val_accuracy: 0.6258\n",
            "Epoch 554/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7781 - accuracy: 0.6586 - val_loss: 0.8221 - val_accuracy: 0.6472\n",
            "Epoch 555/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7813 - accuracy: 0.6544 - val_loss: 0.8242 - val_accuracy: 0.6157\n",
            "Epoch 556/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7780 - accuracy: 0.6600 - val_loss: 0.8251 - val_accuracy: 0.6191\n",
            "Epoch 557/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7765 - accuracy: 0.6586 - val_loss: 0.8298 - val_accuracy: 0.6135\n",
            "Epoch 558/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7778 - accuracy: 0.6609 - val_loss: 0.8260 - val_accuracy: 0.6169\n",
            "Epoch 559/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7754 - accuracy: 0.6594 - val_loss: 0.8205 - val_accuracy: 0.6337\n",
            "Epoch 560/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7835 - accuracy: 0.6533 - val_loss: 0.8268 - val_accuracy: 0.6270\n",
            "Epoch 561/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7777 - accuracy: 0.6603 - val_loss: 0.8235 - val_accuracy: 0.6348\n",
            "Epoch 562/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7767 - accuracy: 0.6609 - val_loss: 0.8231 - val_accuracy: 0.6236\n",
            "Epoch 563/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7739 - accuracy: 0.6614 - val_loss: 0.8194 - val_accuracy: 0.6315\n",
            "Epoch 564/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7758 - accuracy: 0.6578 - val_loss: 0.8220 - val_accuracy: 0.6371\n",
            "Epoch 565/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7763 - accuracy: 0.6623 - val_loss: 0.8211 - val_accuracy: 0.6371\n",
            "Epoch 566/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7782 - accuracy: 0.6600 - val_loss: 0.8295 - val_accuracy: 0.6079\n",
            "Epoch 567/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7770 - accuracy: 0.6625 - val_loss: 0.8237 - val_accuracy: 0.6270\n",
            "Epoch 568/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7744 - accuracy: 0.6594 - val_loss: 0.8197 - val_accuracy: 0.6326\n",
            "Epoch 569/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7766 - accuracy: 0.6578 - val_loss: 0.8279 - val_accuracy: 0.6270\n",
            "Epoch 570/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7748 - accuracy: 0.6676 - val_loss: 0.8402 - val_accuracy: 0.5944\n",
            "Epoch 571/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7752 - accuracy: 0.6617 - val_loss: 0.8229 - val_accuracy: 0.6281\n",
            "Epoch 572/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7762 - accuracy: 0.6561 - val_loss: 0.8242 - val_accuracy: 0.6180\n",
            "Epoch 573/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7753 - accuracy: 0.6597 - val_loss: 0.8351 - val_accuracy: 0.5955\n",
            "Epoch 574/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7787 - accuracy: 0.6566 - val_loss: 0.8239 - val_accuracy: 0.6258\n",
            "Epoch 575/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7788 - accuracy: 0.6558 - val_loss: 0.8237 - val_accuracy: 0.6393\n",
            "Epoch 576/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7762 - accuracy: 0.6583 - val_loss: 0.8324 - val_accuracy: 0.6079\n",
            "Epoch 577/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7832 - accuracy: 0.6524 - val_loss: 0.8202 - val_accuracy: 0.6382\n",
            "Epoch 578/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7778 - accuracy: 0.6538 - val_loss: 0.8291 - val_accuracy: 0.6034\n",
            "Epoch 579/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7773 - accuracy: 0.6547 - val_loss: 0.8281 - val_accuracy: 0.6371\n",
            "Epoch 580/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7775 - accuracy: 0.6541 - val_loss: 0.8260 - val_accuracy: 0.6393\n",
            "Epoch 581/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7795 - accuracy: 0.6592 - val_loss: 0.8338 - val_accuracy: 0.5978\n",
            "Epoch 582/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7781 - accuracy: 0.6592 - val_loss: 0.8257 - val_accuracy: 0.6348\n",
            "Epoch 583/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7757 - accuracy: 0.6569 - val_loss: 0.8208 - val_accuracy: 0.6326\n",
            "Epoch 584/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7742 - accuracy: 0.6606 - val_loss: 0.8335 - val_accuracy: 0.6056\n",
            "Epoch 585/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7730 - accuracy: 0.6645 - val_loss: 0.8205 - val_accuracy: 0.6382\n",
            "Epoch 586/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7768 - accuracy: 0.6614 - val_loss: 0.8267 - val_accuracy: 0.6157\n",
            "Epoch 587/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7757 - accuracy: 0.6586 - val_loss: 0.8304 - val_accuracy: 0.6258\n",
            "Epoch 588/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7757 - accuracy: 0.6578 - val_loss: 0.8203 - val_accuracy: 0.6393\n",
            "Epoch 589/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7752 - accuracy: 0.6597 - val_loss: 0.8339 - val_accuracy: 0.6045\n",
            "Epoch 590/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7768 - accuracy: 0.6600 - val_loss: 0.8271 - val_accuracy: 0.6191\n",
            "Epoch 591/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7731 - accuracy: 0.6634 - val_loss: 0.8212 - val_accuracy: 0.6360\n",
            "Epoch 592/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7735 - accuracy: 0.6623 - val_loss: 0.8223 - val_accuracy: 0.6258\n",
            "Epoch 593/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7746 - accuracy: 0.6617 - val_loss: 0.8366 - val_accuracy: 0.6034\n",
            "Epoch 594/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7736 - accuracy: 0.6600 - val_loss: 0.8245 - val_accuracy: 0.6236\n",
            "Epoch 595/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7720 - accuracy: 0.6634 - val_loss: 0.8258 - val_accuracy: 0.6416\n",
            "Epoch 596/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7763 - accuracy: 0.6572 - val_loss: 0.8393 - val_accuracy: 0.6011\n",
            "Epoch 597/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7783 - accuracy: 0.6561 - val_loss: 0.8238 - val_accuracy: 0.6337\n",
            "Epoch 598/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7721 - accuracy: 0.6617 - val_loss: 0.8329 - val_accuracy: 0.6022\n",
            "Epoch 599/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7742 - accuracy: 0.6552 - val_loss: 0.8231 - val_accuracy: 0.6213\n",
            "Epoch 600/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7777 - accuracy: 0.6535 - val_loss: 0.8300 - val_accuracy: 0.6303\n",
            "Epoch 601/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7757 - accuracy: 0.6589 - val_loss: 0.8340 - val_accuracy: 0.6236\n",
            "Epoch 602/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7744 - accuracy: 0.6614 - val_loss: 0.8460 - val_accuracy: 0.5955\n",
            "Epoch 603/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7760 - accuracy: 0.6648 - val_loss: 0.8241 - val_accuracy: 0.6438\n",
            "Epoch 604/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7771 - accuracy: 0.6549 - val_loss: 0.8304 - val_accuracy: 0.6135\n",
            "Epoch 605/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7786 - accuracy: 0.6513 - val_loss: 0.8312 - val_accuracy: 0.6180\n",
            "Epoch 606/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7750 - accuracy: 0.6592 - val_loss: 0.8253 - val_accuracy: 0.6337\n",
            "Epoch 607/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7725 - accuracy: 0.6606 - val_loss: 0.8234 - val_accuracy: 0.6303\n",
            "Epoch 608/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7732 - accuracy: 0.6586 - val_loss: 0.8403 - val_accuracy: 0.6124\n",
            "Epoch 609/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7730 - accuracy: 0.6592 - val_loss: 0.8184 - val_accuracy: 0.6348\n",
            "Epoch 610/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7723 - accuracy: 0.6639 - val_loss: 0.8395 - val_accuracy: 0.6045\n",
            "Epoch 611/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7732 - accuracy: 0.6614 - val_loss: 0.8240 - val_accuracy: 0.6303\n",
            "Epoch 612/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7736 - accuracy: 0.6603 - val_loss: 0.8224 - val_accuracy: 0.6371\n",
            "Epoch 613/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7783 - accuracy: 0.6558 - val_loss: 0.8224 - val_accuracy: 0.6191\n",
            "Epoch 614/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7738 - accuracy: 0.6617 - val_loss: 0.8264 - val_accuracy: 0.6213\n",
            "Epoch 615/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7724 - accuracy: 0.6634 - val_loss: 0.8274 - val_accuracy: 0.6079\n",
            "Epoch 616/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7732 - accuracy: 0.6594 - val_loss: 0.8231 - val_accuracy: 0.6371\n",
            "Epoch 617/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7761 - accuracy: 0.6533 - val_loss: 0.8248 - val_accuracy: 0.6258\n",
            "Epoch 618/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7725 - accuracy: 0.6589 - val_loss: 0.8411 - val_accuracy: 0.5933\n",
            "Epoch 619/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7718 - accuracy: 0.6634 - val_loss: 0.8271 - val_accuracy: 0.6146\n",
            "Epoch 620/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7794 - accuracy: 0.6544 - val_loss: 0.8231 - val_accuracy: 0.6337\n",
            "Epoch 621/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7727 - accuracy: 0.6648 - val_loss: 0.8227 - val_accuracy: 0.6281\n",
            "Epoch 622/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7739 - accuracy: 0.6611 - val_loss: 0.8209 - val_accuracy: 0.6326\n",
            "Epoch 623/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7733 - accuracy: 0.6625 - val_loss: 0.8429 - val_accuracy: 0.6022\n",
            "Epoch 624/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7764 - accuracy: 0.6583 - val_loss: 0.8294 - val_accuracy: 0.6169\n",
            "Epoch 625/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7745 - accuracy: 0.6566 - val_loss: 0.8328 - val_accuracy: 0.6247\n",
            "Epoch 626/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7772 - accuracy: 0.6544 - val_loss: 0.8246 - val_accuracy: 0.6135\n",
            "Epoch 627/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7714 - accuracy: 0.6594 - val_loss: 0.8225 - val_accuracy: 0.6337\n",
            "Epoch 628/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7725 - accuracy: 0.6575 - val_loss: 0.8284 - val_accuracy: 0.6112\n",
            "Epoch 629/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7729 - accuracy: 0.6639 - val_loss: 0.8216 - val_accuracy: 0.6360\n",
            "Epoch 630/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7735 - accuracy: 0.6600 - val_loss: 0.8210 - val_accuracy: 0.6270\n",
            "Epoch 631/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7701 - accuracy: 0.6668 - val_loss: 0.8424 - val_accuracy: 0.5933\n",
            "Epoch 632/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7755 - accuracy: 0.6524 - val_loss: 0.8323 - val_accuracy: 0.6090\n",
            "Epoch 633/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7727 - accuracy: 0.6586 - val_loss: 0.8195 - val_accuracy: 0.6360\n",
            "Epoch 634/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7705 - accuracy: 0.6617 - val_loss: 0.8240 - val_accuracy: 0.6213\n",
            "Epoch 635/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7697 - accuracy: 0.6648 - val_loss: 0.8307 - val_accuracy: 0.6112\n",
            "Epoch 636/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7742 - accuracy: 0.6575 - val_loss: 0.8189 - val_accuracy: 0.6303\n",
            "Epoch 637/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7711 - accuracy: 0.6594 - val_loss: 0.8234 - val_accuracy: 0.6348\n",
            "Epoch 638/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7712 - accuracy: 0.6578 - val_loss: 0.8271 - val_accuracy: 0.6281\n",
            "Epoch 639/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7741 - accuracy: 0.6606 - val_loss: 0.8253 - val_accuracy: 0.6404\n",
            "Epoch 640/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7739 - accuracy: 0.6611 - val_loss: 0.8527 - val_accuracy: 0.5989\n",
            "Epoch 641/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7734 - accuracy: 0.6572 - val_loss: 0.8200 - val_accuracy: 0.6303\n",
            "Epoch 642/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7723 - accuracy: 0.6594 - val_loss: 0.8376 - val_accuracy: 0.6056\n",
            "Epoch 643/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7714 - accuracy: 0.6569 - val_loss: 0.8259 - val_accuracy: 0.6180\n",
            "Epoch 644/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7761 - accuracy: 0.6589 - val_loss: 0.8376 - val_accuracy: 0.6056\n",
            "Epoch 645/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7716 - accuracy: 0.6651 - val_loss: 0.8197 - val_accuracy: 0.6360\n",
            "Epoch 646/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7705 - accuracy: 0.6578 - val_loss: 0.8275 - val_accuracy: 0.6382\n",
            "Epoch 647/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7725 - accuracy: 0.6589 - val_loss: 0.8343 - val_accuracy: 0.6022\n",
            "Epoch 648/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7729 - accuracy: 0.6589 - val_loss: 0.8186 - val_accuracy: 0.6427\n",
            "Epoch 649/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7714 - accuracy: 0.6620 - val_loss: 0.8388 - val_accuracy: 0.6090\n",
            "Epoch 650/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7776 - accuracy: 0.6535 - val_loss: 0.8255 - val_accuracy: 0.6281\n",
            "Epoch 651/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7735 - accuracy: 0.6586 - val_loss: 0.8318 - val_accuracy: 0.6090\n",
            "Epoch 652/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7732 - accuracy: 0.6564 - val_loss: 0.8263 - val_accuracy: 0.6247\n",
            "Epoch 653/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7699 - accuracy: 0.6656 - val_loss: 0.8197 - val_accuracy: 0.6371\n",
            "Epoch 654/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7685 - accuracy: 0.6634 - val_loss: 0.8219 - val_accuracy: 0.6337\n",
            "Epoch 655/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7716 - accuracy: 0.6538 - val_loss: 0.8339 - val_accuracy: 0.6112\n",
            "Epoch 656/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7795 - accuracy: 0.6558 - val_loss: 0.8242 - val_accuracy: 0.6337\n",
            "Epoch 657/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7730 - accuracy: 0.6656 - val_loss: 0.8284 - val_accuracy: 0.6146\n",
            "Epoch 658/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7705 - accuracy: 0.6637 - val_loss: 0.8227 - val_accuracy: 0.6236\n",
            "Epoch 659/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7803 - accuracy: 0.6549 - val_loss: 0.8297 - val_accuracy: 0.6067\n",
            "Epoch 660/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7720 - accuracy: 0.6609 - val_loss: 0.8321 - val_accuracy: 0.6112\n",
            "Epoch 661/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7690 - accuracy: 0.6592 - val_loss: 0.8367 - val_accuracy: 0.6034\n",
            "Epoch 662/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7754 - accuracy: 0.6628 - val_loss: 0.8299 - val_accuracy: 0.6056\n",
            "Epoch 663/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7697 - accuracy: 0.6597 - val_loss: 0.8185 - val_accuracy: 0.6360\n",
            "Epoch 664/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7708 - accuracy: 0.6648 - val_loss: 0.8268 - val_accuracy: 0.6202\n",
            "Epoch 665/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7701 - accuracy: 0.6654 - val_loss: 0.8198 - val_accuracy: 0.6292\n",
            "Epoch 666/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7690 - accuracy: 0.6589 - val_loss: 0.8336 - val_accuracy: 0.6112\n",
            "Epoch 667/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7722 - accuracy: 0.6611 - val_loss: 0.8315 - val_accuracy: 0.6202\n",
            "Epoch 668/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7705 - accuracy: 0.6625 - val_loss: 0.8300 - val_accuracy: 0.6157\n",
            "Epoch 669/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7697 - accuracy: 0.6634 - val_loss: 0.8316 - val_accuracy: 0.6045\n",
            "Epoch 670/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7689 - accuracy: 0.6651 - val_loss: 0.8261 - val_accuracy: 0.6258\n",
            "Epoch 671/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7739 - accuracy: 0.6614 - val_loss: 0.8324 - val_accuracy: 0.6056\n",
            "Epoch 672/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7718 - accuracy: 0.6564 - val_loss: 0.8268 - val_accuracy: 0.6202\n",
            "Epoch 673/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7704 - accuracy: 0.6597 - val_loss: 0.8276 - val_accuracy: 0.6135\n",
            "Epoch 674/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7722 - accuracy: 0.6614 - val_loss: 0.8333 - val_accuracy: 0.6348\n",
            "Epoch 675/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7735 - accuracy: 0.6611 - val_loss: 0.8460 - val_accuracy: 0.6045\n",
            "Epoch 676/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7797 - accuracy: 0.6580 - val_loss: 0.8359 - val_accuracy: 0.6157\n",
            "Epoch 677/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7719 - accuracy: 0.6609 - val_loss: 0.8163 - val_accuracy: 0.6360\n",
            "Epoch 678/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7731 - accuracy: 0.6617 - val_loss: 0.8262 - val_accuracy: 0.6169\n",
            "Epoch 679/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7705 - accuracy: 0.6648 - val_loss: 0.8269 - val_accuracy: 0.6146\n",
            "Epoch 680/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7708 - accuracy: 0.6642 - val_loss: 0.8303 - val_accuracy: 0.6101\n",
            "Epoch 681/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7666 - accuracy: 0.6645 - val_loss: 0.8456 - val_accuracy: 0.6000\n",
            "Epoch 682/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7711 - accuracy: 0.6592 - val_loss: 0.8321 - val_accuracy: 0.6135\n",
            "Epoch 683/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7687 - accuracy: 0.6623 - val_loss: 0.8415 - val_accuracy: 0.6045\n",
            "Epoch 684/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7697 - accuracy: 0.6637 - val_loss: 0.8247 - val_accuracy: 0.6146\n",
            "Epoch 685/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7704 - accuracy: 0.6603 - val_loss: 0.8314 - val_accuracy: 0.6258\n",
            "Epoch 686/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7677 - accuracy: 0.6575 - val_loss: 0.8238 - val_accuracy: 0.6202\n",
            "Epoch 687/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7706 - accuracy: 0.6589 - val_loss: 0.8331 - val_accuracy: 0.6067\n",
            "Epoch 688/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7695 - accuracy: 0.6620 - val_loss: 0.8256 - val_accuracy: 0.6191\n",
            "Epoch 689/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7686 - accuracy: 0.6639 - val_loss: 0.8210 - val_accuracy: 0.6315\n",
            "Epoch 690/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7696 - accuracy: 0.6631 - val_loss: 0.8408 - val_accuracy: 0.6034\n",
            "Epoch 691/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7712 - accuracy: 0.6594 - val_loss: 0.8327 - val_accuracy: 0.6157\n",
            "Epoch 692/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7695 - accuracy: 0.6645 - val_loss: 0.8300 - val_accuracy: 0.6225\n",
            "Epoch 693/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7709 - accuracy: 0.6656 - val_loss: 0.8195 - val_accuracy: 0.6404\n",
            "Epoch 694/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7699 - accuracy: 0.6676 - val_loss: 0.8446 - val_accuracy: 0.6011\n",
            "Epoch 695/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7717 - accuracy: 0.6609 - val_loss: 0.8501 - val_accuracy: 0.5910\n",
            "Epoch 696/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7753 - accuracy: 0.6569 - val_loss: 0.8245 - val_accuracy: 0.6247\n",
            "Epoch 697/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7803 - accuracy: 0.6504 - val_loss: 0.8276 - val_accuracy: 0.6404\n",
            "Epoch 698/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7697 - accuracy: 0.6592 - val_loss: 0.8194 - val_accuracy: 0.6382\n",
            "Epoch 699/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7678 - accuracy: 0.6628 - val_loss: 0.8255 - val_accuracy: 0.6258\n",
            "Epoch 700/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7697 - accuracy: 0.6625 - val_loss: 0.8362 - val_accuracy: 0.6124\n",
            "Epoch 701/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7750 - accuracy: 0.6642 - val_loss: 0.8248 - val_accuracy: 0.6270\n",
            "Epoch 702/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7668 - accuracy: 0.6625 - val_loss: 0.8317 - val_accuracy: 0.6191\n",
            "Epoch 703/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7687 - accuracy: 0.6611 - val_loss: 0.8447 - val_accuracy: 0.5978\n",
            "Epoch 704/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7700 - accuracy: 0.6609 - val_loss: 0.8295 - val_accuracy: 0.6112\n",
            "Epoch 705/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7699 - accuracy: 0.6592 - val_loss: 0.8252 - val_accuracy: 0.6236\n",
            "Epoch 706/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7674 - accuracy: 0.6611 - val_loss: 0.8268 - val_accuracy: 0.6393\n",
            "Epoch 707/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7714 - accuracy: 0.6639 - val_loss: 0.8279 - val_accuracy: 0.6090\n",
            "Epoch 708/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7734 - accuracy: 0.6606 - val_loss: 0.8210 - val_accuracy: 0.6427\n",
            "Epoch 709/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7672 - accuracy: 0.6679 - val_loss: 0.8423 - val_accuracy: 0.6011\n",
            "Epoch 710/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7703 - accuracy: 0.6586 - val_loss: 0.8639 - val_accuracy: 0.6135\n",
            "Epoch 711/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7753 - accuracy: 0.6535 - val_loss: 0.8345 - val_accuracy: 0.6146\n",
            "Epoch 712/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7659 - accuracy: 0.6648 - val_loss: 0.8395 - val_accuracy: 0.6000\n",
            "Epoch 713/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7672 - accuracy: 0.6670 - val_loss: 0.8204 - val_accuracy: 0.6404\n",
            "Epoch 714/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7678 - accuracy: 0.6614 - val_loss: 0.8338 - val_accuracy: 0.6124\n",
            "Epoch 715/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7725 - accuracy: 0.6538 - val_loss: 0.8257 - val_accuracy: 0.6337\n",
            "Epoch 716/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7724 - accuracy: 0.6614 - val_loss: 0.8227 - val_accuracy: 0.6281\n",
            "Epoch 717/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7668 - accuracy: 0.6654 - val_loss: 0.8271 - val_accuracy: 0.6135\n",
            "Epoch 718/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7724 - accuracy: 0.6564 - val_loss: 0.8241 - val_accuracy: 0.6315\n",
            "Epoch 719/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7711 - accuracy: 0.6586 - val_loss: 0.8382 - val_accuracy: 0.6067\n",
            "Epoch 720/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7685 - accuracy: 0.6637 - val_loss: 0.8217 - val_accuracy: 0.6315\n",
            "Epoch 721/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7655 - accuracy: 0.6701 - val_loss: 0.8267 - val_accuracy: 0.6371\n",
            "Epoch 722/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7682 - accuracy: 0.6589 - val_loss: 0.8245 - val_accuracy: 0.6292\n",
            "Epoch 723/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7667 - accuracy: 0.6651 - val_loss: 0.8295 - val_accuracy: 0.6101\n",
            "Epoch 724/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7678 - accuracy: 0.6659 - val_loss: 0.8303 - val_accuracy: 0.6236\n",
            "Epoch 725/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7727 - accuracy: 0.6637 - val_loss: 0.8272 - val_accuracy: 0.6169\n",
            "Epoch 726/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7673 - accuracy: 0.6642 - val_loss: 0.8219 - val_accuracy: 0.6258\n",
            "Epoch 727/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7678 - accuracy: 0.6690 - val_loss: 0.8309 - val_accuracy: 0.6202\n",
            "Epoch 728/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7677 - accuracy: 0.6682 - val_loss: 0.8352 - val_accuracy: 0.6045\n",
            "Epoch 729/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7748 - accuracy: 0.6572 - val_loss: 0.8451 - val_accuracy: 0.6022\n",
            "Epoch 730/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7683 - accuracy: 0.6617 - val_loss: 0.8294 - val_accuracy: 0.6135\n",
            "Epoch 731/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7673 - accuracy: 0.6606 - val_loss: 0.8260 - val_accuracy: 0.6236\n",
            "Epoch 732/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7651 - accuracy: 0.6693 - val_loss: 0.8223 - val_accuracy: 0.6292\n",
            "Epoch 733/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7675 - accuracy: 0.6659 - val_loss: 0.8323 - val_accuracy: 0.6135\n",
            "Epoch 734/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7708 - accuracy: 0.6634 - val_loss: 0.8280 - val_accuracy: 0.6213\n",
            "Epoch 735/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7665 - accuracy: 0.6656 - val_loss: 0.8349 - val_accuracy: 0.6045\n",
            "Epoch 736/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7690 - accuracy: 0.6597 - val_loss: 0.8349 - val_accuracy: 0.6079\n",
            "Epoch 737/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7661 - accuracy: 0.6648 - val_loss: 0.8266 - val_accuracy: 0.6281\n",
            "Epoch 738/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7706 - accuracy: 0.6634 - val_loss: 0.8344 - val_accuracy: 0.6157\n",
            "Epoch 739/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7757 - accuracy: 0.6555 - val_loss: 0.8285 - val_accuracy: 0.6281\n",
            "Epoch 740/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7697 - accuracy: 0.6620 - val_loss: 0.8216 - val_accuracy: 0.6416\n",
            "Epoch 741/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7706 - accuracy: 0.6654 - val_loss: 0.8292 - val_accuracy: 0.6157\n",
            "Epoch 742/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7648 - accuracy: 0.6684 - val_loss: 0.8261 - val_accuracy: 0.6404\n",
            "Epoch 743/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7665 - accuracy: 0.6673 - val_loss: 0.8433 - val_accuracy: 0.6045\n",
            "Epoch 744/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7713 - accuracy: 0.6589 - val_loss: 0.8215 - val_accuracy: 0.6303\n",
            "Epoch 745/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7652 - accuracy: 0.6662 - val_loss: 0.8221 - val_accuracy: 0.6337\n",
            "Epoch 746/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7657 - accuracy: 0.6676 - val_loss: 0.8385 - val_accuracy: 0.6213\n",
            "Epoch 747/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7711 - accuracy: 0.6609 - val_loss: 0.8312 - val_accuracy: 0.6157\n",
            "Epoch 748/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7665 - accuracy: 0.6656 - val_loss: 0.8428 - val_accuracy: 0.6090\n",
            "Epoch 749/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7758 - accuracy: 0.6527 - val_loss: 0.8253 - val_accuracy: 0.6360\n",
            "Epoch 750/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7686 - accuracy: 0.6603 - val_loss: 0.8284 - val_accuracy: 0.6169\n",
            "Epoch 751/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7652 - accuracy: 0.6690 - val_loss: 0.8300 - val_accuracy: 0.6382\n",
            "Epoch 752/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7688 - accuracy: 0.6623 - val_loss: 0.8426 - val_accuracy: 0.6022\n",
            "Epoch 753/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7700 - accuracy: 0.6617 - val_loss: 0.8194 - val_accuracy: 0.6292\n",
            "Epoch 754/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7664 - accuracy: 0.6651 - val_loss: 0.8358 - val_accuracy: 0.6135\n",
            "Epoch 755/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7684 - accuracy: 0.6631 - val_loss: 0.8220 - val_accuracy: 0.6292\n",
            "Epoch 756/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7655 - accuracy: 0.6682 - val_loss: 0.8206 - val_accuracy: 0.6326\n",
            "Epoch 757/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7664 - accuracy: 0.6634 - val_loss: 0.8255 - val_accuracy: 0.6180\n",
            "Epoch 758/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7674 - accuracy: 0.6600 - val_loss: 0.8438 - val_accuracy: 0.6011\n",
            "Epoch 759/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7655 - accuracy: 0.6620 - val_loss: 0.8348 - val_accuracy: 0.6112\n",
            "Epoch 760/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7648 - accuracy: 0.6609 - val_loss: 0.8259 - val_accuracy: 0.6258\n",
            "Epoch 761/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7649 - accuracy: 0.6631 - val_loss: 0.8243 - val_accuracy: 0.6416\n",
            "Epoch 762/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7670 - accuracy: 0.6617 - val_loss: 0.8460 - val_accuracy: 0.6056\n",
            "Epoch 763/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7653 - accuracy: 0.6659 - val_loss: 0.8468 - val_accuracy: 0.6034\n",
            "Epoch 764/2000\n",
            "56/56 [==============================] - 1s 13ms/step - loss: 0.7646 - accuracy: 0.6625 - val_loss: 0.8221 - val_accuracy: 0.6360\n",
            "Epoch 765/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7649 - accuracy: 0.6673 - val_loss: 0.8526 - val_accuracy: 0.5933\n",
            "Epoch 766/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7676 - accuracy: 0.6628 - val_loss: 0.8337 - val_accuracy: 0.6135\n",
            "Epoch 767/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7660 - accuracy: 0.6682 - val_loss: 0.8298 - val_accuracy: 0.6213\n",
            "Epoch 768/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7634 - accuracy: 0.6659 - val_loss: 0.8310 - val_accuracy: 0.6371\n",
            "Epoch 769/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7660 - accuracy: 0.6639 - val_loss: 0.8257 - val_accuracy: 0.6292\n",
            "Epoch 770/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7643 - accuracy: 0.6631 - val_loss: 0.8223 - val_accuracy: 0.6348\n",
            "Epoch 771/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7657 - accuracy: 0.6594 - val_loss: 0.8436 - val_accuracy: 0.6011\n",
            "Epoch 772/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7661 - accuracy: 0.6654 - val_loss: 0.8214 - val_accuracy: 0.6281\n",
            "Epoch 773/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7626 - accuracy: 0.6741 - val_loss: 0.8227 - val_accuracy: 0.6303\n",
            "Epoch 774/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7639 - accuracy: 0.6637 - val_loss: 0.8272 - val_accuracy: 0.6337\n",
            "Epoch 775/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7649 - accuracy: 0.6625 - val_loss: 0.8222 - val_accuracy: 0.6270\n",
            "Epoch 776/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7695 - accuracy: 0.6648 - val_loss: 0.8386 - val_accuracy: 0.6124\n",
            "Epoch 777/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7680 - accuracy: 0.6623 - val_loss: 0.8377 - val_accuracy: 0.6112\n",
            "Epoch 778/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7631 - accuracy: 0.6665 - val_loss: 0.8254 - val_accuracy: 0.6360\n",
            "Epoch 779/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7712 - accuracy: 0.6569 - val_loss: 0.8667 - val_accuracy: 0.5921\n",
            "Epoch 780/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7654 - accuracy: 0.6656 - val_loss: 0.8287 - val_accuracy: 0.6191\n",
            "Epoch 781/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7651 - accuracy: 0.6679 - val_loss: 0.8305 - val_accuracy: 0.6124\n",
            "Epoch 782/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7699 - accuracy: 0.6589 - val_loss: 0.8301 - val_accuracy: 0.6124\n",
            "Epoch 783/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7629 - accuracy: 0.6707 - val_loss: 0.8365 - val_accuracy: 0.6079\n",
            "Epoch 784/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7635 - accuracy: 0.6699 - val_loss: 0.8396 - val_accuracy: 0.6090\n",
            "Epoch 785/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7686 - accuracy: 0.6639 - val_loss: 0.8341 - val_accuracy: 0.6079\n",
            "Epoch 786/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7637 - accuracy: 0.6670 - val_loss: 0.8301 - val_accuracy: 0.6326\n",
            "Epoch 787/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7642 - accuracy: 0.6651 - val_loss: 0.8242 - val_accuracy: 0.6270\n",
            "Epoch 788/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7618 - accuracy: 0.6673 - val_loss: 0.8480 - val_accuracy: 0.6056\n",
            "Epoch 789/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7640 - accuracy: 0.6631 - val_loss: 0.8348 - val_accuracy: 0.6146\n",
            "Epoch 790/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7623 - accuracy: 0.6648 - val_loss: 0.8494 - val_accuracy: 0.6146\n",
            "Epoch 791/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7667 - accuracy: 0.6639 - val_loss: 0.8319 - val_accuracy: 0.6169\n",
            "Epoch 792/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7624 - accuracy: 0.6656 - val_loss: 0.8400 - val_accuracy: 0.6022\n",
            "Epoch 793/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7635 - accuracy: 0.6670 - val_loss: 0.8290 - val_accuracy: 0.6281\n",
            "Epoch 794/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7632 - accuracy: 0.6713 - val_loss: 0.8340 - val_accuracy: 0.6112\n",
            "Epoch 795/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7666 - accuracy: 0.6648 - val_loss: 0.8252 - val_accuracy: 0.6315\n",
            "Epoch 796/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7624 - accuracy: 0.6628 - val_loss: 0.8278 - val_accuracy: 0.6247\n",
            "Epoch 797/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7623 - accuracy: 0.6628 - val_loss: 0.8257 - val_accuracy: 0.6404\n",
            "Epoch 798/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7629 - accuracy: 0.6639 - val_loss: 0.8350 - val_accuracy: 0.6124\n",
            "Epoch 799/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7616 - accuracy: 0.6684 - val_loss: 0.8318 - val_accuracy: 0.6146\n",
            "Epoch 800/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7612 - accuracy: 0.6682 - val_loss: 0.8382 - val_accuracy: 0.6135\n",
            "Epoch 801/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7632 - accuracy: 0.6642 - val_loss: 0.8248 - val_accuracy: 0.6270\n",
            "Epoch 802/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7619 - accuracy: 0.6628 - val_loss: 0.8343 - val_accuracy: 0.6169\n",
            "Epoch 803/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7609 - accuracy: 0.6687 - val_loss: 0.8272 - val_accuracy: 0.6303\n",
            "Epoch 804/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7625 - accuracy: 0.6659 - val_loss: 0.8234 - val_accuracy: 0.6225\n",
            "Epoch 805/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7651 - accuracy: 0.6656 - val_loss: 0.8301 - val_accuracy: 0.6281\n",
            "Epoch 806/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7626 - accuracy: 0.6701 - val_loss: 0.8243 - val_accuracy: 0.6337\n",
            "Epoch 807/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7628 - accuracy: 0.6648 - val_loss: 0.8282 - val_accuracy: 0.6382\n",
            "Epoch 808/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7616 - accuracy: 0.6662 - val_loss: 0.8258 - val_accuracy: 0.6360\n",
            "Epoch 809/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7635 - accuracy: 0.6693 - val_loss: 0.8288 - val_accuracy: 0.6258\n",
            "Epoch 810/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7603 - accuracy: 0.6670 - val_loss: 0.8246 - val_accuracy: 0.6393\n",
            "Epoch 811/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7636 - accuracy: 0.6651 - val_loss: 0.8280 - val_accuracy: 0.6382\n",
            "Epoch 812/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7670 - accuracy: 0.6642 - val_loss: 0.8538 - val_accuracy: 0.5989\n",
            "Epoch 813/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7680 - accuracy: 0.6594 - val_loss: 0.8335 - val_accuracy: 0.6112\n",
            "Epoch 814/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7637 - accuracy: 0.6611 - val_loss: 0.8401 - val_accuracy: 0.6090\n",
            "Epoch 815/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7642 - accuracy: 0.6645 - val_loss: 0.8327 - val_accuracy: 0.6124\n",
            "Epoch 816/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7660 - accuracy: 0.6665 - val_loss: 0.8360 - val_accuracy: 0.6169\n",
            "Epoch 817/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7673 - accuracy: 0.6594 - val_loss: 0.8404 - val_accuracy: 0.6045\n",
            "Epoch 818/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7636 - accuracy: 0.6606 - val_loss: 0.8241 - val_accuracy: 0.6236\n",
            "Epoch 819/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7646 - accuracy: 0.6651 - val_loss: 0.8353 - val_accuracy: 0.6124\n",
            "Epoch 820/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7674 - accuracy: 0.6642 - val_loss: 0.8365 - val_accuracy: 0.6124\n",
            "Epoch 821/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7613 - accuracy: 0.6628 - val_loss: 0.8646 - val_accuracy: 0.5978\n",
            "Epoch 822/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7676 - accuracy: 0.6625 - val_loss: 0.8213 - val_accuracy: 0.6315\n",
            "Epoch 823/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7640 - accuracy: 0.6617 - val_loss: 0.8251 - val_accuracy: 0.6315\n",
            "Epoch 824/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7604 - accuracy: 0.6645 - val_loss: 0.8348 - val_accuracy: 0.6202\n",
            "Epoch 825/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7634 - accuracy: 0.6673 - val_loss: 0.8256 - val_accuracy: 0.6326\n",
            "Epoch 826/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7601 - accuracy: 0.6673 - val_loss: 0.8458 - val_accuracy: 0.5989\n",
            "Epoch 827/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7634 - accuracy: 0.6600 - val_loss: 0.8270 - val_accuracy: 0.6180\n",
            "Epoch 828/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7630 - accuracy: 0.6662 - val_loss: 0.8259 - val_accuracy: 0.6292\n",
            "Epoch 829/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7623 - accuracy: 0.6696 - val_loss: 0.8351 - val_accuracy: 0.6169\n",
            "Epoch 830/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7596 - accuracy: 0.6679 - val_loss: 0.8295 - val_accuracy: 0.6169\n",
            "Epoch 831/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7663 - accuracy: 0.6662 - val_loss: 0.8303 - val_accuracy: 0.6180\n",
            "Epoch 832/2000\n",
            "56/56 [==============================] - 1s 13ms/step - loss: 0.7614 - accuracy: 0.6642 - val_loss: 0.8266 - val_accuracy: 0.6326\n",
            "Epoch 833/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7614 - accuracy: 0.6662 - val_loss: 0.8396 - val_accuracy: 0.6045\n",
            "Epoch 834/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7673 - accuracy: 0.6555 - val_loss: 0.8274 - val_accuracy: 0.6247\n",
            "Epoch 835/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7603 - accuracy: 0.6701 - val_loss: 0.8317 - val_accuracy: 0.6360\n",
            "Epoch 836/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7663 - accuracy: 0.6679 - val_loss: 0.8248 - val_accuracy: 0.6281\n",
            "Epoch 837/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7634 - accuracy: 0.6676 - val_loss: 0.8223 - val_accuracy: 0.6281\n",
            "Epoch 838/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7603 - accuracy: 0.6659 - val_loss: 0.8441 - val_accuracy: 0.6112\n",
            "Epoch 839/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7602 - accuracy: 0.6639 - val_loss: 0.8249 - val_accuracy: 0.6281\n",
            "Epoch 840/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7618 - accuracy: 0.6670 - val_loss: 0.8249 - val_accuracy: 0.6258\n",
            "Epoch 841/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7621 - accuracy: 0.6637 - val_loss: 0.8281 - val_accuracy: 0.6258\n",
            "Epoch 842/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7621 - accuracy: 0.6659 - val_loss: 0.8249 - val_accuracy: 0.6281\n",
            "Epoch 843/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7599 - accuracy: 0.6693 - val_loss: 0.8284 - val_accuracy: 0.6247\n",
            "Epoch 844/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7632 - accuracy: 0.6679 - val_loss: 0.8472 - val_accuracy: 0.6000\n",
            "Epoch 845/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7615 - accuracy: 0.6656 - val_loss: 0.8319 - val_accuracy: 0.6371\n",
            "Epoch 846/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7619 - accuracy: 0.6631 - val_loss: 0.8291 - val_accuracy: 0.6225\n",
            "Epoch 847/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7652 - accuracy: 0.6639 - val_loss: 0.8267 - val_accuracy: 0.6315\n",
            "Epoch 848/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7637 - accuracy: 0.6634 - val_loss: 0.8413 - val_accuracy: 0.6090\n",
            "Epoch 849/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7636 - accuracy: 0.6682 - val_loss: 0.8316 - val_accuracy: 0.6461\n",
            "Epoch 850/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7647 - accuracy: 0.6620 - val_loss: 0.8527 - val_accuracy: 0.6011\n",
            "Epoch 851/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7593 - accuracy: 0.6654 - val_loss: 0.8300 - val_accuracy: 0.6157\n",
            "Epoch 852/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7615 - accuracy: 0.6654 - val_loss: 0.8301 - val_accuracy: 0.6202\n",
            "Epoch 853/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7581 - accuracy: 0.6710 - val_loss: 0.8303 - val_accuracy: 0.6247\n",
            "Epoch 854/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7600 - accuracy: 0.6676 - val_loss: 0.8233 - val_accuracy: 0.6247\n",
            "Epoch 855/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7614 - accuracy: 0.6654 - val_loss: 0.8281 - val_accuracy: 0.6157\n",
            "Epoch 856/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7638 - accuracy: 0.6592 - val_loss: 0.8514 - val_accuracy: 0.5966\n",
            "Epoch 857/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7625 - accuracy: 0.6639 - val_loss: 0.8274 - val_accuracy: 0.6270\n",
            "Epoch 858/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7575 - accuracy: 0.6687 - val_loss: 0.8382 - val_accuracy: 0.6213\n",
            "Epoch 859/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7594 - accuracy: 0.6696 - val_loss: 0.8507 - val_accuracy: 0.6022\n",
            "Epoch 860/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7638 - accuracy: 0.6682 - val_loss: 0.8221 - val_accuracy: 0.6326\n",
            "Epoch 861/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7606 - accuracy: 0.6634 - val_loss: 0.8306 - val_accuracy: 0.6213\n",
            "Epoch 862/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7637 - accuracy: 0.6659 - val_loss: 0.8285 - val_accuracy: 0.6213\n",
            "Epoch 863/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7590 - accuracy: 0.6693 - val_loss: 0.8608 - val_accuracy: 0.5989\n",
            "Epoch 864/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7615 - accuracy: 0.6659 - val_loss: 0.8339 - val_accuracy: 0.6225\n",
            "Epoch 865/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7593 - accuracy: 0.6659 - val_loss: 0.8441 - val_accuracy: 0.6011\n",
            "Epoch 866/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7614 - accuracy: 0.6659 - val_loss: 0.8304 - val_accuracy: 0.6202\n",
            "Epoch 867/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7605 - accuracy: 0.6676 - val_loss: 0.8358 - val_accuracy: 0.6225\n",
            "Epoch 868/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7643 - accuracy: 0.6642 - val_loss: 0.8302 - val_accuracy: 0.6169\n",
            "Epoch 869/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7588 - accuracy: 0.6721 - val_loss: 0.8237 - val_accuracy: 0.6225\n",
            "Epoch 870/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7576 - accuracy: 0.6701 - val_loss: 0.8569 - val_accuracy: 0.5978\n",
            "Epoch 871/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7577 - accuracy: 0.6713 - val_loss: 0.8271 - val_accuracy: 0.6315\n",
            "Epoch 872/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7584 - accuracy: 0.6704 - val_loss: 0.8356 - val_accuracy: 0.6157\n",
            "Epoch 873/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7600 - accuracy: 0.6699 - val_loss: 0.8287 - val_accuracy: 0.6315\n",
            "Epoch 874/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7567 - accuracy: 0.6713 - val_loss: 0.8303 - val_accuracy: 0.6360\n",
            "Epoch 875/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7620 - accuracy: 0.6645 - val_loss: 0.8334 - val_accuracy: 0.6337\n",
            "Epoch 876/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7605 - accuracy: 0.6645 - val_loss: 0.8390 - val_accuracy: 0.6112\n",
            "Epoch 877/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7578 - accuracy: 0.6715 - val_loss: 0.8261 - val_accuracy: 0.6247\n",
            "Epoch 878/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7594 - accuracy: 0.6656 - val_loss: 0.8253 - val_accuracy: 0.6213\n",
            "Epoch 879/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7599 - accuracy: 0.6715 - val_loss: 0.8272 - val_accuracy: 0.6270\n",
            "Epoch 880/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7577 - accuracy: 0.6713 - val_loss: 0.8322 - val_accuracy: 0.6292\n",
            "Epoch 881/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7632 - accuracy: 0.6684 - val_loss: 0.8260 - val_accuracy: 0.6247\n",
            "Epoch 882/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7595 - accuracy: 0.6676 - val_loss: 0.8280 - val_accuracy: 0.6337\n",
            "Epoch 883/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7595 - accuracy: 0.6682 - val_loss: 0.8293 - val_accuracy: 0.6281\n",
            "Epoch 884/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7601 - accuracy: 0.6665 - val_loss: 0.8230 - val_accuracy: 0.6360\n",
            "Epoch 885/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7634 - accuracy: 0.6620 - val_loss: 0.8262 - val_accuracy: 0.6326\n",
            "Epoch 886/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7563 - accuracy: 0.6710 - val_loss: 0.8330 - val_accuracy: 0.6202\n",
            "Epoch 887/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7589 - accuracy: 0.6715 - val_loss: 0.8353 - val_accuracy: 0.6157\n",
            "Epoch 888/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7612 - accuracy: 0.6639 - val_loss: 0.8306 - val_accuracy: 0.6202\n",
            "Epoch 889/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7653 - accuracy: 0.6611 - val_loss: 0.8359 - val_accuracy: 0.6124\n",
            "Epoch 890/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7590 - accuracy: 0.6651 - val_loss: 0.8342 - val_accuracy: 0.6225\n",
            "Epoch 891/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7563 - accuracy: 0.6676 - val_loss: 0.8370 - val_accuracy: 0.6079\n",
            "Epoch 892/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7596 - accuracy: 0.6676 - val_loss: 0.8334 - val_accuracy: 0.6225\n",
            "Epoch 893/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7573 - accuracy: 0.6696 - val_loss: 0.8289 - val_accuracy: 0.6225\n",
            "Epoch 894/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7573 - accuracy: 0.6656 - val_loss: 0.8303 - val_accuracy: 0.6146\n",
            "Epoch 895/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7597 - accuracy: 0.6696 - val_loss: 0.8351 - val_accuracy: 0.6236\n",
            "Epoch 896/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7584 - accuracy: 0.6592 - val_loss: 0.8299 - val_accuracy: 0.6281\n",
            "Epoch 897/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7563 - accuracy: 0.6668 - val_loss: 0.8475 - val_accuracy: 0.6045\n",
            "Epoch 898/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7577 - accuracy: 0.6662 - val_loss: 0.8378 - val_accuracy: 0.6079\n",
            "Epoch 899/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7582 - accuracy: 0.6710 - val_loss: 0.8338 - val_accuracy: 0.6202\n",
            "Epoch 900/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7556 - accuracy: 0.6687 - val_loss: 0.8293 - val_accuracy: 0.6247\n",
            "Epoch 901/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7562 - accuracy: 0.6701 - val_loss: 0.8287 - val_accuracy: 0.6326\n",
            "Epoch 902/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7566 - accuracy: 0.6676 - val_loss: 0.8314 - val_accuracy: 0.6225\n",
            "Epoch 903/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7570 - accuracy: 0.6724 - val_loss: 0.8301 - val_accuracy: 0.6213\n",
            "Epoch 904/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7574 - accuracy: 0.6648 - val_loss: 0.8344 - val_accuracy: 0.6157\n",
            "Epoch 905/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7589 - accuracy: 0.6642 - val_loss: 0.8301 - val_accuracy: 0.6202\n",
            "Epoch 906/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7568 - accuracy: 0.6710 - val_loss: 0.8419 - val_accuracy: 0.6124\n",
            "Epoch 907/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7597 - accuracy: 0.6662 - val_loss: 0.8300 - val_accuracy: 0.6292\n",
            "Epoch 908/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7561 - accuracy: 0.6718 - val_loss: 0.8453 - val_accuracy: 0.6112\n",
            "Epoch 909/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7559 - accuracy: 0.6665 - val_loss: 0.8339 - val_accuracy: 0.6157\n",
            "Epoch 910/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7612 - accuracy: 0.6639 - val_loss: 0.8296 - val_accuracy: 0.6202\n",
            "Epoch 911/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7601 - accuracy: 0.6645 - val_loss: 0.8464 - val_accuracy: 0.6034\n",
            "Epoch 912/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7587 - accuracy: 0.6654 - val_loss: 0.8292 - val_accuracy: 0.6202\n",
            "Epoch 913/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7609 - accuracy: 0.6645 - val_loss: 0.8335 - val_accuracy: 0.6191\n",
            "Epoch 914/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7567 - accuracy: 0.6699 - val_loss: 0.8265 - val_accuracy: 0.6292\n",
            "Epoch 915/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7631 - accuracy: 0.6701 - val_loss: 0.8390 - val_accuracy: 0.6090\n",
            "Epoch 916/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7583 - accuracy: 0.6654 - val_loss: 0.8295 - val_accuracy: 0.6180\n",
            "Epoch 917/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7620 - accuracy: 0.6634 - val_loss: 0.8338 - val_accuracy: 0.6124\n",
            "Epoch 918/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7583 - accuracy: 0.6699 - val_loss: 0.8384 - val_accuracy: 0.6079\n",
            "Epoch 919/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7591 - accuracy: 0.6699 - val_loss: 0.8248 - val_accuracy: 0.6202\n",
            "Epoch 920/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7559 - accuracy: 0.6696 - val_loss: 0.8371 - val_accuracy: 0.6236\n",
            "Epoch 921/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7565 - accuracy: 0.6687 - val_loss: 0.8296 - val_accuracy: 0.6236\n",
            "Epoch 922/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7569 - accuracy: 0.6642 - val_loss: 0.8283 - val_accuracy: 0.6371\n",
            "Epoch 923/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7686 - accuracy: 0.6572 - val_loss: 0.8232 - val_accuracy: 0.6281\n",
            "Epoch 924/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7614 - accuracy: 0.6642 - val_loss: 0.8240 - val_accuracy: 0.6270\n",
            "Epoch 925/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7591 - accuracy: 0.6654 - val_loss: 0.8262 - val_accuracy: 0.6247\n",
            "Epoch 926/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7541 - accuracy: 0.6676 - val_loss: 0.8326 - val_accuracy: 0.6135\n",
            "Epoch 927/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7548 - accuracy: 0.6735 - val_loss: 0.8260 - val_accuracy: 0.6281\n",
            "Epoch 928/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7562 - accuracy: 0.6662 - val_loss: 0.8312 - val_accuracy: 0.6202\n",
            "Epoch 929/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7568 - accuracy: 0.6676 - val_loss: 0.8304 - val_accuracy: 0.6180\n",
            "Epoch 930/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7583 - accuracy: 0.6665 - val_loss: 0.8349 - val_accuracy: 0.6225\n",
            "Epoch 931/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7562 - accuracy: 0.6721 - val_loss: 0.8342 - val_accuracy: 0.6213\n",
            "Epoch 932/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7570 - accuracy: 0.6631 - val_loss: 0.8254 - val_accuracy: 0.6236\n",
            "Epoch 933/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7561 - accuracy: 0.6696 - val_loss: 0.8275 - val_accuracy: 0.6225\n",
            "Epoch 934/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7541 - accuracy: 0.6724 - val_loss: 0.8301 - val_accuracy: 0.6213\n",
            "Epoch 935/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7557 - accuracy: 0.6662 - val_loss: 0.8245 - val_accuracy: 0.6281\n",
            "Epoch 936/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7574 - accuracy: 0.6642 - val_loss: 0.8450 - val_accuracy: 0.6112\n",
            "Epoch 937/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7559 - accuracy: 0.6693 - val_loss: 0.8580 - val_accuracy: 0.6101\n",
            "Epoch 938/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7605 - accuracy: 0.6693 - val_loss: 0.8335 - val_accuracy: 0.6202\n",
            "Epoch 939/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7596 - accuracy: 0.6682 - val_loss: 0.8263 - val_accuracy: 0.6270\n",
            "Epoch 940/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7565 - accuracy: 0.6668 - val_loss: 0.8303 - val_accuracy: 0.6292\n",
            "Epoch 941/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7554 - accuracy: 0.6639 - val_loss: 0.8376 - val_accuracy: 0.6135\n",
            "Epoch 942/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7549 - accuracy: 0.6704 - val_loss: 0.8418 - val_accuracy: 0.6146\n",
            "Epoch 943/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7583 - accuracy: 0.6668 - val_loss: 0.8426 - val_accuracy: 0.6112\n",
            "Epoch 944/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7558 - accuracy: 0.6684 - val_loss: 0.8493 - val_accuracy: 0.6056\n",
            "Epoch 945/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7548 - accuracy: 0.6687 - val_loss: 0.8357 - val_accuracy: 0.6281\n",
            "Epoch 946/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7582 - accuracy: 0.6693 - val_loss: 0.8298 - val_accuracy: 0.6258\n",
            "Epoch 947/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7571 - accuracy: 0.6715 - val_loss: 0.8243 - val_accuracy: 0.6247\n",
            "Epoch 948/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7562 - accuracy: 0.6701 - val_loss: 0.8261 - val_accuracy: 0.6315\n",
            "Epoch 949/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7555 - accuracy: 0.6707 - val_loss: 0.8459 - val_accuracy: 0.6034\n",
            "Epoch 950/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7568 - accuracy: 0.6668 - val_loss: 0.8266 - val_accuracy: 0.6258\n",
            "Epoch 951/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7581 - accuracy: 0.6693 - val_loss: 0.8283 - val_accuracy: 0.6281\n",
            "Epoch 952/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7579 - accuracy: 0.6639 - val_loss: 0.8477 - val_accuracy: 0.6079\n",
            "Epoch 953/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7584 - accuracy: 0.6668 - val_loss: 0.8316 - val_accuracy: 0.6191\n",
            "Epoch 954/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7522 - accuracy: 0.6732 - val_loss: 0.8336 - val_accuracy: 0.6213\n",
            "Epoch 955/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7569 - accuracy: 0.6665 - val_loss: 0.8332 - val_accuracy: 0.6213\n",
            "Epoch 956/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7539 - accuracy: 0.6690 - val_loss: 0.8260 - val_accuracy: 0.6281\n",
            "Epoch 957/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7551 - accuracy: 0.6676 - val_loss: 0.8411 - val_accuracy: 0.6124\n",
            "Epoch 958/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7561 - accuracy: 0.6690 - val_loss: 0.8341 - val_accuracy: 0.6360\n",
            "Epoch 959/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7566 - accuracy: 0.6713 - val_loss: 0.8474 - val_accuracy: 0.6090\n",
            "Epoch 960/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7573 - accuracy: 0.6682 - val_loss: 0.8305 - val_accuracy: 0.6247\n",
            "Epoch 961/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7533 - accuracy: 0.6696 - val_loss: 0.8238 - val_accuracy: 0.6303\n",
            "Epoch 962/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7543 - accuracy: 0.6721 - val_loss: 0.8342 - val_accuracy: 0.6213\n",
            "Epoch 963/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7573 - accuracy: 0.6699 - val_loss: 0.8784 - val_accuracy: 0.6045\n",
            "Epoch 964/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7570 - accuracy: 0.6699 - val_loss: 0.8251 - val_accuracy: 0.6225\n",
            "Epoch 965/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7555 - accuracy: 0.6690 - val_loss: 0.8321 - val_accuracy: 0.6202\n",
            "Epoch 966/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7538 - accuracy: 0.6687 - val_loss: 0.8485 - val_accuracy: 0.6124\n",
            "Epoch 967/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7570 - accuracy: 0.6687 - val_loss: 0.8334 - val_accuracy: 0.6213\n",
            "Epoch 968/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7597 - accuracy: 0.6628 - val_loss: 0.8378 - val_accuracy: 0.6202\n",
            "Epoch 969/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7536 - accuracy: 0.6699 - val_loss: 0.8280 - val_accuracy: 0.6236\n",
            "Epoch 970/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7539 - accuracy: 0.6713 - val_loss: 0.8517 - val_accuracy: 0.6169\n",
            "Epoch 971/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7586 - accuracy: 0.6699 - val_loss: 0.8269 - val_accuracy: 0.6303\n",
            "Epoch 972/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7543 - accuracy: 0.6710 - val_loss: 0.8285 - val_accuracy: 0.6202\n",
            "Epoch 973/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7535 - accuracy: 0.6648 - val_loss: 0.8320 - val_accuracy: 0.6191\n",
            "Epoch 974/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7523 - accuracy: 0.6693 - val_loss: 0.8392 - val_accuracy: 0.6157\n",
            "Epoch 975/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7551 - accuracy: 0.6642 - val_loss: 0.8243 - val_accuracy: 0.6270\n",
            "Epoch 976/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7550 - accuracy: 0.6673 - val_loss: 0.8336 - val_accuracy: 0.6146\n",
            "Epoch 977/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7541 - accuracy: 0.6648 - val_loss: 0.8327 - val_accuracy: 0.6258\n",
            "Epoch 978/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7540 - accuracy: 0.6749 - val_loss: 0.8333 - val_accuracy: 0.6202\n",
            "Epoch 979/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7536 - accuracy: 0.6684 - val_loss: 0.8374 - val_accuracy: 0.6202\n",
            "Epoch 980/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7543 - accuracy: 0.6735 - val_loss: 0.8521 - val_accuracy: 0.6011\n",
            "Epoch 981/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7532 - accuracy: 0.6713 - val_loss: 0.8270 - val_accuracy: 0.6236\n",
            "Epoch 982/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7515 - accuracy: 0.6687 - val_loss: 0.8683 - val_accuracy: 0.6090\n",
            "Epoch 983/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7532 - accuracy: 0.6659 - val_loss: 0.8272 - val_accuracy: 0.6202\n",
            "Epoch 984/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7538 - accuracy: 0.6662 - val_loss: 0.8355 - val_accuracy: 0.6157\n",
            "Epoch 985/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7588 - accuracy: 0.6614 - val_loss: 0.8350 - val_accuracy: 0.6169\n",
            "Epoch 986/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7553 - accuracy: 0.6687 - val_loss: 0.8317 - val_accuracy: 0.6225\n",
            "Epoch 987/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7576 - accuracy: 0.6659 - val_loss: 0.8375 - val_accuracy: 0.6247\n",
            "Epoch 988/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7556 - accuracy: 0.6659 - val_loss: 0.8248 - val_accuracy: 0.6236\n",
            "Epoch 989/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7561 - accuracy: 0.6699 - val_loss: 0.8288 - val_accuracy: 0.6180\n",
            "Epoch 990/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7536 - accuracy: 0.6704 - val_loss: 0.8415 - val_accuracy: 0.6135\n",
            "Epoch 991/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7549 - accuracy: 0.6676 - val_loss: 0.8394 - val_accuracy: 0.6135\n",
            "Epoch 992/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7547 - accuracy: 0.6662 - val_loss: 0.8330 - val_accuracy: 0.6236\n",
            "Epoch 993/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7536 - accuracy: 0.6670 - val_loss: 0.8452 - val_accuracy: 0.6169\n",
            "Epoch 994/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7564 - accuracy: 0.6696 - val_loss: 0.8272 - val_accuracy: 0.6258\n",
            "Epoch 995/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7524 - accuracy: 0.6701 - val_loss: 0.8322 - val_accuracy: 0.6236\n",
            "Epoch 996/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7535 - accuracy: 0.6690 - val_loss: 0.8324 - val_accuracy: 0.6360\n",
            "Epoch 997/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7524 - accuracy: 0.6684 - val_loss: 0.8347 - val_accuracy: 0.6124\n",
            "Epoch 998/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7539 - accuracy: 0.6676 - val_loss: 0.8228 - val_accuracy: 0.6258\n",
            "Epoch 999/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7548 - accuracy: 0.6679 - val_loss: 0.8311 - val_accuracy: 0.6191\n",
            "Epoch 1000/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7553 - accuracy: 0.6732 - val_loss: 0.8382 - val_accuracy: 0.6236\n",
            "Epoch 1001/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7529 - accuracy: 0.6670 - val_loss: 0.8263 - val_accuracy: 0.6371\n",
            "Epoch 1002/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7549 - accuracy: 0.6639 - val_loss: 0.8258 - val_accuracy: 0.6225\n",
            "Epoch 1003/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7527 - accuracy: 0.6718 - val_loss: 0.8263 - val_accuracy: 0.6337\n",
            "Epoch 1004/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7540 - accuracy: 0.6693 - val_loss: 0.8260 - val_accuracy: 0.6281\n",
            "Epoch 1005/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7585 - accuracy: 0.6654 - val_loss: 0.8254 - val_accuracy: 0.6292\n",
            "Epoch 1006/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7513 - accuracy: 0.6665 - val_loss: 0.8331 - val_accuracy: 0.6191\n",
            "Epoch 1007/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7562 - accuracy: 0.6673 - val_loss: 0.8223 - val_accuracy: 0.6236\n",
            "Epoch 1008/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7545 - accuracy: 0.6684 - val_loss: 0.8320 - val_accuracy: 0.6236\n",
            "Epoch 1009/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7545 - accuracy: 0.6656 - val_loss: 0.8304 - val_accuracy: 0.6225\n",
            "Epoch 1010/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7516 - accuracy: 0.6676 - val_loss: 0.8285 - val_accuracy: 0.6247\n",
            "Epoch 1011/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7522 - accuracy: 0.6684 - val_loss: 0.8337 - val_accuracy: 0.6169\n",
            "Epoch 1012/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7521 - accuracy: 0.6707 - val_loss: 0.8308 - val_accuracy: 0.6348\n",
            "Epoch 1013/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7505 - accuracy: 0.6659 - val_loss: 0.8308 - val_accuracy: 0.6292\n",
            "Epoch 1014/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7512 - accuracy: 0.6744 - val_loss: 0.8306 - val_accuracy: 0.6236\n",
            "Epoch 1015/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7531 - accuracy: 0.6684 - val_loss: 0.8340 - val_accuracy: 0.6191\n",
            "Epoch 1016/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7534 - accuracy: 0.6690 - val_loss: 0.8265 - val_accuracy: 0.6247\n",
            "Epoch 1017/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7557 - accuracy: 0.6699 - val_loss: 0.8263 - val_accuracy: 0.6281\n",
            "Epoch 1018/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7526 - accuracy: 0.6710 - val_loss: 0.8424 - val_accuracy: 0.6180\n",
            "Epoch 1019/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7522 - accuracy: 0.6701 - val_loss: 0.8313 - val_accuracy: 0.6326\n",
            "Epoch 1020/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7534 - accuracy: 0.6735 - val_loss: 0.8404 - val_accuracy: 0.6135\n",
            "Epoch 1021/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7510 - accuracy: 0.6662 - val_loss: 0.8315 - val_accuracy: 0.6326\n",
            "Epoch 1022/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7514 - accuracy: 0.6699 - val_loss: 0.8270 - val_accuracy: 0.6236\n",
            "Epoch 1023/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7508 - accuracy: 0.6684 - val_loss: 0.8305 - val_accuracy: 0.6236\n",
            "Epoch 1024/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7505 - accuracy: 0.6744 - val_loss: 0.8406 - val_accuracy: 0.6090\n",
            "Epoch 1025/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7535 - accuracy: 0.6715 - val_loss: 0.8217 - val_accuracy: 0.6303\n",
            "Epoch 1026/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7515 - accuracy: 0.6718 - val_loss: 0.8472 - val_accuracy: 0.6112\n",
            "Epoch 1027/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7547 - accuracy: 0.6659 - val_loss: 0.8344 - val_accuracy: 0.6236\n",
            "Epoch 1028/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7591 - accuracy: 0.6670 - val_loss: 0.8281 - val_accuracy: 0.6213\n",
            "Epoch 1029/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7513 - accuracy: 0.6735 - val_loss: 0.8283 - val_accuracy: 0.6213\n",
            "Epoch 1030/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7528 - accuracy: 0.6701 - val_loss: 0.8261 - val_accuracy: 0.6258\n",
            "Epoch 1031/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7521 - accuracy: 0.6724 - val_loss: 0.8373 - val_accuracy: 0.6180\n",
            "Epoch 1032/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7540 - accuracy: 0.6637 - val_loss: 0.8431 - val_accuracy: 0.6169\n",
            "Epoch 1033/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7560 - accuracy: 0.6682 - val_loss: 0.8234 - val_accuracy: 0.6258\n",
            "Epoch 1034/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7503 - accuracy: 0.6727 - val_loss: 0.8294 - val_accuracy: 0.6270\n",
            "Epoch 1035/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7507 - accuracy: 0.6752 - val_loss: 0.8280 - val_accuracy: 0.6236\n",
            "Epoch 1036/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7518 - accuracy: 0.6727 - val_loss: 0.8461 - val_accuracy: 0.6169\n",
            "Epoch 1037/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7507 - accuracy: 0.6744 - val_loss: 0.8220 - val_accuracy: 0.6337\n",
            "Epoch 1038/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7554 - accuracy: 0.6710 - val_loss: 0.8314 - val_accuracy: 0.6258\n",
            "Epoch 1039/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7527 - accuracy: 0.6659 - val_loss: 0.8254 - val_accuracy: 0.6225\n",
            "Epoch 1040/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7501 - accuracy: 0.6673 - val_loss: 0.8316 - val_accuracy: 0.6191\n",
            "Epoch 1041/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7484 - accuracy: 0.6673 - val_loss: 0.8411 - val_accuracy: 0.6236\n",
            "Epoch 1042/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7570 - accuracy: 0.6687 - val_loss: 0.8240 - val_accuracy: 0.6270\n",
            "Epoch 1043/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7521 - accuracy: 0.6687 - val_loss: 0.8493 - val_accuracy: 0.6382\n",
            "Epoch 1044/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7567 - accuracy: 0.6715 - val_loss: 0.8273 - val_accuracy: 0.6258\n",
            "Epoch 1045/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7484 - accuracy: 0.6682 - val_loss: 0.8431 - val_accuracy: 0.6202\n",
            "Epoch 1046/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7496 - accuracy: 0.6704 - val_loss: 0.8338 - val_accuracy: 0.6360\n",
            "Epoch 1047/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7565 - accuracy: 0.6687 - val_loss: 0.8398 - val_accuracy: 0.6157\n",
            "Epoch 1048/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7505 - accuracy: 0.6718 - val_loss: 0.8351 - val_accuracy: 0.6225\n",
            "Epoch 1049/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7506 - accuracy: 0.6715 - val_loss: 0.8338 - val_accuracy: 0.6191\n",
            "Epoch 1050/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7516 - accuracy: 0.6704 - val_loss: 0.8279 - val_accuracy: 0.6225\n",
            "Epoch 1051/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7616 - accuracy: 0.6639 - val_loss: 0.8519 - val_accuracy: 0.6079\n",
            "Epoch 1052/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7516 - accuracy: 0.6735 - val_loss: 0.8342 - val_accuracy: 0.6236\n",
            "Epoch 1053/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7500 - accuracy: 0.6710 - val_loss: 0.8318 - val_accuracy: 0.6236\n",
            "Epoch 1054/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7501 - accuracy: 0.6729 - val_loss: 0.8290 - val_accuracy: 0.6270\n",
            "Epoch 1055/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7503 - accuracy: 0.6690 - val_loss: 0.8490 - val_accuracy: 0.6157\n",
            "Epoch 1056/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7553 - accuracy: 0.6687 - val_loss: 0.8354 - val_accuracy: 0.6270\n",
            "Epoch 1057/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7534 - accuracy: 0.6597 - val_loss: 0.8345 - val_accuracy: 0.6180\n",
            "Epoch 1058/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7539 - accuracy: 0.6710 - val_loss: 0.8367 - val_accuracy: 0.6315\n",
            "Epoch 1059/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7514 - accuracy: 0.6704 - val_loss: 0.8405 - val_accuracy: 0.6191\n",
            "Epoch 1060/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7548 - accuracy: 0.6648 - val_loss: 0.8226 - val_accuracy: 0.6281\n",
            "Epoch 1061/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7512 - accuracy: 0.6707 - val_loss: 0.8258 - val_accuracy: 0.6236\n",
            "Epoch 1062/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7501 - accuracy: 0.6721 - val_loss: 0.8367 - val_accuracy: 0.6202\n",
            "Epoch 1063/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7488 - accuracy: 0.6710 - val_loss: 0.8308 - val_accuracy: 0.6258\n",
            "Epoch 1064/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7523 - accuracy: 0.6727 - val_loss: 0.8514 - val_accuracy: 0.6090\n",
            "Epoch 1065/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7511 - accuracy: 0.6707 - val_loss: 0.8290 - val_accuracy: 0.6371\n",
            "Epoch 1066/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7487 - accuracy: 0.6707 - val_loss: 0.8268 - val_accuracy: 0.6247\n",
            "Epoch 1067/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7504 - accuracy: 0.6715 - val_loss: 0.8410 - val_accuracy: 0.6247\n",
            "Epoch 1068/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7513 - accuracy: 0.6682 - val_loss: 0.8433 - val_accuracy: 0.6146\n",
            "Epoch 1069/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7502 - accuracy: 0.6732 - val_loss: 0.8262 - val_accuracy: 0.6258\n",
            "Epoch 1070/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7498 - accuracy: 0.6727 - val_loss: 0.8430 - val_accuracy: 0.6202\n",
            "Epoch 1071/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7510 - accuracy: 0.6710 - val_loss: 0.8374 - val_accuracy: 0.6258\n",
            "Epoch 1072/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7482 - accuracy: 0.6704 - val_loss: 0.8203 - val_accuracy: 0.6303\n",
            "Epoch 1073/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7491 - accuracy: 0.6693 - val_loss: 0.8325 - val_accuracy: 0.6236\n",
            "Epoch 1074/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7478 - accuracy: 0.6766 - val_loss: 0.8246 - val_accuracy: 0.6225\n",
            "Epoch 1075/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7532 - accuracy: 0.6684 - val_loss: 0.8305 - val_accuracy: 0.6326\n",
            "Epoch 1076/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7495 - accuracy: 0.6721 - val_loss: 0.8327 - val_accuracy: 0.6258\n",
            "Epoch 1077/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7494 - accuracy: 0.6693 - val_loss: 0.8306 - val_accuracy: 0.6292\n",
            "Epoch 1078/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7569 - accuracy: 0.6651 - val_loss: 0.8255 - val_accuracy: 0.6292\n",
            "Epoch 1079/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7508 - accuracy: 0.6679 - val_loss: 0.8472 - val_accuracy: 0.6135\n",
            "Epoch 1080/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7514 - accuracy: 0.6662 - val_loss: 0.8295 - val_accuracy: 0.6236\n",
            "Epoch 1081/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7536 - accuracy: 0.6673 - val_loss: 0.8342 - val_accuracy: 0.6303\n",
            "Epoch 1082/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7500 - accuracy: 0.6715 - val_loss: 0.8260 - val_accuracy: 0.6337\n",
            "Epoch 1083/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7493 - accuracy: 0.6741 - val_loss: 0.8298 - val_accuracy: 0.6258\n",
            "Epoch 1084/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7487 - accuracy: 0.6696 - val_loss: 0.8300 - val_accuracy: 0.6371\n",
            "Epoch 1085/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7548 - accuracy: 0.6639 - val_loss: 0.8521 - val_accuracy: 0.6112\n",
            "Epoch 1086/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7494 - accuracy: 0.6679 - val_loss: 0.8430 - val_accuracy: 0.6124\n",
            "Epoch 1087/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7548 - accuracy: 0.6718 - val_loss: 0.8256 - val_accuracy: 0.6281\n",
            "Epoch 1088/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7500 - accuracy: 0.6772 - val_loss: 0.8288 - val_accuracy: 0.6258\n",
            "Epoch 1089/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7514 - accuracy: 0.6673 - val_loss: 0.8244 - val_accuracy: 0.6270\n",
            "Epoch 1090/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7525 - accuracy: 0.6651 - val_loss: 0.8297 - val_accuracy: 0.6281\n",
            "Epoch 1091/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7508 - accuracy: 0.6701 - val_loss: 0.8287 - val_accuracy: 0.6180\n",
            "Epoch 1092/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7481 - accuracy: 0.6668 - val_loss: 0.8377 - val_accuracy: 0.6258\n",
            "Epoch 1093/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7484 - accuracy: 0.6704 - val_loss: 0.8327 - val_accuracy: 0.6236\n",
            "Epoch 1094/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7484 - accuracy: 0.6707 - val_loss: 0.8321 - val_accuracy: 0.6360\n",
            "Epoch 1095/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7502 - accuracy: 0.6673 - val_loss: 0.8276 - val_accuracy: 0.6247\n",
            "Epoch 1096/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7483 - accuracy: 0.6746 - val_loss: 0.8346 - val_accuracy: 0.6292\n",
            "Epoch 1097/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7525 - accuracy: 0.6670 - val_loss: 0.8361 - val_accuracy: 0.6169\n",
            "Epoch 1098/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7516 - accuracy: 0.6791 - val_loss: 0.8310 - val_accuracy: 0.6225\n",
            "Epoch 1099/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7506 - accuracy: 0.6701 - val_loss: 0.8304 - val_accuracy: 0.6202\n",
            "Epoch 1100/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7487 - accuracy: 0.6690 - val_loss: 0.8292 - val_accuracy: 0.6236\n",
            "Epoch 1101/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7490 - accuracy: 0.6715 - val_loss: 0.8272 - val_accuracy: 0.6281\n",
            "Epoch 1102/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7495 - accuracy: 0.6628 - val_loss: 0.8390 - val_accuracy: 0.6225\n",
            "Epoch 1103/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7489 - accuracy: 0.6735 - val_loss: 0.8247 - val_accuracy: 0.6247\n",
            "Epoch 1104/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7463 - accuracy: 0.6687 - val_loss: 0.8390 - val_accuracy: 0.6258\n",
            "Epoch 1105/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7482 - accuracy: 0.6656 - val_loss: 0.8292 - val_accuracy: 0.6303\n",
            "Epoch 1106/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7543 - accuracy: 0.6693 - val_loss: 0.8290 - val_accuracy: 0.6281\n",
            "Epoch 1107/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7542 - accuracy: 0.6693 - val_loss: 0.8336 - val_accuracy: 0.6258\n",
            "Epoch 1108/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7509 - accuracy: 0.6696 - val_loss: 0.8328 - val_accuracy: 0.6236\n",
            "Epoch 1109/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7504 - accuracy: 0.6718 - val_loss: 0.8281 - val_accuracy: 0.6225\n",
            "Epoch 1110/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7480 - accuracy: 0.6704 - val_loss: 0.8326 - val_accuracy: 0.6281\n",
            "Epoch 1111/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7466 - accuracy: 0.6693 - val_loss: 0.8270 - val_accuracy: 0.6236\n",
            "Epoch 1112/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7497 - accuracy: 0.6710 - val_loss: 0.8343 - val_accuracy: 0.6213\n",
            "Epoch 1113/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7480 - accuracy: 0.6718 - val_loss: 0.8635 - val_accuracy: 0.6101\n",
            "Epoch 1114/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7502 - accuracy: 0.6746 - val_loss: 0.8246 - val_accuracy: 0.6292\n",
            "Epoch 1115/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7572 - accuracy: 0.6625 - val_loss: 0.8431 - val_accuracy: 0.6202\n",
            "Epoch 1116/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7487 - accuracy: 0.6699 - val_loss: 0.8341 - val_accuracy: 0.6360\n",
            "Epoch 1117/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7506 - accuracy: 0.6648 - val_loss: 0.8296 - val_accuracy: 0.6270\n",
            "Epoch 1118/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7498 - accuracy: 0.6710 - val_loss: 0.8236 - val_accuracy: 0.6225\n",
            "Epoch 1119/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7470 - accuracy: 0.6710 - val_loss: 0.8289 - val_accuracy: 0.6236\n",
            "Epoch 1120/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7484 - accuracy: 0.6718 - val_loss: 0.8266 - val_accuracy: 0.6247\n",
            "Epoch 1121/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7467 - accuracy: 0.6721 - val_loss: 0.8290 - val_accuracy: 0.6281\n",
            "Epoch 1122/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7467 - accuracy: 0.6676 - val_loss: 0.8415 - val_accuracy: 0.6292\n",
            "Epoch 1123/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7536 - accuracy: 0.6713 - val_loss: 0.8427 - val_accuracy: 0.6169\n",
            "Epoch 1124/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7486 - accuracy: 0.6732 - val_loss: 0.8265 - val_accuracy: 0.6258\n",
            "Epoch 1125/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7494 - accuracy: 0.6662 - val_loss: 0.8286 - val_accuracy: 0.6315\n",
            "Epoch 1126/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7528 - accuracy: 0.6654 - val_loss: 0.8351 - val_accuracy: 0.6225\n",
            "Epoch 1127/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7508 - accuracy: 0.6682 - val_loss: 0.8258 - val_accuracy: 0.6315\n",
            "Epoch 1128/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7508 - accuracy: 0.6670 - val_loss: 0.8241 - val_accuracy: 0.6247\n",
            "Epoch 1129/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7459 - accuracy: 0.6701 - val_loss: 0.8265 - val_accuracy: 0.6258\n",
            "Epoch 1130/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7515 - accuracy: 0.6679 - val_loss: 0.8488 - val_accuracy: 0.6169\n",
            "Epoch 1131/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7479 - accuracy: 0.6752 - val_loss: 0.8218 - val_accuracy: 0.6247\n",
            "Epoch 1132/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7463 - accuracy: 0.6690 - val_loss: 0.8289 - val_accuracy: 0.6292\n",
            "Epoch 1133/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7500 - accuracy: 0.6735 - val_loss: 0.8306 - val_accuracy: 0.6247\n",
            "Epoch 1134/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7482 - accuracy: 0.6701 - val_loss: 0.8311 - val_accuracy: 0.6270\n",
            "Epoch 1135/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7465 - accuracy: 0.6746 - val_loss: 0.8361 - val_accuracy: 0.6213\n",
            "Epoch 1136/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7450 - accuracy: 0.6741 - val_loss: 0.8232 - val_accuracy: 0.6315\n",
            "Epoch 1137/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7458 - accuracy: 0.6704 - val_loss: 0.8405 - val_accuracy: 0.6303\n",
            "Epoch 1138/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7482 - accuracy: 0.6690 - val_loss: 0.8250 - val_accuracy: 0.6247\n",
            "Epoch 1139/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7477 - accuracy: 0.6710 - val_loss: 0.8334 - val_accuracy: 0.6371\n",
            "Epoch 1140/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7474 - accuracy: 0.6729 - val_loss: 0.8558 - val_accuracy: 0.6180\n",
            "Epoch 1141/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7537 - accuracy: 0.6673 - val_loss: 0.8321 - val_accuracy: 0.6303\n",
            "Epoch 1142/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7494 - accuracy: 0.6760 - val_loss: 0.8304 - val_accuracy: 0.6225\n",
            "Epoch 1143/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7479 - accuracy: 0.6752 - val_loss: 0.8414 - val_accuracy: 0.6225\n",
            "Epoch 1144/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7488 - accuracy: 0.6704 - val_loss: 0.8294 - val_accuracy: 0.6270\n",
            "Epoch 1145/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7479 - accuracy: 0.6696 - val_loss: 0.8431 - val_accuracy: 0.6090\n",
            "Epoch 1146/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7515 - accuracy: 0.6780 - val_loss: 0.8326 - val_accuracy: 0.6315\n",
            "Epoch 1147/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7454 - accuracy: 0.6741 - val_loss: 0.8264 - val_accuracy: 0.6303\n",
            "Epoch 1148/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7481 - accuracy: 0.6704 - val_loss: 0.8306 - val_accuracy: 0.6416\n",
            "Epoch 1149/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7455 - accuracy: 0.6713 - val_loss: 0.8381 - val_accuracy: 0.6180\n",
            "Epoch 1150/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7529 - accuracy: 0.6676 - val_loss: 0.8226 - val_accuracy: 0.6337\n",
            "Epoch 1151/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7486 - accuracy: 0.6704 - val_loss: 0.8216 - val_accuracy: 0.6236\n",
            "Epoch 1152/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7506 - accuracy: 0.6701 - val_loss: 0.8233 - val_accuracy: 0.6315\n",
            "Epoch 1153/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7511 - accuracy: 0.6687 - val_loss: 0.8201 - val_accuracy: 0.6292\n",
            "Epoch 1154/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7456 - accuracy: 0.6696 - val_loss: 0.8249 - val_accuracy: 0.6337\n",
            "Epoch 1155/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7466 - accuracy: 0.6673 - val_loss: 0.8397 - val_accuracy: 0.6213\n",
            "Epoch 1156/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7476 - accuracy: 0.6699 - val_loss: 0.8417 - val_accuracy: 0.6169\n",
            "Epoch 1157/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7515 - accuracy: 0.6713 - val_loss: 0.8274 - val_accuracy: 0.6213\n",
            "Epoch 1158/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7460 - accuracy: 0.6721 - val_loss: 0.8254 - val_accuracy: 0.6348\n",
            "Epoch 1159/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7498 - accuracy: 0.6704 - val_loss: 0.8259 - val_accuracy: 0.6236\n",
            "Epoch 1160/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7491 - accuracy: 0.6704 - val_loss: 0.8295 - val_accuracy: 0.6225\n",
            "Epoch 1161/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7479 - accuracy: 0.6727 - val_loss: 0.8299 - val_accuracy: 0.6258\n",
            "Epoch 1162/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7476 - accuracy: 0.6780 - val_loss: 0.8234 - val_accuracy: 0.6292\n",
            "Epoch 1163/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7497 - accuracy: 0.6718 - val_loss: 0.8321 - val_accuracy: 0.6236\n",
            "Epoch 1164/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7483 - accuracy: 0.6701 - val_loss: 0.8270 - val_accuracy: 0.6315\n",
            "Epoch 1165/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7510 - accuracy: 0.6684 - val_loss: 0.8231 - val_accuracy: 0.6247\n",
            "Epoch 1166/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7498 - accuracy: 0.6654 - val_loss: 0.8369 - val_accuracy: 0.6270\n",
            "Epoch 1167/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7507 - accuracy: 0.6670 - val_loss: 0.8273 - val_accuracy: 0.6225\n",
            "Epoch 1168/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7426 - accuracy: 0.6755 - val_loss: 0.8341 - val_accuracy: 0.6270\n",
            "Epoch 1169/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7531 - accuracy: 0.6673 - val_loss: 0.8371 - val_accuracy: 0.6213\n",
            "Epoch 1170/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7468 - accuracy: 0.6744 - val_loss: 0.8487 - val_accuracy: 0.6169\n",
            "Epoch 1171/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7466 - accuracy: 0.6741 - val_loss: 0.8196 - val_accuracy: 0.6247\n",
            "Epoch 1172/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7470 - accuracy: 0.6710 - val_loss: 0.8274 - val_accuracy: 0.6247\n",
            "Epoch 1173/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7435 - accuracy: 0.6732 - val_loss: 0.8341 - val_accuracy: 0.6225\n",
            "Epoch 1174/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7437 - accuracy: 0.6749 - val_loss: 0.8280 - val_accuracy: 0.6213\n",
            "Epoch 1175/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7549 - accuracy: 0.6659 - val_loss: 0.8345 - val_accuracy: 0.6427\n",
            "Epoch 1176/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7504 - accuracy: 0.6684 - val_loss: 0.8521 - val_accuracy: 0.6124\n",
            "Epoch 1177/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7452 - accuracy: 0.6724 - val_loss: 0.8358 - val_accuracy: 0.6315\n",
            "Epoch 1178/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7511 - accuracy: 0.6715 - val_loss: 0.8498 - val_accuracy: 0.6112\n",
            "Epoch 1179/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7483 - accuracy: 0.6670 - val_loss: 0.8275 - val_accuracy: 0.6191\n",
            "Epoch 1180/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7462 - accuracy: 0.6724 - val_loss: 0.8231 - val_accuracy: 0.6337\n",
            "Epoch 1181/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7459 - accuracy: 0.6710 - val_loss: 0.8394 - val_accuracy: 0.6146\n",
            "Epoch 1182/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7449 - accuracy: 0.6727 - val_loss: 0.8435 - val_accuracy: 0.6146\n",
            "Epoch 1183/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7475 - accuracy: 0.6701 - val_loss: 0.8477 - val_accuracy: 0.6112\n",
            "Epoch 1184/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7494 - accuracy: 0.6693 - val_loss: 0.8278 - val_accuracy: 0.6270\n",
            "Epoch 1185/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7454 - accuracy: 0.6727 - val_loss: 0.8287 - val_accuracy: 0.6258\n",
            "Epoch 1186/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7453 - accuracy: 0.6721 - val_loss: 0.8331 - val_accuracy: 0.6258\n",
            "Epoch 1187/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7460 - accuracy: 0.6766 - val_loss: 0.8355 - val_accuracy: 0.6247\n",
            "Epoch 1188/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7470 - accuracy: 0.6732 - val_loss: 0.8229 - val_accuracy: 0.6281\n",
            "Epoch 1189/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7476 - accuracy: 0.6651 - val_loss: 0.8639 - val_accuracy: 0.6112\n",
            "Epoch 1190/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7549 - accuracy: 0.6668 - val_loss: 0.8295 - val_accuracy: 0.6258\n",
            "Epoch 1191/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7465 - accuracy: 0.6693 - val_loss: 0.8696 - val_accuracy: 0.6135\n",
            "Epoch 1192/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7472 - accuracy: 0.6721 - val_loss: 0.8269 - val_accuracy: 0.6270\n",
            "Epoch 1193/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7443 - accuracy: 0.6735 - val_loss: 0.8215 - val_accuracy: 0.6292\n",
            "Epoch 1194/2000\n",
            "56/56 [==============================] - 1s 13ms/step - loss: 0.7448 - accuracy: 0.6701 - val_loss: 0.8270 - val_accuracy: 0.6270\n",
            "Epoch 1195/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7468 - accuracy: 0.6707 - val_loss: 0.8436 - val_accuracy: 0.6180\n",
            "Epoch 1196/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7459 - accuracy: 0.6746 - val_loss: 0.8248 - val_accuracy: 0.6393\n",
            "Epoch 1197/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7498 - accuracy: 0.6696 - val_loss: 0.8246 - val_accuracy: 0.6371\n",
            "Epoch 1198/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7460 - accuracy: 0.6710 - val_loss: 0.8344 - val_accuracy: 0.6169\n",
            "Epoch 1199/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7446 - accuracy: 0.6744 - val_loss: 0.8222 - val_accuracy: 0.6258\n",
            "Epoch 1200/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7458 - accuracy: 0.6732 - val_loss: 0.8277 - val_accuracy: 0.6337\n",
            "Epoch 1201/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7445 - accuracy: 0.6724 - val_loss: 0.8356 - val_accuracy: 0.6258\n",
            "Epoch 1202/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7435 - accuracy: 0.6735 - val_loss: 0.8402 - val_accuracy: 0.6202\n",
            "Epoch 1203/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7444 - accuracy: 0.6752 - val_loss: 0.8331 - val_accuracy: 0.6303\n",
            "Epoch 1204/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7453 - accuracy: 0.6738 - val_loss: 0.8295 - val_accuracy: 0.6247\n",
            "Epoch 1205/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7500 - accuracy: 0.6732 - val_loss: 0.8239 - val_accuracy: 0.6326\n",
            "Epoch 1206/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7468 - accuracy: 0.6738 - val_loss: 0.8256 - val_accuracy: 0.6360\n",
            "Epoch 1207/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7432 - accuracy: 0.6713 - val_loss: 0.8352 - val_accuracy: 0.6247\n",
            "Epoch 1208/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7481 - accuracy: 0.6682 - val_loss: 0.8280 - val_accuracy: 0.6315\n",
            "Epoch 1209/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7445 - accuracy: 0.6741 - val_loss: 0.8410 - val_accuracy: 0.6258\n",
            "Epoch 1210/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7469 - accuracy: 0.6707 - val_loss: 0.8247 - val_accuracy: 0.6393\n",
            "Epoch 1211/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7459 - accuracy: 0.6741 - val_loss: 0.8216 - val_accuracy: 0.6348\n",
            "Epoch 1212/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7487 - accuracy: 0.6682 - val_loss: 0.8281 - val_accuracy: 0.6303\n",
            "Epoch 1213/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7466 - accuracy: 0.6774 - val_loss: 0.8195 - val_accuracy: 0.6461\n",
            "Epoch 1214/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7459 - accuracy: 0.6718 - val_loss: 0.8252 - val_accuracy: 0.6360\n",
            "Epoch 1215/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7419 - accuracy: 0.6735 - val_loss: 0.8271 - val_accuracy: 0.6258\n",
            "Epoch 1216/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7453 - accuracy: 0.6758 - val_loss: 0.8213 - val_accuracy: 0.6303\n",
            "Epoch 1217/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7444 - accuracy: 0.6718 - val_loss: 0.8246 - val_accuracy: 0.6236\n",
            "Epoch 1218/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7479 - accuracy: 0.6718 - val_loss: 0.8431 - val_accuracy: 0.6213\n",
            "Epoch 1219/2000\n",
            "56/56 [==============================] - 1s 13ms/step - loss: 0.7481 - accuracy: 0.6713 - val_loss: 0.8593 - val_accuracy: 0.6157\n",
            "Epoch 1220/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7481 - accuracy: 0.6729 - val_loss: 0.8406 - val_accuracy: 0.6202\n",
            "Epoch 1221/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7439 - accuracy: 0.6732 - val_loss: 0.8385 - val_accuracy: 0.6281\n",
            "Epoch 1222/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7450 - accuracy: 0.6772 - val_loss: 0.8313 - val_accuracy: 0.6281\n",
            "Epoch 1223/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7425 - accuracy: 0.6763 - val_loss: 0.8309 - val_accuracy: 0.6281\n",
            "Epoch 1224/2000\n",
            "56/56 [==============================] - 1s 10ms/step - loss: 0.7456 - accuracy: 0.6729 - val_loss: 0.8189 - val_accuracy: 0.6360\n",
            "Epoch 1225/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7467 - accuracy: 0.6744 - val_loss: 0.8253 - val_accuracy: 0.6326\n",
            "Epoch 1226/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7440 - accuracy: 0.6665 - val_loss: 0.8200 - val_accuracy: 0.6371\n",
            "Epoch 1227/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7458 - accuracy: 0.6738 - val_loss: 0.8575 - val_accuracy: 0.6146\n",
            "Epoch 1228/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7503 - accuracy: 0.6656 - val_loss: 0.8200 - val_accuracy: 0.6303\n",
            "Epoch 1229/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7418 - accuracy: 0.6772 - val_loss: 0.8241 - val_accuracy: 0.6326\n",
            "Epoch 1230/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7438 - accuracy: 0.6741 - val_loss: 0.8219 - val_accuracy: 0.6270\n",
            "Epoch 1231/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7433 - accuracy: 0.6744 - val_loss: 0.8254 - val_accuracy: 0.6247\n",
            "Epoch 1232/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7412 - accuracy: 0.6738 - val_loss: 0.8239 - val_accuracy: 0.6303\n",
            "Epoch 1233/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7462 - accuracy: 0.6690 - val_loss: 0.8252 - val_accuracy: 0.6315\n",
            "Epoch 1234/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7423 - accuracy: 0.6744 - val_loss: 0.8323 - val_accuracy: 0.6236\n",
            "Epoch 1235/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7439 - accuracy: 0.6721 - val_loss: 0.8225 - val_accuracy: 0.6315\n",
            "Epoch 1236/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7452 - accuracy: 0.6741 - val_loss: 0.8288 - val_accuracy: 0.6303\n",
            "Epoch 1237/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7472 - accuracy: 0.6693 - val_loss: 0.8234 - val_accuracy: 0.6258\n",
            "Epoch 1238/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7468 - accuracy: 0.6735 - val_loss: 0.8256 - val_accuracy: 0.6382\n",
            "Epoch 1239/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7424 - accuracy: 0.6732 - val_loss: 0.8318 - val_accuracy: 0.6292\n",
            "Epoch 1240/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7409 - accuracy: 0.6721 - val_loss: 0.8254 - val_accuracy: 0.6303\n",
            "Epoch 1241/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7440 - accuracy: 0.6780 - val_loss: 0.8291 - val_accuracy: 0.6270\n",
            "Epoch 1242/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7422 - accuracy: 0.6718 - val_loss: 0.8280 - val_accuracy: 0.6281\n",
            "Epoch 1243/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7424 - accuracy: 0.6676 - val_loss: 0.8348 - val_accuracy: 0.6236\n",
            "Epoch 1244/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7401 - accuracy: 0.6780 - val_loss: 0.8355 - val_accuracy: 0.6202\n",
            "Epoch 1245/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7466 - accuracy: 0.6718 - val_loss: 0.8283 - val_accuracy: 0.6326\n",
            "Epoch 1246/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7454 - accuracy: 0.6679 - val_loss: 0.8264 - val_accuracy: 0.6326\n",
            "Epoch 1247/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7416 - accuracy: 0.6732 - val_loss: 0.8198 - val_accuracy: 0.6281\n",
            "Epoch 1248/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7456 - accuracy: 0.6673 - val_loss: 0.8319 - val_accuracy: 0.6270\n",
            "Epoch 1249/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7439 - accuracy: 0.6707 - val_loss: 0.8240 - val_accuracy: 0.6292\n",
            "Epoch 1250/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7433 - accuracy: 0.6729 - val_loss: 0.8355 - val_accuracy: 0.6213\n",
            "Epoch 1251/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7461 - accuracy: 0.6715 - val_loss: 0.8455 - val_accuracy: 0.6191\n",
            "Epoch 1252/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7429 - accuracy: 0.6755 - val_loss: 0.8367 - val_accuracy: 0.6225\n",
            "Epoch 1253/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7458 - accuracy: 0.6718 - val_loss: 0.8228 - val_accuracy: 0.6292\n",
            "Epoch 1254/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7436 - accuracy: 0.6718 - val_loss: 0.8341 - val_accuracy: 0.6270\n",
            "Epoch 1255/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7423 - accuracy: 0.6805 - val_loss: 0.8304 - val_accuracy: 0.6348\n",
            "Epoch 1256/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7419 - accuracy: 0.6710 - val_loss: 0.8319 - val_accuracy: 0.6303\n",
            "Epoch 1257/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7445 - accuracy: 0.6758 - val_loss: 0.8238 - val_accuracy: 0.6303\n",
            "Epoch 1258/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7512 - accuracy: 0.6724 - val_loss: 0.8234 - val_accuracy: 0.6393\n",
            "Epoch 1259/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7437 - accuracy: 0.6763 - val_loss: 0.8330 - val_accuracy: 0.6236\n",
            "Epoch 1260/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7430 - accuracy: 0.6780 - val_loss: 0.8310 - val_accuracy: 0.6315\n",
            "Epoch 1261/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7422 - accuracy: 0.6752 - val_loss: 0.8274 - val_accuracy: 0.6292\n",
            "Epoch 1262/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7406 - accuracy: 0.6738 - val_loss: 0.8277 - val_accuracy: 0.6292\n",
            "Epoch 1263/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7429 - accuracy: 0.6755 - val_loss: 0.8248 - val_accuracy: 0.6337\n",
            "Epoch 1264/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7431 - accuracy: 0.6724 - val_loss: 0.8286 - val_accuracy: 0.6270\n",
            "Epoch 1265/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7442 - accuracy: 0.6679 - val_loss: 0.8241 - val_accuracy: 0.6281\n",
            "Epoch 1266/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7424 - accuracy: 0.6713 - val_loss: 0.8246 - val_accuracy: 0.6326\n",
            "Epoch 1267/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7446 - accuracy: 0.6707 - val_loss: 0.8264 - val_accuracy: 0.6270\n",
            "Epoch 1268/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7408 - accuracy: 0.6763 - val_loss: 0.8389 - val_accuracy: 0.6202\n",
            "Epoch 1269/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7435 - accuracy: 0.6738 - val_loss: 0.8261 - val_accuracy: 0.6270\n",
            "Epoch 1270/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7439 - accuracy: 0.6746 - val_loss: 0.8259 - val_accuracy: 0.6393\n",
            "Epoch 1271/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7416 - accuracy: 0.6744 - val_loss: 0.8397 - val_accuracy: 0.6303\n",
            "Epoch 1272/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7434 - accuracy: 0.6760 - val_loss: 0.8434 - val_accuracy: 0.6202\n",
            "Epoch 1273/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7428 - accuracy: 0.6693 - val_loss: 0.8338 - val_accuracy: 0.6270\n",
            "Epoch 1274/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7456 - accuracy: 0.6769 - val_loss: 0.8598 - val_accuracy: 0.6135\n",
            "Epoch 1275/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7449 - accuracy: 0.6718 - val_loss: 0.8234 - val_accuracy: 0.6247\n",
            "Epoch 1276/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7413 - accuracy: 0.6766 - val_loss: 0.8314 - val_accuracy: 0.6225\n",
            "Epoch 1277/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7406 - accuracy: 0.6715 - val_loss: 0.8203 - val_accuracy: 0.6270\n",
            "Epoch 1278/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7431 - accuracy: 0.6715 - val_loss: 0.8269 - val_accuracy: 0.6360\n",
            "Epoch 1279/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7430 - accuracy: 0.6738 - val_loss: 0.8353 - val_accuracy: 0.6326\n",
            "Epoch 1280/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7483 - accuracy: 0.6735 - val_loss: 0.8351 - val_accuracy: 0.6236\n",
            "Epoch 1281/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7430 - accuracy: 0.6710 - val_loss: 0.8215 - val_accuracy: 0.6416\n",
            "Epoch 1282/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7420 - accuracy: 0.6774 - val_loss: 0.8257 - val_accuracy: 0.6303\n",
            "Epoch 1283/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7404 - accuracy: 0.6755 - val_loss: 0.8212 - val_accuracy: 0.6393\n",
            "Epoch 1284/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7413 - accuracy: 0.6729 - val_loss: 0.8227 - val_accuracy: 0.6326\n",
            "Epoch 1285/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7411 - accuracy: 0.6729 - val_loss: 0.8354 - val_accuracy: 0.6225\n",
            "Epoch 1286/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7429 - accuracy: 0.6758 - val_loss: 0.8306 - val_accuracy: 0.6315\n",
            "Epoch 1287/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7421 - accuracy: 0.6797 - val_loss: 0.8262 - val_accuracy: 0.6258\n",
            "Epoch 1288/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7405 - accuracy: 0.6800 - val_loss: 0.8293 - val_accuracy: 0.6303\n",
            "Epoch 1289/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7399 - accuracy: 0.6741 - val_loss: 0.8230 - val_accuracy: 0.6371\n",
            "Epoch 1290/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7454 - accuracy: 0.6682 - val_loss: 0.8305 - val_accuracy: 0.6326\n",
            "Epoch 1291/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7445 - accuracy: 0.6724 - val_loss: 0.8208 - val_accuracy: 0.6292\n",
            "Epoch 1292/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7421 - accuracy: 0.6727 - val_loss: 0.8192 - val_accuracy: 0.6337\n",
            "Epoch 1293/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7447 - accuracy: 0.6800 - val_loss: 0.8254 - val_accuracy: 0.6225\n",
            "Epoch 1294/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7425 - accuracy: 0.6713 - val_loss: 0.8262 - val_accuracy: 0.6326\n",
            "Epoch 1295/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7409 - accuracy: 0.6721 - val_loss: 0.8391 - val_accuracy: 0.6281\n",
            "Epoch 1296/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7406 - accuracy: 0.6789 - val_loss: 0.8427 - val_accuracy: 0.6225\n",
            "Epoch 1297/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7422 - accuracy: 0.6713 - val_loss: 0.8298 - val_accuracy: 0.6247\n",
            "Epoch 1298/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7422 - accuracy: 0.6724 - val_loss: 0.8204 - val_accuracy: 0.6393\n",
            "Epoch 1299/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7407 - accuracy: 0.6786 - val_loss: 0.8203 - val_accuracy: 0.6382\n",
            "Epoch 1300/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7420 - accuracy: 0.6727 - val_loss: 0.8202 - val_accuracy: 0.6371\n",
            "Epoch 1301/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7409 - accuracy: 0.6718 - val_loss: 0.8219 - val_accuracy: 0.6360\n",
            "Epoch 1302/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7464 - accuracy: 0.6721 - val_loss: 0.8426 - val_accuracy: 0.6247\n",
            "Epoch 1303/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7508 - accuracy: 0.6727 - val_loss: 0.8152 - val_accuracy: 0.6337\n",
            "Epoch 1304/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7406 - accuracy: 0.6800 - val_loss: 0.8252 - val_accuracy: 0.6303\n",
            "Epoch 1305/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7432 - accuracy: 0.6772 - val_loss: 0.8284 - val_accuracy: 0.6326\n",
            "Epoch 1306/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7406 - accuracy: 0.6721 - val_loss: 0.8430 - val_accuracy: 0.6202\n",
            "Epoch 1307/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7413 - accuracy: 0.6746 - val_loss: 0.8321 - val_accuracy: 0.6258\n",
            "Epoch 1308/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7403 - accuracy: 0.6696 - val_loss: 0.8438 - val_accuracy: 0.6202\n",
            "Epoch 1309/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7508 - accuracy: 0.6721 - val_loss: 0.8280 - val_accuracy: 0.6292\n",
            "Epoch 1310/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7395 - accuracy: 0.6724 - val_loss: 0.8252 - val_accuracy: 0.6270\n",
            "Epoch 1311/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7384 - accuracy: 0.6772 - val_loss: 0.8239 - val_accuracy: 0.6315\n",
            "Epoch 1312/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7422 - accuracy: 0.6687 - val_loss: 0.8248 - val_accuracy: 0.6315\n",
            "Epoch 1313/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7432 - accuracy: 0.6741 - val_loss: 0.8259 - val_accuracy: 0.6258\n",
            "Epoch 1314/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7392 - accuracy: 0.6803 - val_loss: 0.8308 - val_accuracy: 0.6213\n",
            "Epoch 1315/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7399 - accuracy: 0.6769 - val_loss: 0.8301 - val_accuracy: 0.6315\n",
            "Epoch 1316/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7407 - accuracy: 0.6746 - val_loss: 0.8238 - val_accuracy: 0.6348\n",
            "Epoch 1317/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7378 - accuracy: 0.6774 - val_loss: 0.8295 - val_accuracy: 0.6270\n",
            "Epoch 1318/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7377 - accuracy: 0.6805 - val_loss: 0.8249 - val_accuracy: 0.6326\n",
            "Epoch 1319/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7390 - accuracy: 0.6715 - val_loss: 0.8363 - val_accuracy: 0.6225\n",
            "Epoch 1320/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7424 - accuracy: 0.6746 - val_loss: 0.8367 - val_accuracy: 0.6225\n",
            "Epoch 1321/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7411 - accuracy: 0.6791 - val_loss: 0.8258 - val_accuracy: 0.6303\n",
            "Epoch 1322/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7376 - accuracy: 0.6789 - val_loss: 0.8232 - val_accuracy: 0.6303\n",
            "Epoch 1323/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7369 - accuracy: 0.6780 - val_loss: 0.8280 - val_accuracy: 0.6270\n",
            "Epoch 1324/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7404 - accuracy: 0.6786 - val_loss: 0.8383 - val_accuracy: 0.6247\n",
            "Epoch 1325/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7400 - accuracy: 0.6803 - val_loss: 0.8265 - val_accuracy: 0.6202\n",
            "Epoch 1326/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7400 - accuracy: 0.6749 - val_loss: 0.8249 - val_accuracy: 0.6281\n",
            "Epoch 1327/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7395 - accuracy: 0.6738 - val_loss: 0.8290 - val_accuracy: 0.6303\n",
            "Epoch 1328/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7403 - accuracy: 0.6699 - val_loss: 0.8183 - val_accuracy: 0.6348\n",
            "Epoch 1329/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7412 - accuracy: 0.6797 - val_loss: 0.8149 - val_accuracy: 0.6337\n",
            "Epoch 1330/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7365 - accuracy: 0.6755 - val_loss: 0.8339 - val_accuracy: 0.6236\n",
            "Epoch 1331/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7484 - accuracy: 0.6752 - val_loss: 0.8222 - val_accuracy: 0.6393\n",
            "Epoch 1332/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7406 - accuracy: 0.6746 - val_loss: 0.8428 - val_accuracy: 0.6202\n",
            "Epoch 1333/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7409 - accuracy: 0.6752 - val_loss: 0.8190 - val_accuracy: 0.6270\n",
            "Epoch 1334/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7369 - accuracy: 0.6791 - val_loss: 0.8314 - val_accuracy: 0.6258\n",
            "Epoch 1335/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7386 - accuracy: 0.6808 - val_loss: 0.8238 - val_accuracy: 0.6348\n",
            "Epoch 1336/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7379 - accuracy: 0.6729 - val_loss: 0.8236 - val_accuracy: 0.6326\n",
            "Epoch 1337/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7380 - accuracy: 0.6766 - val_loss: 0.8320 - val_accuracy: 0.6326\n",
            "Epoch 1338/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7407 - accuracy: 0.6724 - val_loss: 0.8227 - val_accuracy: 0.6213\n",
            "Epoch 1339/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7414 - accuracy: 0.6741 - val_loss: 0.8310 - val_accuracy: 0.6303\n",
            "Epoch 1340/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7397 - accuracy: 0.6735 - val_loss: 0.8221 - val_accuracy: 0.6360\n",
            "Epoch 1341/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7413 - accuracy: 0.6758 - val_loss: 0.8309 - val_accuracy: 0.6225\n",
            "Epoch 1342/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7394 - accuracy: 0.6696 - val_loss: 0.8272 - val_accuracy: 0.6236\n",
            "Epoch 1343/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7379 - accuracy: 0.6752 - val_loss: 0.8239 - val_accuracy: 0.6360\n",
            "Epoch 1344/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7384 - accuracy: 0.6749 - val_loss: 0.8168 - val_accuracy: 0.6303\n",
            "Epoch 1345/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7376 - accuracy: 0.6783 - val_loss: 0.8207 - val_accuracy: 0.6326\n",
            "Epoch 1346/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7397 - accuracy: 0.6758 - val_loss: 0.8286 - val_accuracy: 0.6281\n",
            "Epoch 1347/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7414 - accuracy: 0.6710 - val_loss: 0.8352 - val_accuracy: 0.6236\n",
            "Epoch 1348/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7405 - accuracy: 0.6749 - val_loss: 0.8255 - val_accuracy: 0.6258\n",
            "Epoch 1349/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7399 - accuracy: 0.6727 - val_loss: 0.8215 - val_accuracy: 0.6281\n",
            "Epoch 1350/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7393 - accuracy: 0.6769 - val_loss: 0.8217 - val_accuracy: 0.6360\n",
            "Epoch 1351/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7379 - accuracy: 0.6741 - val_loss: 0.8345 - val_accuracy: 0.6315\n",
            "Epoch 1352/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7391 - accuracy: 0.6791 - val_loss: 0.8255 - val_accuracy: 0.6337\n",
            "Epoch 1353/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7365 - accuracy: 0.6800 - val_loss: 0.8191 - val_accuracy: 0.6315\n",
            "Epoch 1354/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7435 - accuracy: 0.6766 - val_loss: 0.8218 - val_accuracy: 0.6258\n",
            "Epoch 1355/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7370 - accuracy: 0.6758 - val_loss: 0.8282 - val_accuracy: 0.6371\n",
            "Epoch 1356/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7384 - accuracy: 0.6735 - val_loss: 0.8237 - val_accuracy: 0.6360\n",
            "Epoch 1357/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7381 - accuracy: 0.6766 - val_loss: 0.8206 - val_accuracy: 0.6348\n",
            "Epoch 1358/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7368 - accuracy: 0.6828 - val_loss: 0.8190 - val_accuracy: 0.6281\n",
            "Epoch 1359/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7374 - accuracy: 0.6744 - val_loss: 0.8167 - val_accuracy: 0.6360\n",
            "Epoch 1360/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7376 - accuracy: 0.6713 - val_loss: 0.8287 - val_accuracy: 0.6213\n",
            "Epoch 1361/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7424 - accuracy: 0.6710 - val_loss: 0.8294 - val_accuracy: 0.6213\n",
            "Epoch 1362/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7410 - accuracy: 0.6696 - val_loss: 0.8188 - val_accuracy: 0.6326\n",
            "Epoch 1363/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7373 - accuracy: 0.6763 - val_loss: 0.8206 - val_accuracy: 0.6303\n",
            "Epoch 1364/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7385 - accuracy: 0.6752 - val_loss: 0.8519 - val_accuracy: 0.6169\n",
            "Epoch 1365/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7401 - accuracy: 0.6699 - val_loss: 0.8195 - val_accuracy: 0.6281\n",
            "Epoch 1366/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7384 - accuracy: 0.6735 - val_loss: 0.8360 - val_accuracy: 0.6236\n",
            "Epoch 1367/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7381 - accuracy: 0.6727 - val_loss: 0.8179 - val_accuracy: 0.6438\n",
            "Epoch 1368/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7375 - accuracy: 0.6789 - val_loss: 0.8343 - val_accuracy: 0.6270\n",
            "Epoch 1369/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7368 - accuracy: 0.6758 - val_loss: 0.8270 - val_accuracy: 0.6303\n",
            "Epoch 1370/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7365 - accuracy: 0.6766 - val_loss: 0.8513 - val_accuracy: 0.6236\n",
            "Epoch 1371/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7401 - accuracy: 0.6758 - val_loss: 0.8290 - val_accuracy: 0.6292\n",
            "Epoch 1372/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7367 - accuracy: 0.6800 - val_loss: 0.8188 - val_accuracy: 0.6315\n",
            "Epoch 1373/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7365 - accuracy: 0.6735 - val_loss: 0.8241 - val_accuracy: 0.6236\n",
            "Epoch 1374/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7388 - accuracy: 0.6693 - val_loss: 0.8222 - val_accuracy: 0.6281\n",
            "Epoch 1375/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7361 - accuracy: 0.6774 - val_loss: 0.8215 - val_accuracy: 0.6281\n",
            "Epoch 1376/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7357 - accuracy: 0.6760 - val_loss: 0.8198 - val_accuracy: 0.6303\n",
            "Epoch 1377/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7406 - accuracy: 0.6755 - val_loss: 0.8180 - val_accuracy: 0.6303\n",
            "Epoch 1378/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7391 - accuracy: 0.6746 - val_loss: 0.8134 - val_accuracy: 0.6303\n",
            "Epoch 1379/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7389 - accuracy: 0.6797 - val_loss: 0.8328 - val_accuracy: 0.6281\n",
            "Epoch 1380/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7337 - accuracy: 0.6729 - val_loss: 0.8172 - val_accuracy: 0.6258\n",
            "Epoch 1381/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7366 - accuracy: 0.6828 - val_loss: 0.8208 - val_accuracy: 0.6326\n",
            "Epoch 1382/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7376 - accuracy: 0.6777 - val_loss: 0.8135 - val_accuracy: 0.6382\n",
            "Epoch 1383/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7385 - accuracy: 0.6774 - val_loss: 0.8225 - val_accuracy: 0.6281\n",
            "Epoch 1384/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7378 - accuracy: 0.6755 - val_loss: 0.8175 - val_accuracy: 0.6303\n",
            "Epoch 1385/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7390 - accuracy: 0.6789 - val_loss: 0.8181 - val_accuracy: 0.6236\n",
            "Epoch 1386/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7380 - accuracy: 0.6797 - val_loss: 0.8282 - val_accuracy: 0.6360\n",
            "Epoch 1387/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7401 - accuracy: 0.6769 - val_loss: 0.8160 - val_accuracy: 0.6360\n",
            "Epoch 1388/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7344 - accuracy: 0.6780 - val_loss: 0.8197 - val_accuracy: 0.6281\n",
            "Epoch 1389/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7346 - accuracy: 0.6713 - val_loss: 0.8248 - val_accuracy: 0.6292\n",
            "Epoch 1390/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7413 - accuracy: 0.6749 - val_loss: 0.8194 - val_accuracy: 0.6315\n",
            "Epoch 1391/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7386 - accuracy: 0.6794 - val_loss: 0.8171 - val_accuracy: 0.6348\n",
            "Epoch 1392/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7370 - accuracy: 0.6789 - val_loss: 0.8190 - val_accuracy: 0.6382\n",
            "Epoch 1393/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7375 - accuracy: 0.6738 - val_loss: 0.8343 - val_accuracy: 0.6270\n",
            "Epoch 1394/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7381 - accuracy: 0.6744 - val_loss: 0.8162 - val_accuracy: 0.6270\n",
            "Epoch 1395/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7355 - accuracy: 0.6738 - val_loss: 0.8156 - val_accuracy: 0.6303\n",
            "Epoch 1396/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7374 - accuracy: 0.6791 - val_loss: 0.8213 - val_accuracy: 0.6258\n",
            "Epoch 1397/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7415 - accuracy: 0.6727 - val_loss: 0.8131 - val_accuracy: 0.6247\n",
            "Epoch 1398/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7395 - accuracy: 0.6758 - val_loss: 0.8194 - val_accuracy: 0.6292\n",
            "Epoch 1399/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7370 - accuracy: 0.6777 - val_loss: 0.8152 - val_accuracy: 0.6348\n",
            "Epoch 1400/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7357 - accuracy: 0.6758 - val_loss: 0.8299 - val_accuracy: 0.6247\n",
            "Epoch 1401/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7376 - accuracy: 0.6772 - val_loss: 0.8184 - val_accuracy: 0.6258\n",
            "Epoch 1402/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7444 - accuracy: 0.6648 - val_loss: 0.8434 - val_accuracy: 0.6247\n",
            "Epoch 1403/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7366 - accuracy: 0.6752 - val_loss: 0.8180 - val_accuracy: 0.6247\n",
            "Epoch 1404/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7348 - accuracy: 0.6805 - val_loss: 0.8211 - val_accuracy: 0.6360\n",
            "Epoch 1405/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7356 - accuracy: 0.6755 - val_loss: 0.8262 - val_accuracy: 0.6270\n",
            "Epoch 1406/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7369 - accuracy: 0.6811 - val_loss: 0.8286 - val_accuracy: 0.6292\n",
            "Epoch 1407/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7379 - accuracy: 0.6710 - val_loss: 0.8184 - val_accuracy: 0.6326\n",
            "Epoch 1408/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7383 - accuracy: 0.6783 - val_loss: 0.8260 - val_accuracy: 0.6315\n",
            "Epoch 1409/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7328 - accuracy: 0.6800 - val_loss: 0.8350 - val_accuracy: 0.6303\n",
            "Epoch 1410/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7390 - accuracy: 0.6758 - val_loss: 0.8289 - val_accuracy: 0.6371\n",
            "Epoch 1411/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7358 - accuracy: 0.6789 - val_loss: 0.8240 - val_accuracy: 0.6281\n",
            "Epoch 1412/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7357 - accuracy: 0.6797 - val_loss: 0.8337 - val_accuracy: 0.6371\n",
            "Epoch 1413/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7432 - accuracy: 0.6755 - val_loss: 0.8353 - val_accuracy: 0.6247\n",
            "Epoch 1414/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7349 - accuracy: 0.6752 - val_loss: 0.8194 - val_accuracy: 0.6258\n",
            "Epoch 1415/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7336 - accuracy: 0.6724 - val_loss: 0.8190 - val_accuracy: 0.6326\n",
            "Epoch 1416/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7376 - accuracy: 0.6808 - val_loss: 0.8230 - val_accuracy: 0.6292\n",
            "Epoch 1417/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7376 - accuracy: 0.6763 - val_loss: 0.8235 - val_accuracy: 0.6371\n",
            "Epoch 1418/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7392 - accuracy: 0.6715 - val_loss: 0.8184 - val_accuracy: 0.6281\n",
            "Epoch 1419/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7377 - accuracy: 0.6777 - val_loss: 0.8164 - val_accuracy: 0.6382\n",
            "Epoch 1420/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7361 - accuracy: 0.6766 - val_loss: 0.8181 - val_accuracy: 0.6315\n",
            "Epoch 1421/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7374 - accuracy: 0.6752 - val_loss: 0.8164 - val_accuracy: 0.6303\n",
            "Epoch 1422/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7362 - accuracy: 0.6783 - val_loss: 0.8196 - val_accuracy: 0.6315\n",
            "Epoch 1423/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7358 - accuracy: 0.6780 - val_loss: 0.8147 - val_accuracy: 0.6270\n",
            "Epoch 1424/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7380 - accuracy: 0.6735 - val_loss: 0.8361 - val_accuracy: 0.6303\n",
            "Epoch 1425/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7361 - accuracy: 0.6808 - val_loss: 0.8215 - val_accuracy: 0.6326\n",
            "Epoch 1426/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7402 - accuracy: 0.6738 - val_loss: 0.8231 - val_accuracy: 0.6337\n",
            "Epoch 1427/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7340 - accuracy: 0.6814 - val_loss: 0.8218 - val_accuracy: 0.6247\n",
            "Epoch 1428/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7341 - accuracy: 0.6780 - val_loss: 0.8238 - val_accuracy: 0.6281\n",
            "Epoch 1429/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7345 - accuracy: 0.6755 - val_loss: 0.8163 - val_accuracy: 0.6281\n",
            "Epoch 1430/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7356 - accuracy: 0.6746 - val_loss: 0.8201 - val_accuracy: 0.6315\n",
            "Epoch 1431/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7324 - accuracy: 0.6774 - val_loss: 0.8269 - val_accuracy: 0.6326\n",
            "Epoch 1432/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7357 - accuracy: 0.6774 - val_loss: 0.8226 - val_accuracy: 0.6348\n",
            "Epoch 1433/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7388 - accuracy: 0.6797 - val_loss: 0.8292 - val_accuracy: 0.6337\n",
            "Epoch 1434/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7331 - accuracy: 0.6772 - val_loss: 0.8203 - val_accuracy: 0.6281\n",
            "Epoch 1435/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7340 - accuracy: 0.6803 - val_loss: 0.8240 - val_accuracy: 0.6270\n",
            "Epoch 1436/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7328 - accuracy: 0.6797 - val_loss: 0.8532 - val_accuracy: 0.6191\n",
            "Epoch 1437/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7377 - accuracy: 0.6766 - val_loss: 0.8445 - val_accuracy: 0.6236\n",
            "Epoch 1438/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7343 - accuracy: 0.6763 - val_loss: 0.8193 - val_accuracy: 0.6303\n",
            "Epoch 1439/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7329 - accuracy: 0.6811 - val_loss: 0.8211 - val_accuracy: 0.6292\n",
            "Epoch 1440/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7343 - accuracy: 0.6772 - val_loss: 0.8218 - val_accuracy: 0.6270\n",
            "Epoch 1441/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7332 - accuracy: 0.6758 - val_loss: 0.8353 - val_accuracy: 0.6258\n",
            "Epoch 1442/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7349 - accuracy: 0.6769 - val_loss: 0.8230 - val_accuracy: 0.6393\n",
            "Epoch 1443/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7392 - accuracy: 0.6791 - val_loss: 0.8276 - val_accuracy: 0.6315\n",
            "Epoch 1444/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7330 - accuracy: 0.6814 - val_loss: 0.8183 - val_accuracy: 0.6326\n",
            "Epoch 1445/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7332 - accuracy: 0.6791 - val_loss: 0.8188 - val_accuracy: 0.6292\n",
            "Epoch 1446/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7340 - accuracy: 0.6867 - val_loss: 0.8173 - val_accuracy: 0.6292\n",
            "Epoch 1447/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7346 - accuracy: 0.6828 - val_loss: 0.8267 - val_accuracy: 0.6225\n",
            "Epoch 1448/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7363 - accuracy: 0.6783 - val_loss: 0.8218 - val_accuracy: 0.6303\n",
            "Epoch 1449/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7345 - accuracy: 0.6825 - val_loss: 0.8210 - val_accuracy: 0.6348\n",
            "Epoch 1450/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7328 - accuracy: 0.6780 - val_loss: 0.8176 - val_accuracy: 0.6270\n",
            "Epoch 1451/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7313 - accuracy: 0.6772 - val_loss: 0.8265 - val_accuracy: 0.6348\n",
            "Epoch 1452/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7331 - accuracy: 0.6769 - val_loss: 0.8291 - val_accuracy: 0.6281\n",
            "Epoch 1453/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7329 - accuracy: 0.6791 - val_loss: 0.8253 - val_accuracy: 0.6438\n",
            "Epoch 1454/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7359 - accuracy: 0.6777 - val_loss: 0.8162 - val_accuracy: 0.6360\n",
            "Epoch 1455/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7344 - accuracy: 0.6800 - val_loss: 0.8180 - val_accuracy: 0.6371\n",
            "Epoch 1456/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7375 - accuracy: 0.6817 - val_loss: 0.8231 - val_accuracy: 0.6258\n",
            "Epoch 1457/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7368 - accuracy: 0.6744 - val_loss: 0.8305 - val_accuracy: 0.6258\n",
            "Epoch 1458/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7330 - accuracy: 0.6769 - val_loss: 0.8167 - val_accuracy: 0.6393\n",
            "Epoch 1459/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7413 - accuracy: 0.6789 - val_loss: 0.8207 - val_accuracy: 0.6326\n",
            "Epoch 1460/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7308 - accuracy: 0.6763 - val_loss: 0.8190 - val_accuracy: 0.6303\n",
            "Epoch 1461/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7393 - accuracy: 0.6696 - val_loss: 0.8226 - val_accuracy: 0.6270\n",
            "Epoch 1462/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7332 - accuracy: 0.6760 - val_loss: 0.8228 - val_accuracy: 0.6281\n",
            "Epoch 1463/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7324 - accuracy: 0.6777 - val_loss: 0.8350 - val_accuracy: 0.6213\n",
            "Epoch 1464/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7342 - accuracy: 0.6783 - val_loss: 0.8248 - val_accuracy: 0.6270\n",
            "Epoch 1465/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7331 - accuracy: 0.6819 - val_loss: 0.8498 - val_accuracy: 0.6180\n",
            "Epoch 1466/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7337 - accuracy: 0.6808 - val_loss: 0.8361 - val_accuracy: 0.6213\n",
            "Epoch 1467/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7329 - accuracy: 0.6822 - val_loss: 0.8230 - val_accuracy: 0.6337\n",
            "Epoch 1468/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7323 - accuracy: 0.6749 - val_loss: 0.8292 - val_accuracy: 0.6281\n",
            "Epoch 1469/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7319 - accuracy: 0.6786 - val_loss: 0.8195 - val_accuracy: 0.6337\n",
            "Epoch 1470/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7359 - accuracy: 0.6845 - val_loss: 0.8192 - val_accuracy: 0.6315\n",
            "Epoch 1471/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7362 - accuracy: 0.6699 - val_loss: 0.8277 - val_accuracy: 0.6303\n",
            "Epoch 1472/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7334 - accuracy: 0.6769 - val_loss: 0.8189 - val_accuracy: 0.6191\n",
            "Epoch 1473/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7337 - accuracy: 0.6791 - val_loss: 0.8192 - val_accuracy: 0.6315\n",
            "Epoch 1474/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7355 - accuracy: 0.6763 - val_loss: 0.8171 - val_accuracy: 0.6281\n",
            "Epoch 1475/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7313 - accuracy: 0.6859 - val_loss: 0.8157 - val_accuracy: 0.6360\n",
            "Epoch 1476/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7326 - accuracy: 0.6766 - val_loss: 0.8221 - val_accuracy: 0.6315\n",
            "Epoch 1477/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7289 - accuracy: 0.6794 - val_loss: 0.8201 - val_accuracy: 0.6303\n",
            "Epoch 1478/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7364 - accuracy: 0.6721 - val_loss: 0.8196 - val_accuracy: 0.6315\n",
            "Epoch 1479/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7320 - accuracy: 0.6797 - val_loss: 0.8189 - val_accuracy: 0.6281\n",
            "Epoch 1480/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7303 - accuracy: 0.6777 - val_loss: 0.8300 - val_accuracy: 0.6303\n",
            "Epoch 1481/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7368 - accuracy: 0.6763 - val_loss: 0.8138 - val_accuracy: 0.6303\n",
            "Epoch 1482/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7346 - accuracy: 0.6710 - val_loss: 0.8257 - val_accuracy: 0.6281\n",
            "Epoch 1483/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7374 - accuracy: 0.6786 - val_loss: 0.8381 - val_accuracy: 0.6292\n",
            "Epoch 1484/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7322 - accuracy: 0.6766 - val_loss: 0.8151 - val_accuracy: 0.6303\n",
            "Epoch 1485/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7330 - accuracy: 0.6774 - val_loss: 0.8186 - val_accuracy: 0.6292\n",
            "Epoch 1486/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7345 - accuracy: 0.6777 - val_loss: 0.8162 - val_accuracy: 0.6281\n",
            "Epoch 1487/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7349 - accuracy: 0.6825 - val_loss: 0.8198 - val_accuracy: 0.6382\n",
            "Epoch 1488/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7361 - accuracy: 0.6755 - val_loss: 0.8133 - val_accuracy: 0.6371\n",
            "Epoch 1489/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7321 - accuracy: 0.6780 - val_loss: 0.8173 - val_accuracy: 0.6303\n",
            "Epoch 1490/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7334 - accuracy: 0.6774 - val_loss: 0.8206 - val_accuracy: 0.6247\n",
            "Epoch 1491/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7318 - accuracy: 0.6777 - val_loss: 0.8148 - val_accuracy: 0.6315\n",
            "Epoch 1492/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7340 - accuracy: 0.6741 - val_loss: 0.8203 - val_accuracy: 0.6393\n",
            "Epoch 1493/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7294 - accuracy: 0.6791 - val_loss: 0.8175 - val_accuracy: 0.6315\n",
            "Epoch 1494/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7337 - accuracy: 0.6805 - val_loss: 0.8321 - val_accuracy: 0.6225\n",
            "Epoch 1495/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7353 - accuracy: 0.6763 - val_loss: 0.8256 - val_accuracy: 0.6292\n",
            "Epoch 1496/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7321 - accuracy: 0.6721 - val_loss: 0.8187 - val_accuracy: 0.6315\n",
            "Epoch 1497/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7314 - accuracy: 0.6808 - val_loss: 0.8172 - val_accuracy: 0.6337\n",
            "Epoch 1498/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7290 - accuracy: 0.6797 - val_loss: 0.8200 - val_accuracy: 0.6303\n",
            "Epoch 1499/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7339 - accuracy: 0.6735 - val_loss: 0.8263 - val_accuracy: 0.6247\n",
            "Epoch 1500/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7324 - accuracy: 0.6791 - val_loss: 0.8190 - val_accuracy: 0.6315\n",
            "Epoch 1501/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7337 - accuracy: 0.6769 - val_loss: 0.8614 - val_accuracy: 0.6191\n",
            "Epoch 1502/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7372 - accuracy: 0.6772 - val_loss: 0.8299 - val_accuracy: 0.6281\n",
            "Epoch 1503/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7327 - accuracy: 0.6862 - val_loss: 0.8213 - val_accuracy: 0.6281\n",
            "Epoch 1504/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7317 - accuracy: 0.6873 - val_loss: 0.8237 - val_accuracy: 0.6213\n",
            "Epoch 1505/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7346 - accuracy: 0.6744 - val_loss: 0.8171 - val_accuracy: 0.6315\n",
            "Epoch 1506/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7304 - accuracy: 0.6834 - val_loss: 0.8191 - val_accuracy: 0.6382\n",
            "Epoch 1507/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7347 - accuracy: 0.6746 - val_loss: 0.8168 - val_accuracy: 0.6292\n",
            "Epoch 1508/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7352 - accuracy: 0.6834 - val_loss: 0.8281 - val_accuracy: 0.6292\n",
            "Epoch 1509/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7346 - accuracy: 0.6744 - val_loss: 0.8401 - val_accuracy: 0.6258\n",
            "Epoch 1510/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7300 - accuracy: 0.6805 - val_loss: 0.8162 - val_accuracy: 0.6382\n",
            "Epoch 1511/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7314 - accuracy: 0.6794 - val_loss: 0.8137 - val_accuracy: 0.6393\n",
            "Epoch 1512/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7344 - accuracy: 0.6766 - val_loss: 0.8164 - val_accuracy: 0.6382\n",
            "Epoch 1513/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7325 - accuracy: 0.6794 - val_loss: 0.8170 - val_accuracy: 0.6337\n",
            "Epoch 1514/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7310 - accuracy: 0.6766 - val_loss: 0.8138 - val_accuracy: 0.6337\n",
            "Epoch 1515/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7311 - accuracy: 0.6774 - val_loss: 0.8337 - val_accuracy: 0.6270\n",
            "Epoch 1516/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7304 - accuracy: 0.6811 - val_loss: 0.8157 - val_accuracy: 0.6348\n",
            "Epoch 1517/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7312 - accuracy: 0.6808 - val_loss: 0.8236 - val_accuracy: 0.6315\n",
            "Epoch 1518/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7294 - accuracy: 0.6791 - val_loss: 0.8227 - val_accuracy: 0.6348\n",
            "Epoch 1519/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7340 - accuracy: 0.6732 - val_loss: 0.8095 - val_accuracy: 0.6337\n",
            "Epoch 1520/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7292 - accuracy: 0.6777 - val_loss: 0.8229 - val_accuracy: 0.6348\n",
            "Epoch 1521/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7326 - accuracy: 0.6780 - val_loss: 0.8301 - val_accuracy: 0.6461\n",
            "Epoch 1522/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7382 - accuracy: 0.6727 - val_loss: 0.8207 - val_accuracy: 0.6258\n",
            "Epoch 1523/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7309 - accuracy: 0.6791 - val_loss: 0.8223 - val_accuracy: 0.6292\n",
            "Epoch 1524/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7286 - accuracy: 0.6828 - val_loss: 0.8150 - val_accuracy: 0.6371\n",
            "Epoch 1525/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7317 - accuracy: 0.6803 - val_loss: 0.8138 - val_accuracy: 0.6326\n",
            "Epoch 1526/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7298 - accuracy: 0.6777 - val_loss: 0.8208 - val_accuracy: 0.6337\n",
            "Epoch 1527/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7286 - accuracy: 0.6831 - val_loss: 0.8152 - val_accuracy: 0.6360\n",
            "Epoch 1528/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7287 - accuracy: 0.6774 - val_loss: 0.8199 - val_accuracy: 0.6315\n",
            "Epoch 1529/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7315 - accuracy: 0.6780 - val_loss: 0.8178 - val_accuracy: 0.6258\n",
            "Epoch 1530/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7325 - accuracy: 0.6850 - val_loss: 0.8153 - val_accuracy: 0.6326\n",
            "Epoch 1531/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7278 - accuracy: 0.6819 - val_loss: 0.8236 - val_accuracy: 0.6281\n",
            "Epoch 1532/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7293 - accuracy: 0.6780 - val_loss: 0.8202 - val_accuracy: 0.6315\n",
            "Epoch 1533/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7310 - accuracy: 0.6763 - val_loss: 0.8195 - val_accuracy: 0.6315\n",
            "Epoch 1534/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7299 - accuracy: 0.6817 - val_loss: 0.8175 - val_accuracy: 0.6360\n",
            "Epoch 1535/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7321 - accuracy: 0.6814 - val_loss: 0.8158 - val_accuracy: 0.6461\n",
            "Epoch 1536/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7329 - accuracy: 0.6786 - val_loss: 0.8221 - val_accuracy: 0.6303\n",
            "Epoch 1537/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7304 - accuracy: 0.6819 - val_loss: 0.8528 - val_accuracy: 0.6225\n",
            "Epoch 1538/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7374 - accuracy: 0.6755 - val_loss: 0.8252 - val_accuracy: 0.6337\n",
            "Epoch 1539/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7315 - accuracy: 0.6789 - val_loss: 0.8181 - val_accuracy: 0.6270\n",
            "Epoch 1540/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7282 - accuracy: 0.6822 - val_loss: 0.8128 - val_accuracy: 0.6326\n",
            "Epoch 1541/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7291 - accuracy: 0.6845 - val_loss: 0.8481 - val_accuracy: 0.6236\n",
            "Epoch 1542/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7313 - accuracy: 0.6741 - val_loss: 0.8129 - val_accuracy: 0.6393\n",
            "Epoch 1543/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7291 - accuracy: 0.6842 - val_loss: 0.8142 - val_accuracy: 0.6270\n",
            "Epoch 1544/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7299 - accuracy: 0.6876 - val_loss: 0.8428 - val_accuracy: 0.6258\n",
            "Epoch 1545/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7323 - accuracy: 0.6729 - val_loss: 0.8245 - val_accuracy: 0.6393\n",
            "Epoch 1546/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7332 - accuracy: 0.6749 - val_loss: 0.8207 - val_accuracy: 0.6303\n",
            "Epoch 1547/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7277 - accuracy: 0.6831 - val_loss: 0.8244 - val_accuracy: 0.6382\n",
            "Epoch 1548/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7308 - accuracy: 0.6864 - val_loss: 0.8148 - val_accuracy: 0.6337\n",
            "Epoch 1549/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7312 - accuracy: 0.6814 - val_loss: 0.8198 - val_accuracy: 0.6326\n",
            "Epoch 1550/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7286 - accuracy: 0.6828 - val_loss: 0.8146 - val_accuracy: 0.6348\n",
            "Epoch 1551/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7369 - accuracy: 0.6752 - val_loss: 0.8092 - val_accuracy: 0.6382\n",
            "Epoch 1552/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7309 - accuracy: 0.6794 - val_loss: 0.8198 - val_accuracy: 0.6348\n",
            "Epoch 1553/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7296 - accuracy: 0.6811 - val_loss: 0.8268 - val_accuracy: 0.6337\n",
            "Epoch 1554/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7304 - accuracy: 0.6817 - val_loss: 0.8140 - val_accuracy: 0.6404\n",
            "Epoch 1555/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7286 - accuracy: 0.6783 - val_loss: 0.8151 - val_accuracy: 0.6348\n",
            "Epoch 1556/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7334 - accuracy: 0.6800 - val_loss: 0.8178 - val_accuracy: 0.6326\n",
            "Epoch 1557/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7295 - accuracy: 0.6817 - val_loss: 0.8096 - val_accuracy: 0.6270\n",
            "Epoch 1558/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7293 - accuracy: 0.6791 - val_loss: 0.8233 - val_accuracy: 0.6326\n",
            "Epoch 1559/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7277 - accuracy: 0.6834 - val_loss: 0.8249 - val_accuracy: 0.6326\n",
            "Epoch 1560/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7258 - accuracy: 0.6828 - val_loss: 0.8114 - val_accuracy: 0.6371\n",
            "Epoch 1561/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7322 - accuracy: 0.6803 - val_loss: 0.8163 - val_accuracy: 0.6348\n",
            "Epoch 1562/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7325 - accuracy: 0.6769 - val_loss: 0.8256 - val_accuracy: 0.6371\n",
            "Epoch 1563/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7309 - accuracy: 0.6746 - val_loss: 0.8329 - val_accuracy: 0.6326\n",
            "Epoch 1564/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7311 - accuracy: 0.6755 - val_loss: 0.8188 - val_accuracy: 0.6326\n",
            "Epoch 1565/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7271 - accuracy: 0.6870 - val_loss: 0.8183 - val_accuracy: 0.6337\n",
            "Epoch 1566/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7276 - accuracy: 0.6819 - val_loss: 0.8220 - val_accuracy: 0.6315\n",
            "Epoch 1567/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7301 - accuracy: 0.6825 - val_loss: 0.8207 - val_accuracy: 0.6360\n",
            "Epoch 1568/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7296 - accuracy: 0.6819 - val_loss: 0.8180 - val_accuracy: 0.6292\n",
            "Epoch 1569/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7293 - accuracy: 0.6791 - val_loss: 0.8118 - val_accuracy: 0.6315\n",
            "Epoch 1570/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7322 - accuracy: 0.6769 - val_loss: 0.8237 - val_accuracy: 0.6393\n",
            "Epoch 1571/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7340 - accuracy: 0.6772 - val_loss: 0.8167 - val_accuracy: 0.6315\n",
            "Epoch 1572/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7271 - accuracy: 0.6870 - val_loss: 0.8148 - val_accuracy: 0.6404\n",
            "Epoch 1573/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7267 - accuracy: 0.6842 - val_loss: 0.8186 - val_accuracy: 0.6326\n",
            "Epoch 1574/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7312 - accuracy: 0.6791 - val_loss: 0.8191 - val_accuracy: 0.6348\n",
            "Epoch 1575/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7288 - accuracy: 0.6831 - val_loss: 0.8200 - val_accuracy: 0.6326\n",
            "Epoch 1576/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7279 - accuracy: 0.6867 - val_loss: 0.8183 - val_accuracy: 0.6315\n",
            "Epoch 1577/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7287 - accuracy: 0.6789 - val_loss: 0.8140 - val_accuracy: 0.6404\n",
            "Epoch 1578/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7286 - accuracy: 0.6856 - val_loss: 0.8120 - val_accuracy: 0.6449\n",
            "Epoch 1579/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7314 - accuracy: 0.6769 - val_loss: 0.8144 - val_accuracy: 0.6393\n",
            "Epoch 1580/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7319 - accuracy: 0.6786 - val_loss: 0.8160 - val_accuracy: 0.6326\n",
            "Epoch 1581/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7294 - accuracy: 0.6805 - val_loss: 0.8126 - val_accuracy: 0.6303\n",
            "Epoch 1582/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7324 - accuracy: 0.6845 - val_loss: 0.8248 - val_accuracy: 0.6281\n",
            "Epoch 1583/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7284 - accuracy: 0.6817 - val_loss: 0.8189 - val_accuracy: 0.6337\n",
            "Epoch 1584/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7294 - accuracy: 0.6814 - val_loss: 0.8195 - val_accuracy: 0.6348\n",
            "Epoch 1585/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7295 - accuracy: 0.6805 - val_loss: 0.8172 - val_accuracy: 0.6382\n",
            "Epoch 1586/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7279 - accuracy: 0.6811 - val_loss: 0.8291 - val_accuracy: 0.6258\n",
            "Epoch 1587/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7304 - accuracy: 0.6777 - val_loss: 0.8145 - val_accuracy: 0.6315\n",
            "Epoch 1588/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7275 - accuracy: 0.6842 - val_loss: 0.8170 - val_accuracy: 0.6348\n",
            "Epoch 1589/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7307 - accuracy: 0.6808 - val_loss: 0.8230 - val_accuracy: 0.6303\n",
            "Epoch 1590/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7304 - accuracy: 0.6797 - val_loss: 0.8223 - val_accuracy: 0.6348\n",
            "Epoch 1591/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7276 - accuracy: 0.6839 - val_loss: 0.8105 - val_accuracy: 0.6337\n",
            "Epoch 1592/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7246 - accuracy: 0.6825 - val_loss: 0.8188 - val_accuracy: 0.6360\n",
            "Epoch 1593/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7255 - accuracy: 0.6839 - val_loss: 0.8449 - val_accuracy: 0.6258\n",
            "Epoch 1594/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7327 - accuracy: 0.6842 - val_loss: 0.8158 - val_accuracy: 0.6326\n",
            "Epoch 1595/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7271 - accuracy: 0.6822 - val_loss: 0.8201 - val_accuracy: 0.6315\n",
            "Epoch 1596/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7299 - accuracy: 0.6774 - val_loss: 0.8211 - val_accuracy: 0.6303\n",
            "Epoch 1597/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7256 - accuracy: 0.6834 - val_loss: 0.8139 - val_accuracy: 0.6303\n",
            "Epoch 1598/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7263 - accuracy: 0.6870 - val_loss: 0.8144 - val_accuracy: 0.6315\n",
            "Epoch 1599/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7259 - accuracy: 0.6842 - val_loss: 0.8092 - val_accuracy: 0.6337\n",
            "Epoch 1600/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7254 - accuracy: 0.6834 - val_loss: 0.8091 - val_accuracy: 0.6449\n",
            "Epoch 1601/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7274 - accuracy: 0.6845 - val_loss: 0.8197 - val_accuracy: 0.6303\n",
            "Epoch 1602/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7273 - accuracy: 0.6834 - val_loss: 0.8117 - val_accuracy: 0.6348\n",
            "Epoch 1603/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7264 - accuracy: 0.6828 - val_loss: 0.8313 - val_accuracy: 0.6213\n",
            "Epoch 1604/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7329 - accuracy: 0.6777 - val_loss: 0.8208 - val_accuracy: 0.6483\n",
            "Epoch 1605/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7283 - accuracy: 0.6783 - val_loss: 0.8235 - val_accuracy: 0.6281\n",
            "Epoch 1606/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7296 - accuracy: 0.6777 - val_loss: 0.8218 - val_accuracy: 0.6337\n",
            "Epoch 1607/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7265 - accuracy: 0.6870 - val_loss: 0.8156 - val_accuracy: 0.6360\n",
            "Epoch 1608/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7256 - accuracy: 0.6862 - val_loss: 0.8201 - val_accuracy: 0.6281\n",
            "Epoch 1609/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7275 - accuracy: 0.6834 - val_loss: 0.8143 - val_accuracy: 0.6337\n",
            "Epoch 1610/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7371 - accuracy: 0.6783 - val_loss: 0.8196 - val_accuracy: 0.6326\n",
            "Epoch 1611/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7291 - accuracy: 0.6828 - val_loss: 0.8189 - val_accuracy: 0.6348\n",
            "Epoch 1612/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7240 - accuracy: 0.6848 - val_loss: 0.8148 - val_accuracy: 0.6258\n",
            "Epoch 1613/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7304 - accuracy: 0.6794 - val_loss: 0.8128 - val_accuracy: 0.6416\n",
            "Epoch 1614/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7268 - accuracy: 0.6842 - val_loss: 0.8172 - val_accuracy: 0.6281\n",
            "Epoch 1615/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7304 - accuracy: 0.6828 - val_loss: 0.8114 - val_accuracy: 0.6337\n",
            "Epoch 1616/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7315 - accuracy: 0.6789 - val_loss: 0.8099 - val_accuracy: 0.6281\n",
            "Epoch 1617/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7249 - accuracy: 0.6819 - val_loss: 0.8121 - val_accuracy: 0.6337\n",
            "Epoch 1618/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7258 - accuracy: 0.6834 - val_loss: 0.8212 - val_accuracy: 0.6258\n",
            "Epoch 1619/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7280 - accuracy: 0.6777 - val_loss: 0.8104 - val_accuracy: 0.6348\n",
            "Epoch 1620/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7294 - accuracy: 0.6819 - val_loss: 0.8109 - val_accuracy: 0.6348\n",
            "Epoch 1621/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7251 - accuracy: 0.6825 - val_loss: 0.8144 - val_accuracy: 0.6337\n",
            "Epoch 1622/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7263 - accuracy: 0.6842 - val_loss: 0.8228 - val_accuracy: 0.6337\n",
            "Epoch 1623/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7242 - accuracy: 0.6867 - val_loss: 0.8138 - val_accuracy: 0.6303\n",
            "Epoch 1624/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7279 - accuracy: 0.6867 - val_loss: 0.8177 - val_accuracy: 0.6281\n",
            "Epoch 1625/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7225 - accuracy: 0.6898 - val_loss: 0.8202 - val_accuracy: 0.6303\n",
            "Epoch 1626/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7231 - accuracy: 0.6848 - val_loss: 0.8144 - val_accuracy: 0.6292\n",
            "Epoch 1627/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7265 - accuracy: 0.6828 - val_loss: 0.8154 - val_accuracy: 0.6337\n",
            "Epoch 1628/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7250 - accuracy: 0.6867 - val_loss: 0.8158 - val_accuracy: 0.6326\n",
            "Epoch 1629/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7263 - accuracy: 0.6853 - val_loss: 0.8134 - val_accuracy: 0.6348\n",
            "Epoch 1630/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7268 - accuracy: 0.6834 - val_loss: 0.8247 - val_accuracy: 0.6337\n",
            "Epoch 1631/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7255 - accuracy: 0.6842 - val_loss: 0.8130 - val_accuracy: 0.6348\n",
            "Epoch 1632/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7244 - accuracy: 0.6842 - val_loss: 0.8158 - val_accuracy: 0.6348\n",
            "Epoch 1633/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7263 - accuracy: 0.6817 - val_loss: 0.8150 - val_accuracy: 0.6315\n",
            "Epoch 1634/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7289 - accuracy: 0.6825 - val_loss: 0.8330 - val_accuracy: 0.6292\n",
            "Epoch 1635/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7279 - accuracy: 0.6873 - val_loss: 0.8193 - val_accuracy: 0.6348\n",
            "Epoch 1636/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7280 - accuracy: 0.6839 - val_loss: 0.8109 - val_accuracy: 0.6315\n",
            "Epoch 1637/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7251 - accuracy: 0.6848 - val_loss: 0.8254 - val_accuracy: 0.6236\n",
            "Epoch 1638/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7260 - accuracy: 0.6808 - val_loss: 0.8108 - val_accuracy: 0.6337\n",
            "Epoch 1639/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7259 - accuracy: 0.6881 - val_loss: 0.8391 - val_accuracy: 0.6303\n",
            "Epoch 1640/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7270 - accuracy: 0.6772 - val_loss: 0.8097 - val_accuracy: 0.6371\n",
            "Epoch 1641/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7306 - accuracy: 0.6825 - val_loss: 0.8225 - val_accuracy: 0.6348\n",
            "Epoch 1642/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7248 - accuracy: 0.6864 - val_loss: 0.8218 - val_accuracy: 0.6393\n",
            "Epoch 1643/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7264 - accuracy: 0.6862 - val_loss: 0.8416 - val_accuracy: 0.6360\n",
            "Epoch 1644/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7272 - accuracy: 0.6859 - val_loss: 0.8110 - val_accuracy: 0.6315\n",
            "Epoch 1645/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7244 - accuracy: 0.6890 - val_loss: 0.8147 - val_accuracy: 0.6315\n",
            "Epoch 1646/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7245 - accuracy: 0.6859 - val_loss: 0.8118 - val_accuracy: 0.6315\n",
            "Epoch 1647/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7235 - accuracy: 0.6893 - val_loss: 0.8252 - val_accuracy: 0.6315\n",
            "Epoch 1648/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7251 - accuracy: 0.6839 - val_loss: 0.8290 - val_accuracy: 0.6348\n",
            "Epoch 1649/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7267 - accuracy: 0.6805 - val_loss: 0.8218 - val_accuracy: 0.6337\n",
            "Epoch 1650/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7264 - accuracy: 0.6797 - val_loss: 0.8077 - val_accuracy: 0.6348\n",
            "Epoch 1651/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7237 - accuracy: 0.6822 - val_loss: 0.8389 - val_accuracy: 0.6292\n",
            "Epoch 1652/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7229 - accuracy: 0.6800 - val_loss: 0.8124 - val_accuracy: 0.6416\n",
            "Epoch 1653/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7267 - accuracy: 0.6797 - val_loss: 0.8208 - val_accuracy: 0.6292\n",
            "Epoch 1654/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7238 - accuracy: 0.6828 - val_loss: 0.8158 - val_accuracy: 0.6393\n",
            "Epoch 1655/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7269 - accuracy: 0.6856 - val_loss: 0.8331 - val_accuracy: 0.6348\n",
            "Epoch 1656/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7255 - accuracy: 0.6814 - val_loss: 0.8225 - val_accuracy: 0.6315\n",
            "Epoch 1657/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7260 - accuracy: 0.6791 - val_loss: 0.8178 - val_accuracy: 0.6326\n",
            "Epoch 1658/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7258 - accuracy: 0.6791 - val_loss: 0.8132 - val_accuracy: 0.6416\n",
            "Epoch 1659/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7270 - accuracy: 0.6864 - val_loss: 0.8100 - val_accuracy: 0.6382\n",
            "Epoch 1660/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7244 - accuracy: 0.6834 - val_loss: 0.8136 - val_accuracy: 0.6371\n",
            "Epoch 1661/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7269 - accuracy: 0.6794 - val_loss: 0.8230 - val_accuracy: 0.6337\n",
            "Epoch 1662/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7244 - accuracy: 0.6873 - val_loss: 0.8165 - val_accuracy: 0.6337\n",
            "Epoch 1663/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7240 - accuracy: 0.6791 - val_loss: 0.8266 - val_accuracy: 0.6348\n",
            "Epoch 1664/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7244 - accuracy: 0.6881 - val_loss: 0.8112 - val_accuracy: 0.6371\n",
            "Epoch 1665/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7266 - accuracy: 0.6859 - val_loss: 0.8177 - val_accuracy: 0.6315\n",
            "Epoch 1666/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7245 - accuracy: 0.6884 - val_loss: 0.8203 - val_accuracy: 0.6292\n",
            "Epoch 1667/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7263 - accuracy: 0.6856 - val_loss: 0.8105 - val_accuracy: 0.6360\n",
            "Epoch 1668/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7235 - accuracy: 0.6859 - val_loss: 0.8075 - val_accuracy: 0.6337\n",
            "Epoch 1669/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7264 - accuracy: 0.6805 - val_loss: 0.8084 - val_accuracy: 0.6382\n",
            "Epoch 1670/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7207 - accuracy: 0.6901 - val_loss: 0.8132 - val_accuracy: 0.6360\n",
            "Epoch 1671/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7239 - accuracy: 0.6859 - val_loss: 0.8147 - val_accuracy: 0.6337\n",
            "Epoch 1672/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7236 - accuracy: 0.6800 - val_loss: 0.8119 - val_accuracy: 0.6337\n",
            "Epoch 1673/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7284 - accuracy: 0.6884 - val_loss: 0.8086 - val_accuracy: 0.6404\n",
            "Epoch 1674/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7258 - accuracy: 0.6853 - val_loss: 0.8158 - val_accuracy: 0.6382\n",
            "Epoch 1675/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7231 - accuracy: 0.6893 - val_loss: 0.8122 - val_accuracy: 0.6315\n",
            "Epoch 1676/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7232 - accuracy: 0.6859 - val_loss: 0.8097 - val_accuracy: 0.6326\n",
            "Epoch 1677/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7246 - accuracy: 0.6842 - val_loss: 0.8121 - val_accuracy: 0.6337\n",
            "Epoch 1678/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7228 - accuracy: 0.6845 - val_loss: 0.8077 - val_accuracy: 0.6393\n",
            "Epoch 1679/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7197 - accuracy: 0.6887 - val_loss: 0.8182 - val_accuracy: 0.6292\n",
            "Epoch 1680/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7251 - accuracy: 0.6859 - val_loss: 0.8181 - val_accuracy: 0.6281\n",
            "Epoch 1681/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7223 - accuracy: 0.6918 - val_loss: 0.8117 - val_accuracy: 0.6360\n",
            "Epoch 1682/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7239 - accuracy: 0.6864 - val_loss: 0.8214 - val_accuracy: 0.6416\n",
            "Epoch 1683/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7225 - accuracy: 0.6870 - val_loss: 0.8164 - val_accuracy: 0.6348\n",
            "Epoch 1684/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7222 - accuracy: 0.6879 - val_loss: 0.8141 - val_accuracy: 0.6337\n",
            "Epoch 1685/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7219 - accuracy: 0.6856 - val_loss: 0.8286 - val_accuracy: 0.6225\n",
            "Epoch 1686/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7239 - accuracy: 0.6836 - val_loss: 0.8206 - val_accuracy: 0.6427\n",
            "Epoch 1687/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7250 - accuracy: 0.6800 - val_loss: 0.8210 - val_accuracy: 0.6270\n",
            "Epoch 1688/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7251 - accuracy: 0.6848 - val_loss: 0.8190 - val_accuracy: 0.6281\n",
            "Epoch 1689/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7275 - accuracy: 0.6895 - val_loss: 0.8148 - val_accuracy: 0.6393\n",
            "Epoch 1690/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7275 - accuracy: 0.6845 - val_loss: 0.8101 - val_accuracy: 0.6326\n",
            "Epoch 1691/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7231 - accuracy: 0.6864 - val_loss: 0.8123 - val_accuracy: 0.6438\n",
            "Epoch 1692/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7219 - accuracy: 0.6834 - val_loss: 0.8107 - val_accuracy: 0.6247\n",
            "Epoch 1693/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7229 - accuracy: 0.6881 - val_loss: 0.8177 - val_accuracy: 0.6303\n",
            "Epoch 1694/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7233 - accuracy: 0.6831 - val_loss: 0.8140 - val_accuracy: 0.6438\n",
            "Epoch 1695/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7269 - accuracy: 0.6864 - val_loss: 0.8115 - val_accuracy: 0.6326\n",
            "Epoch 1696/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7194 - accuracy: 0.6831 - val_loss: 0.8373 - val_accuracy: 0.6337\n",
            "Epoch 1697/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7236 - accuracy: 0.6876 - val_loss: 0.8254 - val_accuracy: 0.6315\n",
            "Epoch 1698/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7241 - accuracy: 0.6901 - val_loss: 0.8703 - val_accuracy: 0.6202\n",
            "Epoch 1699/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7247 - accuracy: 0.6791 - val_loss: 0.8269 - val_accuracy: 0.6281\n",
            "Epoch 1700/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7234 - accuracy: 0.6845 - val_loss: 0.8144 - val_accuracy: 0.6360\n",
            "Epoch 1701/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7269 - accuracy: 0.6836 - val_loss: 0.8152 - val_accuracy: 0.6337\n",
            "Epoch 1702/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7221 - accuracy: 0.6822 - val_loss: 0.8066 - val_accuracy: 0.6326\n",
            "Epoch 1703/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7211 - accuracy: 0.6848 - val_loss: 0.8176 - val_accuracy: 0.6281\n",
            "Epoch 1704/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7236 - accuracy: 0.6808 - val_loss: 0.8277 - val_accuracy: 0.6326\n",
            "Epoch 1705/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7206 - accuracy: 0.6901 - val_loss: 0.8188 - val_accuracy: 0.6281\n",
            "Epoch 1706/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7218 - accuracy: 0.6864 - val_loss: 0.8111 - val_accuracy: 0.6393\n",
            "Epoch 1707/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7209 - accuracy: 0.6890 - val_loss: 0.8079 - val_accuracy: 0.6348\n",
            "Epoch 1708/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7251 - accuracy: 0.6811 - val_loss: 0.8198 - val_accuracy: 0.6348\n",
            "Epoch 1709/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7229 - accuracy: 0.6848 - val_loss: 0.8212 - val_accuracy: 0.6348\n",
            "Epoch 1710/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7204 - accuracy: 0.6856 - val_loss: 0.8193 - val_accuracy: 0.6337\n",
            "Epoch 1711/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7230 - accuracy: 0.6828 - val_loss: 0.8216 - val_accuracy: 0.6326\n",
            "Epoch 1712/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7211 - accuracy: 0.6918 - val_loss: 0.8268 - val_accuracy: 0.6315\n",
            "Epoch 1713/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7216 - accuracy: 0.6864 - val_loss: 0.8053 - val_accuracy: 0.6427\n",
            "Epoch 1714/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7259 - accuracy: 0.6834 - val_loss: 0.8150 - val_accuracy: 0.6382\n",
            "Epoch 1715/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7234 - accuracy: 0.6876 - val_loss: 0.8073 - val_accuracy: 0.6348\n",
            "Epoch 1716/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7248 - accuracy: 0.6876 - val_loss: 0.8316 - val_accuracy: 0.6303\n",
            "Epoch 1717/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7219 - accuracy: 0.6834 - val_loss: 0.8428 - val_accuracy: 0.6337\n",
            "Epoch 1718/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7242 - accuracy: 0.6845 - val_loss: 0.8140 - val_accuracy: 0.6337\n",
            "Epoch 1719/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7194 - accuracy: 0.6924 - val_loss: 0.8117 - val_accuracy: 0.6404\n",
            "Epoch 1720/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7199 - accuracy: 0.6912 - val_loss: 0.8132 - val_accuracy: 0.6416\n",
            "Epoch 1721/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7234 - accuracy: 0.6856 - val_loss: 0.8446 - val_accuracy: 0.6360\n",
            "Epoch 1722/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7231 - accuracy: 0.6845 - val_loss: 0.8112 - val_accuracy: 0.6371\n",
            "Epoch 1723/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7220 - accuracy: 0.6774 - val_loss: 0.8115 - val_accuracy: 0.6303\n",
            "Epoch 1724/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7196 - accuracy: 0.6895 - val_loss: 0.8107 - val_accuracy: 0.6371\n",
            "Epoch 1725/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7205 - accuracy: 0.6901 - val_loss: 0.8297 - val_accuracy: 0.6449\n",
            "Epoch 1726/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7208 - accuracy: 0.6879 - val_loss: 0.8135 - val_accuracy: 0.6382\n",
            "Epoch 1727/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7219 - accuracy: 0.6940 - val_loss: 0.8087 - val_accuracy: 0.6348\n",
            "Epoch 1728/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7204 - accuracy: 0.6828 - val_loss: 0.8175 - val_accuracy: 0.6371\n",
            "Epoch 1729/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7182 - accuracy: 0.6921 - val_loss: 0.8289 - val_accuracy: 0.6315\n",
            "Epoch 1730/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7185 - accuracy: 0.6898 - val_loss: 0.8155 - val_accuracy: 0.6326\n",
            "Epoch 1731/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7191 - accuracy: 0.6881 - val_loss: 0.8179 - val_accuracy: 0.6281\n",
            "Epoch 1732/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7222 - accuracy: 0.6876 - val_loss: 0.8112 - val_accuracy: 0.6326\n",
            "Epoch 1733/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7193 - accuracy: 0.6853 - val_loss: 0.8163 - val_accuracy: 0.6326\n",
            "Epoch 1734/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7219 - accuracy: 0.6850 - val_loss: 0.8285 - val_accuracy: 0.6360\n",
            "Epoch 1735/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7211 - accuracy: 0.6873 - val_loss: 0.8140 - val_accuracy: 0.6360\n",
            "Epoch 1736/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7196 - accuracy: 0.6879 - val_loss: 0.8140 - val_accuracy: 0.6416\n",
            "Epoch 1737/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7205 - accuracy: 0.6887 - val_loss: 0.8166 - val_accuracy: 0.6326\n",
            "Epoch 1738/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7193 - accuracy: 0.6856 - val_loss: 0.8126 - val_accuracy: 0.6382\n",
            "Epoch 1739/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7202 - accuracy: 0.6836 - val_loss: 0.8345 - val_accuracy: 0.6270\n",
            "Epoch 1740/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7215 - accuracy: 0.6867 - val_loss: 0.8134 - val_accuracy: 0.6360\n",
            "Epoch 1741/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7186 - accuracy: 0.6831 - val_loss: 0.8140 - val_accuracy: 0.6326\n",
            "Epoch 1742/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7245 - accuracy: 0.6808 - val_loss: 0.8100 - val_accuracy: 0.6348\n",
            "Epoch 1743/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7194 - accuracy: 0.6935 - val_loss: 0.8187 - val_accuracy: 0.6382\n",
            "Epoch 1744/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7212 - accuracy: 0.6814 - val_loss: 0.8129 - val_accuracy: 0.6315\n",
            "Epoch 1745/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7200 - accuracy: 0.6864 - val_loss: 0.8160 - val_accuracy: 0.6371\n",
            "Epoch 1746/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7173 - accuracy: 0.6873 - val_loss: 0.8139 - val_accuracy: 0.6337\n",
            "Epoch 1747/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7181 - accuracy: 0.6864 - val_loss: 0.8130 - val_accuracy: 0.6360\n",
            "Epoch 1748/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7235 - accuracy: 0.6881 - val_loss: 0.8125 - val_accuracy: 0.6326\n",
            "Epoch 1749/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7182 - accuracy: 0.6876 - val_loss: 0.8202 - val_accuracy: 0.6303\n",
            "Epoch 1750/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7202 - accuracy: 0.6907 - val_loss: 0.8169 - val_accuracy: 0.6337\n",
            "Epoch 1751/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7318 - accuracy: 0.6780 - val_loss: 0.8107 - val_accuracy: 0.6281\n",
            "Epoch 1752/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7214 - accuracy: 0.6825 - val_loss: 0.8088 - val_accuracy: 0.6360\n",
            "Epoch 1753/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7176 - accuracy: 0.6909 - val_loss: 0.8104 - val_accuracy: 0.6360\n",
            "Epoch 1754/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7186 - accuracy: 0.6881 - val_loss: 0.8133 - val_accuracy: 0.6348\n",
            "Epoch 1755/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7165 - accuracy: 0.6915 - val_loss: 0.8231 - val_accuracy: 0.6270\n",
            "Epoch 1756/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7183 - accuracy: 0.6831 - val_loss: 0.8128 - val_accuracy: 0.6393\n",
            "Epoch 1757/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7246 - accuracy: 0.6825 - val_loss: 0.8134 - val_accuracy: 0.6281\n",
            "Epoch 1758/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7180 - accuracy: 0.6924 - val_loss: 0.8205 - val_accuracy: 0.6315\n",
            "Epoch 1759/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7218 - accuracy: 0.6870 - val_loss: 0.8291 - val_accuracy: 0.6337\n",
            "Epoch 1760/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7202 - accuracy: 0.6848 - val_loss: 0.8208 - val_accuracy: 0.6337\n",
            "Epoch 1761/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7225 - accuracy: 0.6901 - val_loss: 0.8257 - val_accuracy: 0.6427\n",
            "Epoch 1762/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7264 - accuracy: 0.6859 - val_loss: 0.8135 - val_accuracy: 0.6292\n",
            "Epoch 1763/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7168 - accuracy: 0.6890 - val_loss: 0.8396 - val_accuracy: 0.6326\n",
            "Epoch 1764/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7232 - accuracy: 0.6873 - val_loss: 0.8169 - val_accuracy: 0.6303\n",
            "Epoch 1765/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7186 - accuracy: 0.6859 - val_loss: 0.8172 - val_accuracy: 0.6292\n",
            "Epoch 1766/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7214 - accuracy: 0.6836 - val_loss: 0.8272 - val_accuracy: 0.6315\n",
            "Epoch 1767/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7185 - accuracy: 0.6893 - val_loss: 0.8182 - val_accuracy: 0.6326\n",
            "Epoch 1768/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7174 - accuracy: 0.6867 - val_loss: 0.8155 - val_accuracy: 0.6348\n",
            "Epoch 1769/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7205 - accuracy: 0.6862 - val_loss: 0.8106 - val_accuracy: 0.6393\n",
            "Epoch 1770/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7189 - accuracy: 0.6881 - val_loss: 0.8241 - val_accuracy: 0.6292\n",
            "Epoch 1771/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7183 - accuracy: 0.6864 - val_loss: 0.8167 - val_accuracy: 0.6371\n",
            "Epoch 1772/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7170 - accuracy: 0.6909 - val_loss: 0.8302 - val_accuracy: 0.6337\n",
            "Epoch 1773/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7197 - accuracy: 0.6893 - val_loss: 0.8170 - val_accuracy: 0.6404\n",
            "Epoch 1774/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7202 - accuracy: 0.6859 - val_loss: 0.8188 - val_accuracy: 0.6449\n",
            "Epoch 1775/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7249 - accuracy: 0.6836 - val_loss: 0.8248 - val_accuracy: 0.6292\n",
            "Epoch 1776/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7198 - accuracy: 0.6862 - val_loss: 0.8077 - val_accuracy: 0.6416\n",
            "Epoch 1777/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7234 - accuracy: 0.6836 - val_loss: 0.8261 - val_accuracy: 0.6303\n",
            "Epoch 1778/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7246 - accuracy: 0.6839 - val_loss: 0.8230 - val_accuracy: 0.6360\n",
            "Epoch 1779/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7206 - accuracy: 0.6887 - val_loss: 0.8334 - val_accuracy: 0.6337\n",
            "Epoch 1780/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7212 - accuracy: 0.6845 - val_loss: 0.8135 - val_accuracy: 0.6337\n",
            "Epoch 1781/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7169 - accuracy: 0.6893 - val_loss: 0.8331 - val_accuracy: 0.6270\n",
            "Epoch 1782/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7188 - accuracy: 0.6898 - val_loss: 0.8170 - val_accuracy: 0.6337\n",
            "Epoch 1783/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7161 - accuracy: 0.6887 - val_loss: 0.8111 - val_accuracy: 0.6360\n",
            "Epoch 1784/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7209 - accuracy: 0.6895 - val_loss: 0.8152 - val_accuracy: 0.6371\n",
            "Epoch 1785/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7188 - accuracy: 0.6915 - val_loss: 0.8210 - val_accuracy: 0.6326\n",
            "Epoch 1786/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7180 - accuracy: 0.6949 - val_loss: 0.8370 - val_accuracy: 0.6315\n",
            "Epoch 1787/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7228 - accuracy: 0.6853 - val_loss: 0.8125 - val_accuracy: 0.6404\n",
            "Epoch 1788/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7191 - accuracy: 0.6850 - val_loss: 0.8233 - val_accuracy: 0.6371\n",
            "Epoch 1789/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7182 - accuracy: 0.6845 - val_loss: 0.8330 - val_accuracy: 0.6393\n",
            "Epoch 1790/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7162 - accuracy: 0.6842 - val_loss: 0.8165 - val_accuracy: 0.6303\n",
            "Epoch 1791/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7174 - accuracy: 0.6895 - val_loss: 0.8097 - val_accuracy: 0.6360\n",
            "Epoch 1792/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7174 - accuracy: 0.6884 - val_loss: 0.8136 - val_accuracy: 0.6281\n",
            "Epoch 1793/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7184 - accuracy: 0.6867 - val_loss: 0.8117 - val_accuracy: 0.6326\n",
            "Epoch 1794/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7156 - accuracy: 0.6848 - val_loss: 0.8194 - val_accuracy: 0.6337\n",
            "Epoch 1795/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7191 - accuracy: 0.6870 - val_loss: 0.8191 - val_accuracy: 0.6371\n",
            "Epoch 1796/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7170 - accuracy: 0.6890 - val_loss: 0.8138 - val_accuracy: 0.6360\n",
            "Epoch 1797/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7175 - accuracy: 0.6895 - val_loss: 0.8283 - val_accuracy: 0.6360\n",
            "Epoch 1798/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7173 - accuracy: 0.6862 - val_loss: 0.8379 - val_accuracy: 0.6393\n",
            "Epoch 1799/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7199 - accuracy: 0.6836 - val_loss: 0.8131 - val_accuracy: 0.6292\n",
            "Epoch 1800/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7186 - accuracy: 0.6862 - val_loss: 0.8132 - val_accuracy: 0.6258\n",
            "Epoch 1801/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7164 - accuracy: 0.6921 - val_loss: 0.8367 - val_accuracy: 0.6360\n",
            "Epoch 1802/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7223 - accuracy: 0.6864 - val_loss: 0.8162 - val_accuracy: 0.6404\n",
            "Epoch 1803/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7172 - accuracy: 0.6884 - val_loss: 0.8161 - val_accuracy: 0.6225\n",
            "Epoch 1804/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7129 - accuracy: 0.6912 - val_loss: 0.8136 - val_accuracy: 0.6247\n",
            "Epoch 1805/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7190 - accuracy: 0.6887 - val_loss: 0.8152 - val_accuracy: 0.6348\n",
            "Epoch 1806/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7224 - accuracy: 0.6870 - val_loss: 0.8134 - val_accuracy: 0.6337\n",
            "Epoch 1807/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7161 - accuracy: 0.6862 - val_loss: 0.8138 - val_accuracy: 0.6303\n",
            "Epoch 1808/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7215 - accuracy: 0.6862 - val_loss: 0.8109 - val_accuracy: 0.6382\n",
            "Epoch 1809/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7196 - accuracy: 0.6850 - val_loss: 0.8173 - val_accuracy: 0.6382\n",
            "Epoch 1810/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7209 - accuracy: 0.6836 - val_loss: 0.8093 - val_accuracy: 0.6438\n",
            "Epoch 1811/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7216 - accuracy: 0.6848 - val_loss: 0.8119 - val_accuracy: 0.6326\n",
            "Epoch 1812/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7175 - accuracy: 0.6926 - val_loss: 0.8140 - val_accuracy: 0.6303\n",
            "Epoch 1813/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7148 - accuracy: 0.6932 - val_loss: 0.8208 - val_accuracy: 0.6258\n",
            "Epoch 1814/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7141 - accuracy: 0.6915 - val_loss: 0.8134 - val_accuracy: 0.6326\n",
            "Epoch 1815/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7176 - accuracy: 0.6822 - val_loss: 0.8114 - val_accuracy: 0.6348\n",
            "Epoch 1816/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7156 - accuracy: 0.6876 - val_loss: 0.8293 - val_accuracy: 0.6258\n",
            "Epoch 1817/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7162 - accuracy: 0.6924 - val_loss: 0.8156 - val_accuracy: 0.6326\n",
            "Epoch 1818/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7138 - accuracy: 0.6895 - val_loss: 0.8170 - val_accuracy: 0.6438\n",
            "Epoch 1819/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7186 - accuracy: 0.6836 - val_loss: 0.8287 - val_accuracy: 0.6247\n",
            "Epoch 1820/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7215 - accuracy: 0.6904 - val_loss: 0.8142 - val_accuracy: 0.6393\n",
            "Epoch 1821/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7156 - accuracy: 0.6834 - val_loss: 0.8120 - val_accuracy: 0.6360\n",
            "Epoch 1822/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7150 - accuracy: 0.6971 - val_loss: 0.8238 - val_accuracy: 0.6270\n",
            "Epoch 1823/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7159 - accuracy: 0.6848 - val_loss: 0.8211 - val_accuracy: 0.6281\n",
            "Epoch 1824/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7159 - accuracy: 0.6879 - val_loss: 0.8202 - val_accuracy: 0.6281\n",
            "Epoch 1825/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7184 - accuracy: 0.6870 - val_loss: 0.8219 - val_accuracy: 0.6404\n",
            "Epoch 1826/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7218 - accuracy: 0.6831 - val_loss: 0.8187 - val_accuracy: 0.6371\n",
            "Epoch 1827/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7171 - accuracy: 0.6870 - val_loss: 0.8112 - val_accuracy: 0.6337\n",
            "Epoch 1828/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7158 - accuracy: 0.6901 - val_loss: 0.8216 - val_accuracy: 0.6326\n",
            "Epoch 1829/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7198 - accuracy: 0.6879 - val_loss: 0.8117 - val_accuracy: 0.6303\n",
            "Epoch 1830/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7136 - accuracy: 0.6907 - val_loss: 0.8233 - val_accuracy: 0.6292\n",
            "Epoch 1831/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7140 - accuracy: 0.6904 - val_loss: 0.8185 - val_accuracy: 0.6292\n",
            "Epoch 1832/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7151 - accuracy: 0.6957 - val_loss: 0.8240 - val_accuracy: 0.6303\n",
            "Epoch 1833/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7145 - accuracy: 0.6887 - val_loss: 0.8169 - val_accuracy: 0.6326\n",
            "Epoch 1834/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7135 - accuracy: 0.6946 - val_loss: 0.8118 - val_accuracy: 0.6360\n",
            "Epoch 1835/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7148 - accuracy: 0.6909 - val_loss: 0.8113 - val_accuracy: 0.6371\n",
            "Epoch 1836/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7176 - accuracy: 0.6884 - val_loss: 0.8132 - val_accuracy: 0.6348\n",
            "Epoch 1837/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7155 - accuracy: 0.6904 - val_loss: 0.8165 - val_accuracy: 0.6258\n",
            "Epoch 1838/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7174 - accuracy: 0.6856 - val_loss: 0.8119 - val_accuracy: 0.6337\n",
            "Epoch 1839/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7140 - accuracy: 0.6898 - val_loss: 0.8199 - val_accuracy: 0.6315\n",
            "Epoch 1840/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7174 - accuracy: 0.6890 - val_loss: 0.8218 - val_accuracy: 0.6360\n",
            "Epoch 1841/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7165 - accuracy: 0.6834 - val_loss: 0.8147 - val_accuracy: 0.6348\n",
            "Epoch 1842/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7154 - accuracy: 0.6924 - val_loss: 0.8214 - val_accuracy: 0.6393\n",
            "Epoch 1843/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7135 - accuracy: 0.6859 - val_loss: 0.8208 - val_accuracy: 0.6337\n",
            "Epoch 1844/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7199 - accuracy: 0.6909 - val_loss: 0.8215 - val_accuracy: 0.6337\n",
            "Epoch 1845/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7178 - accuracy: 0.6904 - val_loss: 0.8113 - val_accuracy: 0.6315\n",
            "Epoch 1846/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7172 - accuracy: 0.6881 - val_loss: 0.8155 - val_accuracy: 0.6393\n",
            "Epoch 1847/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7192 - accuracy: 0.6881 - val_loss: 0.8466 - val_accuracy: 0.6315\n",
            "Epoch 1848/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7119 - accuracy: 0.6895 - val_loss: 0.8220 - val_accuracy: 0.6348\n",
            "Epoch 1849/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7149 - accuracy: 0.6893 - val_loss: 0.8208 - val_accuracy: 0.6371\n",
            "Epoch 1850/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7219 - accuracy: 0.6848 - val_loss: 0.8166 - val_accuracy: 0.6281\n",
            "Epoch 1851/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7203 - accuracy: 0.6859 - val_loss: 0.8274 - val_accuracy: 0.6393\n",
            "Epoch 1852/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7138 - accuracy: 0.6887 - val_loss: 0.8222 - val_accuracy: 0.6348\n",
            "Epoch 1853/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7155 - accuracy: 0.6901 - val_loss: 0.8180 - val_accuracy: 0.6360\n",
            "Epoch 1854/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7127 - accuracy: 0.6929 - val_loss: 0.8176 - val_accuracy: 0.6337\n",
            "Epoch 1855/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7136 - accuracy: 0.6901 - val_loss: 0.8231 - val_accuracy: 0.6270\n",
            "Epoch 1856/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7131 - accuracy: 0.6898 - val_loss: 0.8165 - val_accuracy: 0.6326\n",
            "Epoch 1857/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7164 - accuracy: 0.6881 - val_loss: 0.8173 - val_accuracy: 0.6326\n",
            "Epoch 1858/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7136 - accuracy: 0.6912 - val_loss: 0.8178 - val_accuracy: 0.6270\n",
            "Epoch 1859/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7118 - accuracy: 0.6943 - val_loss: 0.8126 - val_accuracy: 0.6360\n",
            "Epoch 1860/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7173 - accuracy: 0.6850 - val_loss: 0.8233 - val_accuracy: 0.6393\n",
            "Epoch 1861/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7198 - accuracy: 0.6870 - val_loss: 0.8208 - val_accuracy: 0.6292\n",
            "Epoch 1862/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7149 - accuracy: 0.6848 - val_loss: 0.8293 - val_accuracy: 0.6382\n",
            "Epoch 1863/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7161 - accuracy: 0.6862 - val_loss: 0.8185 - val_accuracy: 0.6348\n",
            "Epoch 1864/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7183 - accuracy: 0.6862 - val_loss: 0.8147 - val_accuracy: 0.6427\n",
            "Epoch 1865/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7187 - accuracy: 0.6867 - val_loss: 0.8108 - val_accuracy: 0.6382\n",
            "Epoch 1866/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7179 - accuracy: 0.6876 - val_loss: 0.8220 - val_accuracy: 0.6281\n",
            "Epoch 1867/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7163 - accuracy: 0.6842 - val_loss: 0.8185 - val_accuracy: 0.6303\n",
            "Epoch 1868/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7141 - accuracy: 0.6890 - val_loss: 0.8167 - val_accuracy: 0.6337\n",
            "Epoch 1869/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7136 - accuracy: 0.6915 - val_loss: 0.8302 - val_accuracy: 0.6371\n",
            "Epoch 1870/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7154 - accuracy: 0.6814 - val_loss: 0.8160 - val_accuracy: 0.6427\n",
            "Epoch 1871/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7127 - accuracy: 0.6904 - val_loss: 0.8137 - val_accuracy: 0.6326\n",
            "Epoch 1872/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7132 - accuracy: 0.6924 - val_loss: 0.8135 - val_accuracy: 0.6258\n",
            "Epoch 1873/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7113 - accuracy: 0.6932 - val_loss: 0.8266 - val_accuracy: 0.6348\n",
            "Epoch 1874/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7138 - accuracy: 0.6884 - val_loss: 0.8200 - val_accuracy: 0.6393\n",
            "Epoch 1875/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7154 - accuracy: 0.6926 - val_loss: 0.8207 - val_accuracy: 0.6247\n",
            "Epoch 1876/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7134 - accuracy: 0.6924 - val_loss: 0.8157 - val_accuracy: 0.6315\n",
            "Epoch 1877/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7127 - accuracy: 0.6915 - val_loss: 0.8145 - val_accuracy: 0.6360\n",
            "Epoch 1878/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7139 - accuracy: 0.6876 - val_loss: 0.8191 - val_accuracy: 0.6303\n",
            "Epoch 1879/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7111 - accuracy: 0.6887 - val_loss: 0.8095 - val_accuracy: 0.6360\n",
            "Epoch 1880/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7163 - accuracy: 0.6918 - val_loss: 0.8134 - val_accuracy: 0.6393\n",
            "Epoch 1881/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7160 - accuracy: 0.6898 - val_loss: 0.8128 - val_accuracy: 0.6326\n",
            "Epoch 1882/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7125 - accuracy: 0.6909 - val_loss: 0.8346 - val_accuracy: 0.6315\n",
            "Epoch 1883/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7138 - accuracy: 0.6864 - val_loss: 0.8128 - val_accuracy: 0.6303\n",
            "Epoch 1884/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7176 - accuracy: 0.6836 - val_loss: 0.8130 - val_accuracy: 0.6315\n",
            "Epoch 1885/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7193 - accuracy: 0.6825 - val_loss: 0.8112 - val_accuracy: 0.6360\n",
            "Epoch 1886/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7229 - accuracy: 0.6856 - val_loss: 0.8461 - val_accuracy: 0.6348\n",
            "Epoch 1887/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7136 - accuracy: 0.6884 - val_loss: 0.8149 - val_accuracy: 0.6371\n",
            "Epoch 1888/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7104 - accuracy: 0.6946 - val_loss: 0.8170 - val_accuracy: 0.6315\n",
            "Epoch 1889/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7112 - accuracy: 0.6909 - val_loss: 0.8260 - val_accuracy: 0.6315\n",
            "Epoch 1890/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7135 - accuracy: 0.6876 - val_loss: 0.8187 - val_accuracy: 0.6360\n",
            "Epoch 1891/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7120 - accuracy: 0.6876 - val_loss: 0.8199 - val_accuracy: 0.6292\n",
            "Epoch 1892/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7129 - accuracy: 0.6907 - val_loss: 0.8344 - val_accuracy: 0.6337\n",
            "Epoch 1893/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7177 - accuracy: 0.6912 - val_loss: 0.8128 - val_accuracy: 0.6371\n",
            "Epoch 1894/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7135 - accuracy: 0.6881 - val_loss: 0.8180 - val_accuracy: 0.6247\n",
            "Epoch 1895/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7129 - accuracy: 0.6881 - val_loss: 0.8178 - val_accuracy: 0.6292\n",
            "Epoch 1896/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7135 - accuracy: 0.6898 - val_loss: 0.8122 - val_accuracy: 0.6393\n",
            "Epoch 1897/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7180 - accuracy: 0.6839 - val_loss: 0.8106 - val_accuracy: 0.6348\n",
            "Epoch 1898/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7139 - accuracy: 0.6940 - val_loss: 0.8485 - val_accuracy: 0.6382\n",
            "Epoch 1899/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7142 - accuracy: 0.6862 - val_loss: 0.8168 - val_accuracy: 0.6258\n",
            "Epoch 1900/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7154 - accuracy: 0.6864 - val_loss: 0.8419 - val_accuracy: 0.6326\n",
            "Epoch 1901/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7127 - accuracy: 0.6918 - val_loss: 0.8187 - val_accuracy: 0.6416\n",
            "Epoch 1902/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7141 - accuracy: 0.6867 - val_loss: 0.8149 - val_accuracy: 0.6326\n",
            "Epoch 1903/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7140 - accuracy: 0.6932 - val_loss: 0.8165 - val_accuracy: 0.6382\n",
            "Epoch 1904/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7134 - accuracy: 0.6935 - val_loss: 0.8380 - val_accuracy: 0.6326\n",
            "Epoch 1905/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7123 - accuracy: 0.6932 - val_loss: 0.8114 - val_accuracy: 0.6348\n",
            "Epoch 1906/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7108 - accuracy: 0.6907 - val_loss: 0.8162 - val_accuracy: 0.6281\n",
            "Epoch 1907/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7143 - accuracy: 0.6867 - val_loss: 0.8177 - val_accuracy: 0.6371\n",
            "Epoch 1908/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7153 - accuracy: 0.6921 - val_loss: 0.8177 - val_accuracy: 0.6281\n",
            "Epoch 1909/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7107 - accuracy: 0.6884 - val_loss: 0.8191 - val_accuracy: 0.6270\n",
            "Epoch 1910/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7110 - accuracy: 0.6895 - val_loss: 0.8228 - val_accuracy: 0.6382\n",
            "Epoch 1911/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7145 - accuracy: 0.6887 - val_loss: 0.8239 - val_accuracy: 0.6371\n",
            "Epoch 1912/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7156 - accuracy: 0.6870 - val_loss: 0.8221 - val_accuracy: 0.6281\n",
            "Epoch 1913/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7123 - accuracy: 0.6856 - val_loss: 0.8162 - val_accuracy: 0.6393\n",
            "Epoch 1914/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7166 - accuracy: 0.6859 - val_loss: 0.8315 - val_accuracy: 0.6348\n",
            "Epoch 1915/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7102 - accuracy: 0.6904 - val_loss: 0.8292 - val_accuracy: 0.6326\n",
            "Epoch 1916/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7132 - accuracy: 0.6912 - val_loss: 0.8155 - val_accuracy: 0.6326\n",
            "Epoch 1917/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7096 - accuracy: 0.6864 - val_loss: 0.8291 - val_accuracy: 0.6371\n",
            "Epoch 1918/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7145 - accuracy: 0.6867 - val_loss: 0.8183 - val_accuracy: 0.6348\n",
            "Epoch 1919/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7129 - accuracy: 0.6904 - val_loss: 0.8198 - val_accuracy: 0.6382\n",
            "Epoch 1920/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7165 - accuracy: 0.6853 - val_loss: 0.8628 - val_accuracy: 0.6247\n",
            "Epoch 1921/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7136 - accuracy: 0.6895 - val_loss: 0.8169 - val_accuracy: 0.6326\n",
            "Epoch 1922/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7103 - accuracy: 0.6926 - val_loss: 0.8179 - val_accuracy: 0.6292\n",
            "Epoch 1923/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7114 - accuracy: 0.6890 - val_loss: 0.8164 - val_accuracy: 0.6315\n",
            "Epoch 1924/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7177 - accuracy: 0.6924 - val_loss: 0.8182 - val_accuracy: 0.6337\n",
            "Epoch 1925/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7104 - accuracy: 0.6946 - val_loss: 0.8101 - val_accuracy: 0.6315\n",
            "Epoch 1926/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7134 - accuracy: 0.6921 - val_loss: 0.8199 - val_accuracy: 0.6382\n",
            "Epoch 1927/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7145 - accuracy: 0.6884 - val_loss: 0.8383 - val_accuracy: 0.6326\n",
            "Epoch 1928/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7105 - accuracy: 0.6943 - val_loss: 0.8165 - val_accuracy: 0.6315\n",
            "Epoch 1929/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7118 - accuracy: 0.6898 - val_loss: 0.8164 - val_accuracy: 0.6348\n",
            "Epoch 1930/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7125 - accuracy: 0.6898 - val_loss: 0.8220 - val_accuracy: 0.6393\n",
            "Epoch 1931/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7138 - accuracy: 0.6932 - val_loss: 0.8195 - val_accuracy: 0.6292\n",
            "Epoch 1932/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7139 - accuracy: 0.6893 - val_loss: 0.8301 - val_accuracy: 0.6371\n",
            "Epoch 1933/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7100 - accuracy: 0.6915 - val_loss: 0.8208 - val_accuracy: 0.6303\n",
            "Epoch 1934/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7133 - accuracy: 0.6859 - val_loss: 0.8209 - val_accuracy: 0.6371\n",
            "Epoch 1935/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7148 - accuracy: 0.6932 - val_loss: 0.8216 - val_accuracy: 0.6360\n",
            "Epoch 1936/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7115 - accuracy: 0.6873 - val_loss: 0.8142 - val_accuracy: 0.6348\n",
            "Epoch 1937/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7139 - accuracy: 0.6895 - val_loss: 0.8317 - val_accuracy: 0.6315\n",
            "Epoch 1938/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7146 - accuracy: 0.6881 - val_loss: 0.8252 - val_accuracy: 0.6371\n",
            "Epoch 1939/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7116 - accuracy: 0.6867 - val_loss: 0.8151 - val_accuracy: 0.6303\n",
            "Epoch 1940/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7105 - accuracy: 0.6921 - val_loss: 0.8143 - val_accuracy: 0.6382\n",
            "Epoch 1941/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7077 - accuracy: 0.6932 - val_loss: 0.8139 - val_accuracy: 0.6360\n",
            "Epoch 1942/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7095 - accuracy: 0.6853 - val_loss: 0.8266 - val_accuracy: 0.6247\n",
            "Epoch 1943/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7095 - accuracy: 0.6963 - val_loss: 0.8219 - val_accuracy: 0.6393\n",
            "Epoch 1944/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7095 - accuracy: 0.6952 - val_loss: 0.8205 - val_accuracy: 0.6315\n",
            "Epoch 1945/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7114 - accuracy: 0.6904 - val_loss: 0.8148 - val_accuracy: 0.6360\n",
            "Epoch 1946/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7119 - accuracy: 0.6879 - val_loss: 0.8532 - val_accuracy: 0.6326\n",
            "Epoch 1947/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7152 - accuracy: 0.6887 - val_loss: 0.8235 - val_accuracy: 0.6382\n",
            "Epoch 1948/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7130 - accuracy: 0.6918 - val_loss: 0.8201 - val_accuracy: 0.6292\n",
            "Epoch 1949/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7079 - accuracy: 0.6901 - val_loss: 0.8203 - val_accuracy: 0.6236\n",
            "Epoch 1950/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7075 - accuracy: 0.6952 - val_loss: 0.8199 - val_accuracy: 0.6371\n",
            "Epoch 1951/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7111 - accuracy: 0.6898 - val_loss: 0.8159 - val_accuracy: 0.6326\n",
            "Epoch 1952/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7194 - accuracy: 0.6873 - val_loss: 0.8290 - val_accuracy: 0.6270\n",
            "Epoch 1953/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7101 - accuracy: 0.6909 - val_loss: 0.8216 - val_accuracy: 0.6303\n",
            "Epoch 1954/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7088 - accuracy: 0.6907 - val_loss: 0.8205 - val_accuracy: 0.6371\n",
            "Epoch 1955/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7105 - accuracy: 0.6918 - val_loss: 0.8163 - val_accuracy: 0.6393\n",
            "Epoch 1956/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7093 - accuracy: 0.6856 - val_loss: 0.8154 - val_accuracy: 0.6348\n",
            "Epoch 1957/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7133 - accuracy: 0.6907 - val_loss: 0.8280 - val_accuracy: 0.6348\n",
            "Epoch 1958/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7119 - accuracy: 0.6932 - val_loss: 0.8455 - val_accuracy: 0.6348\n",
            "Epoch 1959/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7126 - accuracy: 0.6859 - val_loss: 0.8175 - val_accuracy: 0.6360\n",
            "Epoch 1960/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7096 - accuracy: 0.6949 - val_loss: 0.8187 - val_accuracy: 0.6360\n",
            "Epoch 1961/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7116 - accuracy: 0.6904 - val_loss: 0.8095 - val_accuracy: 0.6393\n",
            "Epoch 1962/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7116 - accuracy: 0.6864 - val_loss: 0.8180 - val_accuracy: 0.6393\n",
            "Epoch 1963/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7113 - accuracy: 0.6901 - val_loss: 0.8264 - val_accuracy: 0.6438\n",
            "Epoch 1964/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7133 - accuracy: 0.6904 - val_loss: 0.8226 - val_accuracy: 0.6416\n",
            "Epoch 1965/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7104 - accuracy: 0.6915 - val_loss: 0.8191 - val_accuracy: 0.6337\n",
            "Epoch 1966/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7108 - accuracy: 0.6898 - val_loss: 0.8202 - val_accuracy: 0.6292\n",
            "Epoch 1967/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7096 - accuracy: 0.6938 - val_loss: 0.8219 - val_accuracy: 0.6348\n",
            "Epoch 1968/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7134 - accuracy: 0.6828 - val_loss: 0.8185 - val_accuracy: 0.6315\n",
            "Epoch 1969/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7119 - accuracy: 0.6912 - val_loss: 0.8174 - val_accuracy: 0.6315\n",
            "Epoch 1970/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7068 - accuracy: 0.6907 - val_loss: 0.8163 - val_accuracy: 0.6438\n",
            "Epoch 1971/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7115 - accuracy: 0.6895 - val_loss: 0.8184 - val_accuracy: 0.6404\n",
            "Epoch 1972/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7154 - accuracy: 0.6890 - val_loss: 0.8299 - val_accuracy: 0.6348\n",
            "Epoch 1973/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7172 - accuracy: 0.6881 - val_loss: 0.8138 - val_accuracy: 0.6360\n",
            "Epoch 1974/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7115 - accuracy: 0.6929 - val_loss: 0.8198 - val_accuracy: 0.6281\n",
            "Epoch 1975/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7077 - accuracy: 0.6918 - val_loss: 0.8136 - val_accuracy: 0.6360\n",
            "Epoch 1976/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7075 - accuracy: 0.6873 - val_loss: 0.8203 - val_accuracy: 0.6348\n",
            "Epoch 1977/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7089 - accuracy: 0.6904 - val_loss: 0.8282 - val_accuracy: 0.6337\n",
            "Epoch 1978/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7131 - accuracy: 0.6876 - val_loss: 0.8333 - val_accuracy: 0.6326\n",
            "Epoch 1979/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7099 - accuracy: 0.6904 - val_loss: 0.8321 - val_accuracy: 0.6315\n",
            "Epoch 1980/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7090 - accuracy: 0.6904 - val_loss: 0.8365 - val_accuracy: 0.6393\n",
            "Epoch 1981/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7172 - accuracy: 0.6845 - val_loss: 0.8153 - val_accuracy: 0.6258\n",
            "Epoch 1982/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7129 - accuracy: 0.6884 - val_loss: 0.8226 - val_accuracy: 0.6360\n",
            "Epoch 1983/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7084 - accuracy: 0.6904 - val_loss: 0.8220 - val_accuracy: 0.6348\n",
            "Epoch 1984/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7084 - accuracy: 0.6834 - val_loss: 0.8305 - val_accuracy: 0.6247\n",
            "Epoch 1985/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7061 - accuracy: 0.6991 - val_loss: 0.8228 - val_accuracy: 0.6371\n",
            "Epoch 1986/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7085 - accuracy: 0.6907 - val_loss: 0.8176 - val_accuracy: 0.6416\n",
            "Epoch 1987/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7090 - accuracy: 0.6901 - val_loss: 0.8387 - val_accuracy: 0.6416\n",
            "Epoch 1988/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7088 - accuracy: 0.6895 - val_loss: 0.8191 - val_accuracy: 0.6292\n",
            "Epoch 1989/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7076 - accuracy: 0.6926 - val_loss: 0.8217 - val_accuracy: 0.6326\n",
            "Epoch 1990/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7083 - accuracy: 0.6921 - val_loss: 0.8130 - val_accuracy: 0.6382\n",
            "Epoch 1991/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7072 - accuracy: 0.6924 - val_loss: 0.8135 - val_accuracy: 0.6348\n",
            "Epoch 1992/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7107 - accuracy: 0.6949 - val_loss: 0.8167 - val_accuracy: 0.6315\n",
            "Epoch 1993/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7117 - accuracy: 0.6862 - val_loss: 0.8200 - val_accuracy: 0.6382\n",
            "Epoch 1994/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7147 - accuracy: 0.6845 - val_loss: 0.8274 - val_accuracy: 0.6427\n",
            "Epoch 1995/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7079 - accuracy: 0.6859 - val_loss: 0.8187 - val_accuracy: 0.6416\n",
            "Epoch 1996/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7104 - accuracy: 0.6901 - val_loss: 0.8252 - val_accuracy: 0.6315\n",
            "Epoch 1997/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7077 - accuracy: 0.6971 - val_loss: 0.8214 - val_accuracy: 0.6371\n",
            "Epoch 1998/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7075 - accuracy: 0.6924 - val_loss: 0.8386 - val_accuracy: 0.6371\n",
            "Epoch 1999/2000\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7093 - accuracy: 0.6876 - val_loss: 0.8225 - val_accuracy: 0.6427\n",
            "Epoch 2000/2000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.7100 - accuracy: 0.6909 - val_loss: 0.8163 - val_accuracy: 0.6337\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hRQTVtWR3wJ-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "ae79fcec-50b3-4aa0-ea2e-7a3c156a321d"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history['loss']) \n",
        "plt.plot(history.history['val_loss']) \n",
        "plt.title('Model loss') \n",
        "plt.ylabel('Loss') \n",
        "plt.xlabel('Epoch') \n",
        "plt.legend(['Train', 'Test'], loc='upper right') \n",
        "plt.show()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o7aHG9mu3xjO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "b4ff5244-44df-45bd-c471-2249a5e779c9"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVIxGXrh468L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "20ceeb49-09e8-4a6a-8369-aae688101689"
      },
      "source": [
        "y_pred = model.predict(X_val)\n",
        "#print(y_pred)\n",
        "pred = []\n",
        "for i in range(len(y_pred)):\n",
        "    #print(y_pred[i])\n",
        "    #print(np.argmax(y_pred[i]))\n",
        "    pred.append(np.argmax(y_pred[i]))\n",
        "print(pred)\n",
        "\n"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0, 0, 0, 0, 2, 1, 0, 0, 2, 2, 2, 0, 1, 2, 0, 2, 1, 2, 1, 1, 1, 1, 0, 2, 2, 0, 2, 1, 1, 1, 2, 2, 0, 1, 0, 2, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 1, 2, 2, 2, 0, 1, 2, 1, 2, 1, 1, 2, 0, 2, 1, 1, 1, 1, 1, 2, 2, 2, 0, 0, 2, 0, 0, 1, 1, 0, 1, 0, 1, 0, 2, 2, 0, 2, 1, 0, 1, 2, 2, 0, 2, 0, 1, 2, 0, 2, 0, 0, 2, 0, 0, 0, 2, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 2, 1, 2, 0, 1, 2, 1, 1, 2, 1, 1, 0, 0, 1, 1, 1, 2, 1, 2, 1, 1, 0, 2, 2, 1, 2, 1, 0, 2, 0, 2, 2, 0, 1, 0, 1, 2, 0, 2, 2, 2, 0, 0, 1, 2, 1, 0, 0, 2, 2, 1, 0, 1, 0, 1, 0, 2, 2, 0, 1, 1, 0, 0, 1, 1, 1, 0, 2, 1, 0, 2, 0, 2, 1, 2, 0, 1, 0, 0, 1, 0, 0, 1, 1, 2, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 2, 0, 1, 1, 2, 0, 1, 0, 0, 0, 2, 2, 1, 2, 0, 0, 1, 2, 2, 1, 0, 0, 0, 0, 2, 2, 0, 1, 0, 1, 2, 2, 0, 0, 1, 2, 1, 2, 2, 2, 2, 0, 0, 0, 1, 0, 1, 1, 0, 2, 1, 0, 0, 1, 0, 1, 2, 0, 1, 1, 0, 1, 2, 2, 0, 2, 2, 1, 2, 2, 0, 0, 0, 2, 1, 1, 1, 0, 1, 1, 2, 2, 0, 1, 1, 0, 1, 1, 0, 1, 0, 2, 0, 0, 1, 0, 0, 0, 1, 2, 2, 1, 1, 0, 2, 1, 1, 2, 0, 1, 0, 2, 1, 0, 1, 0, 0, 2, 2, 1, 0, 2, 2, 2, 1, 0, 2, 0, 1, 0, 0, 0, 1, 1, 2, 0, 2, 1, 2, 0, 0, 0, 1, 0, 2, 2, 0, 1, 2, 2, 1, 0, 1, 0, 1, 1, 2, 0, 2, 2, 1, 1, 1, 1, 2, 1, 0, 1, 1, 1, 1, 1, 1, 2, 2, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 2, 1, 1, 2, 1, 0, 1, 2, 1, 1, 1, 0, 1, 0, 2, 1, 1, 2, 1, 1, 2, 2, 0, 0, 0, 2, 2, 1, 1, 0, 2, 0, 0, 1, 1, 0, 0, 1, 1, 2, 1, 1, 1, 2, 0, 0, 1, 2, 2, 2, 1, 2, 1, 2, 0, 0, 0, 0, 1, 1, 1, 0, 0, 2, 1, 0, 0, 2, 2, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 2, 2, 1, 2, 0, 0, 2, 0, 2, 2, 0, 0, 0, 0, 2, 0, 1, 1, 2, 0, 1, 0, 0, 0, 2, 2, 0, 0, 2, 2, 2, 1, 0, 0, 2, 1, 0, 2, 1, 1, 1, 2, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 2, 0, 2, 0, 1, 2, 1, 2, 0, 1, 1, 0, 2, 2, 0, 2, 1, 2, 1, 1, 1, 2, 2, 1, 0, 1, 2, 1, 0, 0, 1, 1, 2, 2, 0, 2, 2, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 2, 0, 2, 0, 2, 1, 2, 2, 2, 1, 1, 0, 0, 0, 2, 1, 1, 2, 0, 1, 0, 2, 1, 0, 2, 2, 0, 2, 0, 2, 2, 0, 1, 2, 1, 2, 1, 2, 1, 1, 2, 0, 1, 0, 1, 1, 2, 0, 0, 0, 0, 1, 0, 2, 1, 0, 2, 1, 2, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 2, 1, 0, 1, 1, 1, 2, 0, 1, 2, 1, 0, 0, 0, 0, 1, 1, 2, 0, 2, 2, 2, 2, 1, 1, 2, 2, 1, 0, 0, 2, 2, 1, 1, 1, 1, 2, 2, 1, 2, 2, 2, 1, 1, 0, 2, 0, 2, 0, 1, 0, 2, 0, 1, 2, 2, 2, 0, 2, 1, 0, 0, 0, 2, 1, 0, 2, 0, 0, 1, 1, 2, 0, 1, 1, 1, 2, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 2, 0, 1, 0, 0, 2, 0, 1, 1, 2, 1, 0, 0, 2, 1, 0, 0, 2, 0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 1, 0, 1, 0, 1, 2, 2, 2, 1, 0, 0, 2, 1, 0, 0, 1, 2, 1, 1, 1, 2, 1, 0, 0, 1, 2, 1, 1, 0, 2, 1, 1, 0, 2, 0, 0, 1, 0, 0, 1, 1, 0, 2, 0, 2, 1, 0, 1, 1, 2, 0, 2, 0, 0, 0, 1, 0, 1, 2, 0, 2, 2, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 2, 0, 0, 0, 2, 0, 1, 2, 0, 0, 2, 1, 1, 0, 1, 1, 0, 1, 2, 0, 2, 2, 0, 2, 1, 0, 2, 2, 2, 1, 0, 1, 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gTxKFMlj5IeB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "f434eb30-2285-4b25-d206-c930052262b7"
      },
      "source": [
        "#Converting one hot encoded test label to label\n",
        "test = list()\n",
        "for i in range(len(Y_val)):\n",
        "  #print(Y_test[i])\n",
        "  test.append(np.argmax(Y_val[i]))\n",
        "print(test)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0, 0, 0, 1, 2, 1, 1, 0, 0, 0, 2, 1, 1, 0, 0, 0, 0, 2, 1, 1, 2, 1, 0, 2, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 0, 2, 2, 0, 2, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 2, 1, 0, 0, 1, 2, 2, 2, 1, 2, 2, 0, 2, 0, 1, 2, 1, 1, 2, 2, 2, 0, 0, 1, 0, 2, 0, 1, 0, 1, 0, 2, 2, 2, 1, 0, 2, 2, 0, 1, 1, 0, 2, 2, 0, 0, 2, 0, 2, 2, 0, 2, 1, 0, 0, 2, 0, 2, 1, 2, 1, 1, 0, 0, 0, 0, 1, 2, 0, 2, 1, 1, 0, 1, 2, 2, 0, 2, 1, 2, 2, 0, 0, 1, 1, 2, 2, 2, 0, 1, 0, 2, 2, 1, 2, 0, 0, 2, 2, 2, 2, 0, 1, 1, 0, 0, 0, 2, 0, 2, 2, 1, 2, 2, 0, 1, 2, 2, 2, 1, 0, 1, 2, 1, 0, 2, 2, 0, 0, 2, 2, 2, 1, 1, 2, 0, 2, 0, 2, 0, 0, 2, 1, 2, 1, 1, 0, 2, 1, 1, 0, 1, 2, 1, 2, 1, 1, 1, 2, 1, 2, 0, 1, 0, 2, 1, 1, 0, 2, 2, 1, 0, 0, 0, 2, 2, 2, 0, 2, 0, 2, 2, 2, 1, 2, 1, 1, 2, 2, 0, 0, 1, 1, 1, 2, 2, 2, 0, 1, 0, 1, 0, 2, 1, 2, 2, 0, 0, 1, 0, 2, 2, 0, 2, 1, 0, 1, 1, 0, 1, 2, 0, 1, 0, 0, 1, 2, 2, 0, 2, 0, 1, 1, 2, 0, 0, 0, 2, 0, 1, 0, 1, 1, 1, 2, 1, 2, 2, 1, 0, 1, 1, 2, 1, 2, 2, 0, 0, 1, 1, 2, 0, 1, 2, 0, 1, 0, 1, 2, 0, 0, 2, 2, 1, 1, 0, 1, 0, 0, 2, 0, 2, 2, 1, 0, 2, 2, 2, 1, 0, 2, 0, 0, 2, 0, 0, 1, 1, 2, 2, 2, 1, 2, 1, 0, 2, 1, 0, 2, 2, 1, 0, 1, 2, 2, 0, 1, 2, 2, 1, 2, 0, 2, 2, 1, 2, 0, 1, 2, 1, 0, 1, 0, 2, 2, 1, 1, 2, 2, 0, 1, 0, 1, 2, 1, 0, 2, 2, 0, 2, 2, 1, 2, 0, 1, 1, 1, 1, 1, 1, 0, 2, 0, 2, 1, 1, 2, 0, 2, 2, 0, 2, 1, 0, 2, 2, 1, 1, 0, 0, 2, 1, 1, 1, 0, 0, 1, 1, 2, 2, 0, 0, 1, 0, 2, 1, 2, 2, 2, 1, 2, 2, 2, 2, 0, 1, 1, 1, 1, 1, 0, 2, 2, 1, 2, 0, 2, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 2, 1, 1, 2, 2, 1, 0, 0, 2, 2, 2, 0, 0, 0, 2, 0, 1, 2, 1, 2, 1, 0, 2, 0, 0, 2, 0, 1, 2, 0, 0, 1, 1, 2, 2, 0, 0, 1, 0, 2, 1, 2, 1, 2, 0, 1, 0, 2, 1, 0, 1, 0, 2, 1, 2, 2, 0, 2, 2, 2, 0, 0, 1, 0, 2, 0, 0, 2, 1, 1, 2, 1, 1, 1, 2, 2, 0, 2, 2, 1, 2, 1, 1, 1, 2, 2, 2, 0, 2, 1, 2, 0, 1, 0, 1, 1, 0, 1, 0, 1, 2, 2, 0, 2, 0, 1, 2, 2, 2, 1, 1, 1, 0, 0, 2, 0, 1, 2, 0, 1, 0, 2, 1, 0, 1, 2, 0, 0, 0, 2, 2, 1, 2, 2, 1, 2, 1, 2, 1, 2, 0, 1, 0, 1, 1, 1, 2, 1, 2, 0, 2, 1, 0, 1, 1, 0, 2, 1, 2, 1, 1, 1, 1, 2, 1, 0, 1, 1, 2, 1, 0, 1, 1, 1, 2, 1, 2, 1, 2, 1, 0, 2, 0, 2, 0, 2, 2, 0, 1, 1, 1, 1, 0, 2, 2, 2, 0, 1, 0, 2, 2, 2, 1, 0, 0, 1, 2, 1, 1, 2, 2, 2, 1, 2, 2, 2, 2, 1, 0, 2, 0, 2, 0, 2, 2, 0, 1, 1, 2, 2, 0, 0, 2, 1, 1, 1, 0, 0, 1, 2, 2, 1, 0, 1, 1, 2, 2, 2, 0, 1, 2, 0, 1, 1, 1, 1, 2, 1, 0, 1, 1, 0, 2, 0, 1, 1, 0, 1, 2, 1, 1, 1, 2, 2, 0, 1, 1, 2, 1, 2, 0, 2, 1, 0, 0, 1, 0, 2, 2, 1, 2, 1, 1, 2, 0, 0, 1, 0, 0, 0, 0, 2, 2, 0, 1, 2, 0, 2, 1, 1, 0, 1, 1, 1, 1, 2, 2, 1, 0, 1, 0, 2, 1, 1, 0, 2, 2, 0, 0, 2, 0, 1, 0, 0, 2, 0, 1, 1, 2, 0, 2, 1, 0, 1, 1, 2, 1, 2, 0, 1, 0, 1, 1, 1, 2, 0, 0, 2, 2, 0, 1, 2, 2, 0, 2, 0, 1, 1, 0, 2, 2, 0, 0, 1, 0, 0, 0, 0, 2, 2, 1, 2, 2, 0, 0, 2, 1, 0, 1, 2, 0, 1, 2, 1, 2, 2, 1, 2, 2, 2, 2, 0, 2, 2, 0, 1, 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGbyQRBE6Q0d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "outputId": "508667a3-a1f3-47e5-b368-992195367fba"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix \n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report \n",
        "results = confusion_matrix(test, pred)\n",
        "print('===================================')\n",
        "print(results)\n",
        "print('Accuracy Score :',accuracy_score(test, pred) )\n",
        "print('Report : ')\n",
        "print(classification_report(test, pred))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "===================================\n",
            "[[179  51  43]\n",
            " [ 68 205  26]\n",
            " [ 77  61 180]]\n",
            "Accuracy Score : 0.6337078651685393\n",
            "Report : \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.66      0.60       273\n",
            "           1       0.65      0.69      0.67       299\n",
            "           2       0.72      0.57      0.63       318\n",
            "\n",
            "    accuracy                           0.63       890\n",
            "   macro avg       0.64      0.64      0.63       890\n",
            "weighted avg       0.65      0.63      0.63       890\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}